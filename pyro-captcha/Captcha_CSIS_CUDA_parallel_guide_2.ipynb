{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banner-smith",
   "metadata": {
    "id": "banner-smith"
   },
   "source": [
    "uncomment if executing in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-syria",
   "metadata": {
    "id": "center-syria"
   },
   "outputs": [],
   "source": [
    "! pip uninstall pyro-ppl\n",
    "! pip install pyro-ppl==1.5.1\n",
    "! unzip fonts.zip \n",
    "! unzip claptchagen.zip\n",
    "! unzip csis\n",
    "! cp csis.py /usr/local/lib/python3.7/dist-packages/pyro/infer\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uOtDHX4mpiVp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOtDHX4mpiVp",
    "outputId": "0ff04b17-049a-4cd3-ecfb-bfa9f4d189d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 11 21:36:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2199.998\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
      "bogomips\t: 4399.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 79\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2199.998\n",
      "cache size\t: 56320 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
      "bogomips\t: 4399.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "MemTotal:       13305332 kB\n",
      "MemFree:        10212736 kB\n",
      "MemAvailable:   12417104 kB\n",
      "Buffers:           89648 kB\n",
      "Cached:          2244600 kB\n",
      "SwapCached:            0 kB\n",
      "Active:          1049196 kB\n",
      "Inactive:        1744056 kB\n",
      "Active(anon):     419600 kB\n",
      "Inactive(anon):      444 kB\n",
      "Active(file):     629596 kB\n",
      "Inactive(file):  1743612 kB\n",
      "Unevictable:           0 kB\n",
      "Mlocked:               0 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:              9440 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:        459124 kB\n",
      "Mapped:           227212 kB\n",
      "Shmem:              1192 kB\n",
      "KReclaimable:     145264 kB\n",
      "Slab:             195904 kB\n",
      "SReclaimable:     145264 kB\n",
      "SUnreclaim:        50640 kB\n",
      "KernelStack:        4888 kB\n",
      "PageTables:         6188 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:     6652664 kB\n",
      "Committed_AS:    3376684 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:       47100 kB\n",
      "VmallocChunk:          0 kB\n",
      "Percpu:             1400 kB\n",
      "AnonHugePages:         0 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "FileHugePages:         0 kB\n",
      "FilePmdMapped:         0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "Hugetlb:               0 kB\n",
      "DirectMap4k:      154824 kB\n",
      "DirectMap2M:     5087232 kB\n",
      "DirectMap1G:    10485760 kB\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "! cat /proc/cpuinfo\n",
    "! cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-postage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intimate-postage",
    "outputId": "a7f27d6f-a855-4cce-afb9-0e601de45af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "number of samples in group 0\n",
      "number of samples in group 0\n",
      "number of samples in group 0\n",
      "number of samples in group 4986\n",
      "text 9007 captcha shape (32, 100) noise 0.3105049283504522\n",
      "text 0657 captcha shape (32, 100) noise 0.10054591923603387\n",
      "text 2002 captcha shape (32, 100) noise 0.9829977817005179\n",
      "text 4450 captcha shape (32, 100) noise 0.3057383563226716\n",
      "text 6245 captcha shape (32, 100) noise 0.47087518038872284\n",
      "text 3115 captcha shape (32, 100) noise 0.1437453963130231\n",
      "text 7332 captcha shape (32, 100) noise 0.8306400992374378\n",
      "text 4950 captcha shape (32, 100) noise 0.29843787350670076\n",
      "text 1783 captcha shape (32, 100) noise 0.04538525935751448\n",
      "text 1700 captcha shape (32, 100) noise 0.4846076791229041\n",
      "text 5938 captcha shape (32, 100) noise 0.9292661043042756\n",
      "number of samples in group 5014\n",
      "text 79425 captcha shape (32, 100) noise 0.42946923546619986\n",
      "text 89020 captcha shape (32, 100) noise 0.18049937043420877\n",
      "text 69801 captcha shape (32, 100) noise 0.7777403471725163\n",
      "text 42376 captcha shape (32, 100) noise 0.21456924176396322\n",
      "text 71315 captcha shape (32, 100) noise 0.6497975549393976\n",
      "text 09638 captcha shape (32, 100) noise 0.28535633237845454\n",
      "text 63488 captcha shape (32, 100) noise 0.13433065030667177\n",
      "text 88656 captcha shape (32, 100) noise 0.18074642181684297\n",
      "text 23018 captcha shape (32, 100) noise 0.4628965942798645\n",
      "text 10403 captcha shape (32, 100) noise 0.05404405067668835\n",
      "text 09213 captcha shape (32, 100) noise 0.9086007309471092\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import numpy as np\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from PIL import Image\n",
    "from claptchagen.claptcha import Claptcha\n",
    "from torch.distributions import constraints\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "print(pyro.__version__)\n",
    "\n",
    "captcha_folder = 'generated_captchas'\n",
    "captchaHeight = 32\n",
    "captchaWidth = 100\n",
    "captchaMarginX = 4\n",
    "captchaMarginY = 4\n",
    "batch_size = 10\n",
    "\n",
    "char_dict = string.digits\n",
    "USE_CUDA = True\n",
    "MAX_N = 5 # maximum number of letters in a captcha \n",
    "MIN_N = 4 # minimum number of letters in a captcha\n",
    "MIN_NOISE = 0.01 # minimum noise\n",
    "MAX_NOISE = 0.99 # maximum noise\n",
    "smoke_test = False\n",
    "num_steps = 200 if not smoke_test else 10\n",
    "TrainingSample = 10000 if not smoke_test else 100 # number of captchas generated for training\n",
    "\n",
    "def randomString():\n",
    "    \"\"\"\n",
    "    return a string with <num_char> random letters\n",
    "    \"\"\"\n",
    "    k = random.randint(MIN_N, MAX_N) # sample number of characters\n",
    "    \n",
    "    rndLetters = (random.choice(char_dict) for _ in range(k))\n",
    "    \n",
    "    pad_spaces = MAX_N - k # pad the string so the captcha is close to center\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    \n",
    "    return space + \"\".join(rndLetters) + space\n",
    "\n",
    "def ramdomNoise():\n",
    "    \"\"\"\n",
    "    return a float between MIN_NOISE, MAX_NOISE\n",
    "    \"\"\"\n",
    "    return random.uniform(MIN_NOISE, MAX_NOISE)\n",
    "\n",
    "def generate_random_captcha(n, save=False):\n",
    "    \"\"\"\n",
    "    generate n random captchas,\n",
    "    return a list of texts on the captchas\n",
    "    \"\"\"\n",
    "    # Initialize Claptcha object with random text, FreeMono as font, of size\n",
    "    # 100x30px, using bicubic resampling filter and adding a bit of white noise\n",
    "    c = Claptcha(randomString, \"fonts/FreeSans.ttf\", (captchaWidth, captchaHeight), (captchaMarginX, captchaMarginY),\n",
    "             resample=Image.BILINEAR, noise=0)\n",
    "    captcha_generated = [ [] for i in range(MAX_N)]\n",
    "    for i in range(n):\n",
    "        c.noise = ramdomNoise()\n",
    "        if save:\n",
    "            text, _ = c.write(os.path.join(captcha_folder, 'captcha{}.png'.format(i)))\n",
    "            os.rename(os.path.join(captcha_folder, 'captcha{}.png'.format(i)),os.path.join(captcha_folder, '{}.png'.format(text + \"_\" + str(i))))\n",
    "        text, image = c.image\n",
    "        text = text.strip()\n",
    "        image = np.array(image)[:, :, 0] # the generator is gray scale, only keep one channel is enough\n",
    "        captcha_generated[len(text) - 1].append((text, image, c.noise))\n",
    "    return captcha_generated\n",
    "    \n",
    "captcha_generated = generate_random_captcha(TrainingSample, save=False)\n",
    "for lst in captcha_generated:\n",
    "    print(\"number of samples in group\", len(lst))\n",
    "    # print some sample captcha information generated\n",
    "    for i, t in enumerate(lst):\n",
    "        print(\"text\", t[0], \"captcha shape\", t[1].shape, \"noise\", t[2])\n",
    "        if i >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-underwear",
   "metadata": {
    "id": "negative-underwear"
   },
   "outputs": [],
   "source": [
    "def render_image(chars, fonts=\"fonts/FreeSans.ttf\", size=(captchaWidth, captchaHeight), \n",
    "                 margin=(captchaMarginX, captchaMarginY), resample=Image.BILINEAR, noise=0.3, use_cuda=False):\n",
    "    #noise = noise.data.item()\n",
    "    #print(chars, noise)\n",
    "    pad_spaces = MAX_N - len(chars)\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    chars = space + chars + space\n",
    "    render = Claptcha(chars, fonts, size, margin, resample=resample, noise=noise)\n",
    "\n",
    "    \n",
    "    _ , rendered_image = render.image\n",
    "    rendered_image = np.array(rendered_image)[:,:,0] # the generator is gray scale, only keep one channel is enough\n",
    "    rendered_image = np.subtract(np.divide(rendered_image, 255), 0.5)\n",
    "    rendered_image = torch.from_numpy(rendered_image)\n",
    "    if use_cuda:\n",
    "        rendered_image = rendered_image.cuda()\n",
    "    return rendered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-lobby",
   "metadata": {
    "id": "contrary-lobby"
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, raw_captchas, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.raw_captchas = raw_captchas\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_captchas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.raw_captchas[idx][0]\n",
    "        image = self.raw_captchas[idx][1]\n",
    "        noise = self.raw_captchas[idx][2]\n",
    "        \n",
    "        image = np.subtract(np.divide(image, 255), 0.5)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return label, image, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-spice",
   "metadata": {
    "id": "taken-spice"
   },
   "outputs": [],
   "source": [
    "def make_loarders(BATCH_SIZE, raw_samples):\n",
    "    dataloaders = [] # dataloaders for different num of char\n",
    "    for lst in raw_samples:\n",
    "        if lst:\n",
    "            ds = CaptchaDataset(lst)\n",
    "            dataloader = DataLoader(ds, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True, num_workers=0, drop_last=True)\n",
    "            dataloaders.append(dataloader)\n",
    "    return dataloaders\n",
    "\n",
    "def make_batches(dataloaders):\n",
    "    all_batches = []\n",
    "    for dl in dataloaders:\n",
    "        for i_batch, sample in enumerate(dl):\n",
    "            all_batches.append(sample)\n",
    "    random.shuffle(all_batches)\n",
    "    random.shuffle(all_batches)\n",
    "    return all_batches\n",
    "\n",
    "TrainLoaders = make_loarders(BATCH_SIZE=batch_size, raw_samples=captcha_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-rocket",
   "metadata": {
    "id": "arabic-rocket"
   },
   "outputs": [],
   "source": [
    "class NoiseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, img_size, out_size = 1):\n",
    "        \"\"\"\n",
    "        Network for learning noise in a captcha\n",
    "        \"\"\"\n",
    "        super(NoiseNet, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.fc0 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
    "        self.fc1 = nn.Linear(img_size[0] * img_size[1], 1024)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc20 = nn.Linear(1024, img_size[0] * img_size[1])\n",
    "        self.fc21 = nn.Linear(img_size[0] * img_size[1], out_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        BS = img.shape[0]\n",
    "        img = img.reshape(-1, self.img_size[0] * self.img_size[1])\n",
    "        hidden = F.relu(self.fc0(img))\n",
    "        hidden = self.fc1(hidden)\n",
    "        # mean of noise, used in normal distribution\n",
    "        noise_map = self.fc20(F.relu(self.fc2(F.relu(hidden))))\n",
    "        mean =  self.fc21(F.relu(noise_map))\n",
    "        # std used in normal distribution\n",
    "        sigma = torch.tensor([[1e-8] for _ in range(BS)]).float()\n",
    "        if USE_CUDA:\n",
    "            sigma = sigma.cuda()\n",
    "        return mean, sigma, noise_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-sunset",
   "metadata": {
    "id": "patient-sunset"
   },
   "outputs": [],
   "source": [
    "class NumNet(nn.Module):\n",
    "    def __init__(self, img_size, out_size = 3):\n",
    "        \"\"\"\n",
    "        Network for learning N, number of letters in a captcha\n",
    "        \"\"\"\n",
    "        super(NumNet, self).__init__()\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(img_size[0] * img_size[1] * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_size),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "  \n",
    "    def forward(self, img):\n",
    "        img = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
    "        prob = self.neural_net(img)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-sender",
   "metadata": {
    "id": "authorized-sender"
   },
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, img_size, output_size, MAX_N):\n",
    "        \"\"\"\n",
    "        Network for letters in a captcha, given the noise and number of letters\n",
    "        \"\"\"\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # observe layers\n",
    "        self.nnfc = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.convBN1 = nn.BatchNorm2d(64)\n",
    "        self.convBN2 = nn.BatchNorm2d(64)\n",
    "        self.convBN3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, img, noise_map):\n",
    "        \n",
    "        BATCH_SIZE = img.shape[0]\n",
    "        # feed the noise_map to a linear layer to tune the values\n",
    "        noise_map = F.relu(self.nnfc(noise_map))\n",
    "        noise_map = torch.reshape(noise_map, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
    "    \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
    "        # compute the difference between original image and noise map\n",
    "        # i.e. extract the unnoisy image\n",
    "        img = torch.sub(img, noise_map)\n",
    "\n",
    "        img = self.pool(F.relu(self.convBN1(self.conv1(img))))\n",
    "        img = self.pool(F.relu(self.convBN2(self.conv2(img))))\n",
    "        img = self.pool(F.relu(self.convBN3(self.conv3(img))))\n",
    "        \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1280))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-lending",
   "metadata": {
    "id": "abstract-lending"
   },
   "outputs": [],
   "source": [
    "# Parallel the networks\n",
    "class CharNetSingle(nn.Module):\n",
    "    def __init__(self, img_size, output_size, MAX_N):\n",
    "        \"\"\"\n",
    "        Network for letters in a captcha, given the noise and number of letters\n",
    "        \"\"\"\n",
    "        super(CharNetSingle, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.MAX_N = MAX_N\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1280 * MAX_N, out_channels=2048 * MAX_N, kernel_size=1, groups=MAX_N)\n",
    "        self.conv2 = nn.Conv1d(in_channels=2048 * MAX_N, out_channels=1024 * MAX_N, kernel_size=1, groups=MAX_N)\n",
    "        self.conv3 = nn.Conv1d(in_channels=1024 * MAX_N, out_channels=1024 * MAX_N, kernel_size=1, groups=MAX_N)\n",
    "        self.conv4 = nn.Conv1d(in_channels=1024 * MAX_N, out_channels=output_size * MAX_N, kernel_size=1, groups=MAX_N)\n",
    "\n",
    "    def forward(self, img_embedded, N):\n",
    "        BATCH_SIZE = img_embedded.shape[0]\n",
    "        \n",
    "        img_embedded = torch.reshape(img_embedded, (img_embedded.shape[0], img_embedded.shape[1], 1)).repeat(1, self.MAX_N, 1)\n",
    "\n",
    "        out = F.relu(self.conv1(img_embedded)) # input shape B x (img_embedded x MAX_N) x 1\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.conv4(out) # output shape B x (output_size x MAX_N) x 1\n",
    "        \n",
    "        # we only want the first N x output_size outputs\n",
    "        out = out[:, : N * self.output_size]\n",
    "        out = torch.reshape(out, (BATCH_SIZE, N, self.output_size)) # output shape B x N x output_size (10)\n",
    "        out = F.log_softmax(out, dim=2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-meditation",
   "metadata": {
    "id": "overhead-meditation"
   },
   "outputs": [],
   "source": [
    "def inference(t, use_cuda=False):\n",
    "    \"\"\"\n",
    "    one epoch of inference (iterate the training set once)\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    loss = 0\n",
    "    length = TrainingSample\n",
    "    loss_group = []\n",
    "    all_batches = make_batches(TrainLoaders)\n",
    "    for i_batch, sample_batched in enumerate(all_batches):\n",
    "        \n",
    "        img = sample_batched[1]\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        IMG = {\"captcha\" : img}\n",
    "        imme_loss = csis.step(observations=IMG)\n",
    "        loss += imme_loss / length\n",
    "\n",
    "    print(\"loss at epoch {} is {}\".format(t, loss), end=\"; \")\n",
    "    print(\"Epoch takes\", round(time.time()- start), \"seconds\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-provincial",
   "metadata": {
    "id": "agreed-provincial"
   },
   "outputs": [],
   "source": [
    "def test(n = 0, use_train=False, verbose=False, use_cuda=False):\n",
    "    \"\"\"\n",
    "    benchmarking performance on customized or training set\n",
    "    \"\"\"\n",
    "    if use_train:\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
    "    else:\n",
    "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
    "    \n",
    "    total_correct = 0\n",
    "    char_correct = 0\n",
    "    total_char = 0\n",
    "    all_batches = make_batches(TestLoaders)\n",
    "    noise_difference = 0\n",
    "    for i_batch, t in enumerate(all_batches):\n",
    "\n",
    "        label = t[0][0]\n",
    "        gt_noise = t[2][0]\n",
    "        img = t[1]\n",
    "\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        \n",
    "        IMG = {\"captcha\" : img}\n",
    "        \n",
    "        posterior = csis.run(observations=IMG)\n",
    "        marginal_num = pyro.infer.EmpiricalMarginal(posterior, \"num_char\")\n",
    "        marginal_noise = pyro.infer.EmpiricalMarginal(posterior, \"noise\")\n",
    "        marginal_chars = pyro.infer.EmpiricalMarginal(posterior, \"chars\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            N_index = marginal_num()\n",
    "            N = N_index + captchaModel.num_char_domain[0]\n",
    "            noise = captchaModel._map_to_noise_range(marginal_noise()[0])\n",
    "            #sampled_chars = []\n",
    "            \n",
    "            # sample characters\n",
    "            sampled_chars = torch.squeeze(marginal_chars().cpu())\n",
    "        \n",
    "        chars = \"\"\n",
    "        for i in range(sampled_chars.shape[0]):\n",
    "            c = sampled_chars[i]\n",
    "            chars +=  captchaModel.char_dict[c]\n",
    "        correct = 0\n",
    "        \n",
    "        for p_char, t_char in zip(chars, label):\n",
    "            if p_char == t_char:\n",
    "                correct += 1\n",
    "        noise_difference += abs(float(noise) - float(gt_noise))\n",
    "        if not verbose:\n",
    "            print(\"N_predicted:\", int(N), \"| Actual N:\", len(label), \"| Predicted Noise:\", round(float(noise), 3), \"| Actual Noise:\", round(float(gt_noise), 3), \"| Predicted Text:\", chars, \"| Actual Text:\", label, \"| Correct:\", correct)\n",
    "        if correct == len(label) and int(N) == len(label):\n",
    "            total_correct += 1\n",
    "        char_correct += correct\n",
    "        total_char += len(label)\n",
    "    num_test_samples = i_batch + 1\n",
    "    accuracy = total_correct / num_test_samples\n",
    "    char_accuracy = char_correct / total_char\n",
    "    noise_difference = noise_difference / num_test_samples\n",
    "    print(\"use_train =\", use_train, \"AVG Noise Difference:\", noise_difference, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-invitation",
   "metadata": {
    "id": "occupied-invitation"
   },
   "outputs": [],
   "source": [
    "def test_cycle(use_cuda):\n",
    "    \n",
    "    # disable dropout\n",
    "    #captchaModel.numNet.eval()\n",
    "    #captchaModel.charNetSingle.eval()\n",
    "    test(use_train=True, verbose=True, use_cuda=use_cuda)\n",
    "    test(1000, use_train=False, verbose=True, use_cuda=use_cuda)\n",
    "    #test(10, use_train=True, verbose=False, use_cuda=use_cuda)\n",
    "    test(10, use_train=False, verbose=False, use_cuda=use_cuda)\n",
    "    # enable dropout\n",
    "    #captchaModel.numNet.train()\n",
    "    #captchaModel.charNetSingle.train()\n",
    "\n",
    "def optimize(start_epoch=1, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Training/Inferencing Stage\n",
    "    \"\"\"\n",
    "    loss_sequence = []\n",
    "    pause = 5\n",
    "    save_pause = 10\n",
    "    print(\"Optimizing...\")\n",
    "    for t in range(start_epoch, num_steps + 1):\n",
    "        L = inference(t, use_cuda)\n",
    "        loss_sequence.append(L)\n",
    "        if (t % pause == 0) and (t > 0):\n",
    "            test_cycle(use_cuda=use_cuda)\n",
    "#         if (t % save_pause == 0) and (t > 0):\n",
    "#             save_and_download_checkpoints(\"branches-1-no-var-no-tanh_model.pt\", \"branches-1-no-var-no-tanh_optim.pt\", \"branches-1-no-var-no-tanh_param_store.pt\")\n",
    "    plt.plot(loss_sequence)\n",
    "    plt.title(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-science",
   "metadata": {
    "id": "occasional-science"
   },
   "outputs": [],
   "source": [
    "# saves the model and optimizer states to disk\n",
    "def save_checkpoint(currentModel, currentOptimzier, save_model, save_opt, save_param_store):\n",
    "    print(\"saving model to %s...\" % save_model)\n",
    "    torch.save(currentModel.state_dict(), save_model)\n",
    "    print(\"saving optimizer states to %s...\" % save_opt)\n",
    "    currentOptimzier.save(save_opt)\n",
    "    print(\"saving pyro pram store states to %s...\" % save_param_store)\n",
    "    pyro.get_param_store().save(save_param_store)\n",
    "    print(\"done saving checkpoints to disk.\")\n",
    "\n",
    "# loads the model and optimizer states from disk\n",
    "def load_checkpoint(myModel, myOptimzer, load_model, load_opt, load_param_store):\n",
    "    pyro.clear_param_store()\n",
    "    print(\"loading model from %s...\" % load_model)\n",
    "    myModel.load_state_dict(torch.load(load_model))\n",
    "    print(\"loading optimizer states from %s...\" % load_opt)\n",
    "    myOptimzer.load(load_opt)\n",
    "    print(\"loading pyro pram store states from %s...\" % load_param_store)\n",
    "    pyro.get_param_store().load(load_param_store)\n",
    "    print(\"done loading states.\")\n",
    "    pyro.module(\"guide\", myModel, update_module_params=True)\n",
    "\n",
    "def save_and_download_checkpoints(save_model, save_opt, save_param_store):\n",
    "    save_checkpoint(captchaModel, optimiser, save_model, save_opt, save_param_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-secretary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "composite-secretary",
    "outputId": "b6abf132-eca2-4221-97c0-91d5fb695bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n",
      "loss at epoch 1 is 363932091250952.6; Epoch takes 635 seconds\n",
      "loss at epoch 2 is 109608433209311.39; Epoch takes 639 seconds\n",
      "loss at epoch 3 is 69369415945499.56; Epoch takes 639 seconds\n",
      "loss at epoch 4 is 55036107134310.79; Epoch takes 637 seconds\n",
      "loss at epoch 5 is 45411374870691.88; Epoch takes 637 seconds\n",
      "use_train = True AVG Noise Difference: 0.036527150180645535 Total correct: 6780 accuracy:6780/10000= 0.678 char_accuracy:41223/45014= 0.9157817567867774\n",
      "use_train = False AVG Noise Difference: 0.03754256572315846 Total correct: 695 accuracy:695/1000= 0.695 char_accuracy:4128/4489= 0.919581198485186\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.448 | Actual Noise: 0.456 | Predicted Text: 51169 | Actual Text: 51164 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.163 | Actual Noise: 0.02 | Predicted Text: 5910 | Actual Text: 5910 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.793 | Actual Noise: 0.775 | Predicted Text: 1715 | Actual Text: 1725 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.31 | Actual Noise: 0.34 | Predicted Text: 10995 | Actual Text: 10995 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.462 | Actual Noise: 0.467 | Predicted Text: 1355 | Actual Text: 1355 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.533 | Actual Noise: 0.563 | Predicted Text: 36502 | Actual Text: 66502 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.811 | Actual Noise: 0.859 | Predicted Text: 4015 | Actual Text: 4015 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.185 | Actual Noise: 0.099 | Predicted Text: 04665 | Actual Text: 04665 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.482 | Actual Noise: 0.501 | Predicted Text: 9560 | Actual Text: 9560 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.27 | Actual Noise: 0.235 | Predicted Text: 7181 | Actual Text: 7141 | Correct: 3\n",
      "use_train = False AVG Noise Difference: 0.04213987226220656 Total correct: 6 accuracy:6/10= 0.6 char_accuracy:40/44= 0.9090909090909091\n",
      "loss at epoch 6 is 40772376521893.516; Epoch takes 638 seconds\n",
      "loss at epoch 7 is 37990012950806.49; Epoch takes 638 seconds\n",
      "loss at epoch 8 is 37950155059861.95; Epoch takes 637 seconds\n",
      "loss at epoch 9 is 34573225873506.35; Epoch takes 639 seconds\n",
      "loss at epoch 10 is 33381889847590.938; Epoch takes 637 seconds\n",
      "use_train = True AVG Noise Difference: 0.03444104729189335 Total correct: 8279 accuracy:8279/10000= 0.8279 char_accuracy:43130/45014= 0.958146354467499\n",
      "use_train = False AVG Noise Difference: 0.036717577707654075 Total correct: 815 accuracy:815/1000= 0.815 char_accuracy:4289/4493= 0.9545960382817716\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.339 | Actual Noise: 0.334 | Predicted Text: 8052 | Actual Text: 8052 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.713 | Actual Noise: 0.722 | Predicted Text: 3777 | Actual Text: 3777 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.73 | Actual Noise: 0.704 | Predicted Text: 9365 | Actual Text: 9365 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.667 | Actual Noise: 0.661 | Predicted Text: 98436 | Actual Text: 98436 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.208 | Actual Noise: 0.141 | Predicted Text: 20943 | Actual Text: 20943 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.3 | Actual Noise: 0.26 | Predicted Text: 7706 | Actual Text: 7706 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.381 | Actual Noise: 0.363 | Predicted Text: 6239 | Actual Text: 6239 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.18 | Actual Noise: 0.049 | Predicted Text: 74439 | Actual Text: 74439 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.915 | Actual Noise: 0.985 | Predicted Text: 82768 | Actual Text: 82768 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.196 | Actual Noise: 0.109 | Predicted Text: 3795 | Actual Text: 3795 | Correct: 4\n",
      "use_train = False AVG Noise Difference: 0.045918592454743015 Total correct: 10 accuracy:10/10= 1.0 char_accuracy:44/44= 1.0\n",
      "loss at epoch 11 is 32377940148774.504; Epoch takes 634 seconds\n",
      "loss at epoch 12 is 30971088746813.81; Epoch takes 633 seconds\n",
      "loss at epoch 13 is 28135635960659.992; Epoch takes 633 seconds\n",
      "loss at epoch 14 is 27605111353140.832; Epoch takes 638 seconds\n",
      "loss at epoch 15 is 27239169230923.34; Epoch takes 648 seconds\n",
      "use_train = True AVG Noise Difference: 0.03426812926011208 Total correct: 8813 accuracy:8813/10000= 0.8813 char_accuracy:43743/45014= 0.9717643399831164\n",
      "use_train = False AVG Noise Difference: 0.0355988945849064 Total correct: 881 accuracy:881/1000= 0.881 char_accuracy:4377/4500= 0.9726666666666667\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.164 | Actual Noise: 0.038 | Predicted Text: 0569 | Actual Text: 0569 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.577 | Actual Noise: 0.573 | Predicted Text: 0275 | Actual Text: 0275 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.214 | Actual Noise: 0.154 | Predicted Text: 03135 | Actual Text: 03135 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.479 | Actual Noise: 0.445 | Predicted Text: 38441 | Actual Text: 38441 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.671 | Actual Noise: 0.657 | Predicted Text: 4994 | Actual Text: 4994 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.166 | Actual Noise: 0.04 | Predicted Text: 80077 | Actual Text: 80077 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.751 | Actual Noise: 0.732 | Predicted Text: 7494 | Actual Text: 7494 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.334 | Actual Noise: 0.324 | Predicted Text: 03272 | Actual Text: 03272 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.17 | Actual Noise: 0.054 | Predicted Text: 4450 | Actual Text: 4450 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.215 | Actual Noise: 0.153 | Predicted Text: 55647 | Actual Text: 55647 | Correct: 5\n",
      "use_train = False AVG Noise Difference: 0.05703533751954655 Total correct: 10 accuracy:10/10= 1.0 char_accuracy:45/45= 1.0\n",
      "loss at epoch 16 is 26371675212087.293; Epoch takes 645 seconds\n",
      "loss at epoch 17 is 26969606657415.582; Epoch takes 650 seconds\n",
      "loss at epoch 18 is 24927887243463.9; Epoch takes 639 seconds\n",
      "loss at epoch 19 is 25399263976135.074; Epoch takes 639 seconds\n"
     ]
    }
   ],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    \"\"\"\n",
    "    network, model and guide wrapper class\n",
    "    \"\"\"\n",
    "    def __init__(self, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.num_char_domain = torch.arange(MIN_N, MAX_N + 1)\n",
    "        if use_cuda:\n",
    "            self.num_char_domain = self.num_char_domain.cuda()\n",
    "\n",
    "        self.numNet = NumNet((captchaHeight, captchaWidth), len(self.num_char_domain))\n",
    "        self.noiseNet = NoiseNet((captchaHeight, captchaWidth), 1)\n",
    "        self.char_dict = char_dict # letter dictionary\n",
    "        self.rnn_hidden_size = 512\n",
    "        self.rnn_num_layer = 2\n",
    "        self.charNet = CharNetSingle((captchaHeight, captchaWidth), len(self.char_dict), MAX_N)\n",
    "        self.inputEmbedding = InputEmbedding((captchaHeight, captchaWidth), len(self.char_dict), max(self.num_char_domain))\n",
    "        self.noise_constraint = torch.distributions.constraints.interval(MIN_NOISE, MAX_NOISE)\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "    def _map_to_noise_range(self, input):\n",
    "        \"\"\"\n",
    "        map input number to the valid noise range\n",
    "        \"\"\"\n",
    "        input = torch.distributions.transform_to(self.noise_constraint)(input)\n",
    "        return input\n",
    "\n",
    "    def guide(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        pyro.module(\"guide\", self)\n",
    "        img = observations[\"captcha\"].float()\n",
    "        \n",
    "        # posterior to the number of letters\n",
    "        prob = self.numNet(img)\n",
    "        prob = torch.mean(prob, dim=0)\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(prob))\n",
    "        N_index = torch.add(N_index, self.num_char_domain[0])\n",
    "\n",
    "        with pyro.plate(\"data\", img.shape[0]):\n",
    "            \n",
    "            # posterior to the noise\n",
    "            noise_mean, noise_sig, noise_map = self.noiseNet(img)\n",
    "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "            \n",
    "            # compute the input embedding first (CNNs)\n",
    "            input_emb = self.inputEmbedding(img, noise_map)\n",
    "            # compute the vectorized linear nets\n",
    "            charP_i = self.charNet(input_emb, N_index)\n",
    "            pyro.sample(\"chars\", dist.Categorical(charP_i).to_event(1))\n",
    "    \n",
    "    def model(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        \n",
    "        BS = observations[\"captcha\"].shape[0]\n",
    "        \n",
    "        num_p = torch.tensor(1 / len(self.num_char_domain)).repeat(len(self.num_char_domain))\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            num_p = num_p.cuda()\n",
    "        \n",
    "        # sample the number of characters\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(num_p))\n",
    "        N_index = torch.add(N_index,  self.num_char_domain[0])\n",
    "        \n",
    "        with pyro.plate(\"data\", BS):\n",
    "            \n",
    "            noise_mean = torch.tensor((MAX_NOISE - MIN_NOISE) / 2).repeat((BS, 1))\n",
    "            noise_sig = torch.tensor(0.5).repeat((BS, 1))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                noise_mean = noise_mean.cuda()\n",
    "                noise_sig = noise_sig.cuda()\n",
    "\n",
    "            # sample the noise\n",
    "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "            \n",
    "            # prior of characters\n",
    "            num_c_i = torch.tensor(1 / len(self.char_dict)).repeat((BS, N_index, len(self.char_dict)))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                num_c_i = num_c_i.cuda()\n",
    "            sampled_c = pyro.sample(\"chars\", dist.Categorical(num_c_i).to_event(1))\n",
    "\n",
    "            rendered_images = []\n",
    "            for i in range(sampled_c.shape[0]): # loop through batches\n",
    "                chars = \"\"\n",
    "                for j in range(N_index): # loop through indices\n",
    "                    chars += self.char_dict[sampled_c[i][j]]\n",
    "        \n",
    "                rendered_image = render_image(chars, noise=float(noise_batch[i]), use_cuda=self.use_cuda)\n",
    "                rendered_images.append(rendered_image)\n",
    "                \n",
    "        rendered_images = torch.stack(rendered_images)\n",
    "        sigma = torch.tensor(0.000001)\n",
    "        if self.use_cuda:\n",
    "                sigma = sigma.cuda()\n",
    "\n",
    "        pyro.sample(\"captcha\", dist.Normal(rendered_images, sigma).to_event(2), obs=observations[\"captcha\"])\n",
    "\n",
    "captchaModel = CaptchaModel(USE_CUDA)\n",
    "\n",
    "optimiser = pyro.optim.Adam({'lr': 5e-5})\n",
    "csis = pyro.infer.CSIS(captchaModel.model, captchaModel.guide, optimiser, num_inference_samples=1)\n",
    "\n",
    "\n",
    "optimize(1, USE_CUDA)\n",
    "test_cycle(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JtIuFFPvdzKk",
   "metadata": {
    "id": "JtIuFFPvdzKk"
   },
   "outputs": [],
   "source": [
    "# saves the model and optimizer states to disk\n",
    "def save_checkpoint(currentModel, currentOptimzier, save_model, save_opt, save_param_store):\n",
    "    print(\"saving model to %s...\" % save_model)\n",
    "    torch.save(currentModel.state_dict(), save_model)\n",
    "    print(\"saving optimizer states to %s...\" % save_opt)\n",
    "    currentOptimzier.save(save_opt)\n",
    "    print(\"saving pyro pram store states to %s...\" % save_param_store)\n",
    "    pyro.get_param_store().save(save_param_store)\n",
    "    print(\"done saving checkpoints to disk.\")\n",
    "\n",
    "# loads the model and optimizer states from disk\n",
    "def load_checkpoint(myModel, myOptimzer, load_model, load_opt, load_param_store):\n",
    "    pyro.clear_param_store()\n",
    "    print(\"loading model from %s...\" % load_model)\n",
    "    myModel.load_state_dict(torch.load(load_model))\n",
    "    print(\"loading optimizer states from %s...\" % load_opt)\n",
    "    myOptimzer.load(load_opt)\n",
    "    print(\"loading pyro pram store states from %s...\" % load_param_store)\n",
    "    pyro.get_param_store().load(load_param_store)\n",
    "    print(\"done loading states.\")\n",
    "    pyro.module(\"guide\", myModel, update_module_params=True)\n",
    "\n",
    "def save_and_download_checkpoints(save_model, save_opt, save_param_store):\n",
    "    save_checkpoint(captchaModel, optimiser, save_model, save_opt, save_param_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-sister",
   "metadata": {
    "id": "swiss-sister"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-difficulty",
   "metadata": {
    "id": "genetic-difficulty"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy_of_Copy_of_Captcha_CSIS_CUDA_noise_depend_input_embedding_parallel_guide_more.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
