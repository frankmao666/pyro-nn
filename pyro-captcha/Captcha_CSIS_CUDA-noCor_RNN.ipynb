{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banner-smith",
   "metadata": {
    "id": "monetary-reminder"
   },
   "source": [
    "uncomment if executing in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip uninstall pyro-ppl\n",
    "# ! pip install pyro-ppl==1.5.1\n",
    "# ! unzip fonts.zip \n",
    "# ! unzip claptchagen.zip\n",
    "# ! unzip csis\n",
    "# ! cp csis.py /usr/local/lib/python3.7/dist-packages/pyro/infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intimate-postage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intimate-postage",
    "outputId": "c331cb86-4c0e-41c0-bb80-b7d9a9042530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "number of samples in group 0\n",
      "number of samples in group 0\n",
      "number of samples in group 3402\n",
      "text 275 captcha shape (32, 100) noise 0.7376843730511927\n",
      "text 514 captcha shape (32, 100) noise 0.3852500369815802\n",
      "text 203 captcha shape (32, 100) noise 0.2529799448636407\n",
      "text 275 captcha shape (32, 100) noise 0.062497506655551385\n",
      "text 363 captcha shape (32, 100) noise 0.7036140246645186\n",
      "text 386 captcha shape (32, 100) noise 0.6975403025003474\n",
      "text 960 captcha shape (32, 100) noise 0.0542193981267634\n",
      "text 388 captcha shape (32, 100) noise 0.6433021409711385\n",
      "text 355 captcha shape (32, 100) noise 0.15251262474813806\n",
      "text 253 captcha shape (32, 100) noise 0.14166538866849146\n",
      "text 846 captcha shape (32, 100) noise 0.7555683932734343\n",
      "number of samples in group 3351\n",
      "text 0726 captcha shape (32, 100) noise 0.4040234827006345\n",
      "text 4438 captcha shape (32, 100) noise 0.023875197302529745\n",
      "text 8583 captcha shape (32, 100) noise 0.9692096261365313\n",
      "text 0802 captcha shape (32, 100) noise 0.24500947226919484\n",
      "text 1517 captcha shape (32, 100) noise 0.27848232792759553\n",
      "text 3299 captcha shape (32, 100) noise 0.04776158489834244\n",
      "text 3502 captcha shape (32, 100) noise 0.6180701083832694\n",
      "text 3722 captcha shape (32, 100) noise 0.8481661914744177\n",
      "text 9823 captcha shape (32, 100) noise 0.09969025205719692\n",
      "text 3026 captcha shape (32, 100) noise 0.4386122592599272\n",
      "text 0666 captcha shape (32, 100) noise 0.4259731832113945\n",
      "number of samples in group 3247\n",
      "text 66862 captcha shape (32, 100) noise 0.6574669057459912\n",
      "text 25942 captcha shape (32, 100) noise 0.2742616524356861\n",
      "text 23830 captcha shape (32, 100) noise 0.1555592186722\n",
      "text 25175 captcha shape (32, 100) noise 0.021298371806030683\n",
      "text 59857 captcha shape (32, 100) noise 0.2683956313980119\n",
      "text 92244 captcha shape (32, 100) noise 0.5434905525625501\n",
      "text 85878 captcha shape (32, 100) noise 0.7968061069671528\n",
      "text 88427 captcha shape (32, 100) noise 0.46614035863416575\n",
      "text 78397 captcha shape (32, 100) noise 0.12792333095784855\n",
      "text 64072 captcha shape (32, 100) noise 0.7552888815089683\n",
      "text 13633 captcha shape (32, 100) noise 0.3050156248235505\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import numpy as np\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from PIL import Image\n",
    "from claptchagen.claptcha import Claptcha\n",
    "from torch.distributions import constraints\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "print(pyro.__version__)\n",
    "\n",
    "captcha_folder = 'generated_captchas'\n",
    "captchaHeight = 32\n",
    "captchaWidth = 100\n",
    "captchaMarginX = 4\n",
    "captchaMarginY = 4\n",
    "batch_size = 10\n",
    "\n",
    "#char_dict = string.ascii_lowercase\n",
    "char_dict = string.digits\n",
    "USE_CUDA = True\n",
    "MAX_N = 5 # maximum number of letters in a captcha \n",
    "MIN_N = 3 # minimum number of letters in a captcha\n",
    "MIN_NOISE = 0.01 # minimum noise\n",
    "MAX_NOISE = 0.99 # maximum noise\n",
    "smoke_test = False\n",
    "num_steps = 200 if not smoke_test else 10\n",
    "TrainingSample = 10000 if not smoke_test else 100 # number of captchas generated for training\n",
    "\n",
    "def randomString():\n",
    "    \"\"\"\n",
    "    return a string with <num_char> random letters\n",
    "    \"\"\"\n",
    "    k = random.randint(MIN_N, MAX_N) # sample number of characters\n",
    "    \n",
    "    rndLetters = (random.choice(char_dict) for _ in range(k))\n",
    "    \n",
    "    pad_spaces = MAX_N - k # pad the string so the captcha is close to center\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    \n",
    "    return space + \"\".join(rndLetters) + space\n",
    "\n",
    "def ramdomNoise():\n",
    "    \"\"\"\n",
    "    return a float between MIN_NOISE, MAX_NOISE\n",
    "    \"\"\"\n",
    "    return random.uniform(MIN_NOISE, MAX_NOISE)\n",
    "\n",
    "def generate_random_captcha(n, save=False):\n",
    "    \"\"\"\n",
    "    generate n random captchas,\n",
    "    return a list of texts on the captchas\n",
    "    \"\"\"\n",
    "    # Initialize Claptcha object with random text, FreeMono as font, of size\n",
    "    # 100x30px, using bicubic resampling filter and adding a bit of white noise\n",
    "    c = Claptcha(randomString, \"fonts/FreeSans.ttf\", (captchaWidth, captchaHeight), (captchaMarginX, captchaMarginY),\n",
    "             resample=Image.BILINEAR, noise=0)\n",
    "    captcha_generated = [ [] for i in range(MAX_N)]\n",
    "    for i in range(n):\n",
    "        c.noise = ramdomNoise()\n",
    "        if save:\n",
    "            text, _ = c.write(os.path.join(captcha_folder, 'captcha{}.png'.format(i)))\n",
    "            os.rename(os.path.join(captcha_folder, 'captcha{}.png'.format(i)),os.path.join(captcha_folder, '{}.png'.format(text + \"_\" + str(i))))\n",
    "        text, image = c.image\n",
    "        text = text.strip()\n",
    "        image = np.array(image)[:, :, 0] # the generator is gray scale, only keep one channel is enough\n",
    "        captcha_generated[len(text) - 1].append((text, image, c.noise))\n",
    "    return captcha_generated\n",
    "    \n",
    "captcha_generated = generate_random_captcha(TrainingSample, save=False)\n",
    "for lst in captcha_generated:\n",
    "    print(\"number of samples in group\", len(lst))\n",
    "    # print some sample captcha information generated\n",
    "    for i, t in enumerate(lst):\n",
    "        print(\"text\", t[0], \"captcha shape\", t[1].shape, \"noise\", t[2])\n",
    "        if i >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-underwear",
   "metadata": {
    "id": "negative-underwear"
   },
   "outputs": [],
   "source": [
    "def render_image(chars, fonts=\"fonts/FreeSans.ttf\", size=(captchaWidth, captchaHeight), \n",
    "                 margin=(captchaMarginX, captchaMarginY), resample=Image.BILINEAR, noise=0.3, use_cuda=False):\n",
    "    #noise = noise.data.item()\n",
    "    #print(chars, noise)\n",
    "    pad_spaces = MAX_N - len(chars)\n",
    "    space = \" \" * (pad_spaces // 2)\n",
    "    chars = space + chars + space\n",
    "    render = Claptcha(chars, fonts, size, margin, resample=resample, noise=noise)\n",
    "\n",
    "    \n",
    "    _ , rendered_image = render.image\n",
    "    rendered_image = np.array(rendered_image)[:,:,0] # the generator is gray scale, only keep one channel is enough\n",
    "    rendered_image = np.subtract(np.divide(rendered_image, 255), 0.5)\n",
    "    rendered_image = torch.from_numpy(rendered_image)\n",
    "    if use_cuda:\n",
    "        rendered_image = rendered_image.cuda()\n",
    "    return rendered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contrary-lobby",
   "metadata": {
    "id": "contrary-lobby"
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, raw_captchas, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.raw_captchas = raw_captchas\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_captchas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.raw_captchas[idx][0]\n",
    "        image = self.raw_captchas[idx][1]\n",
    "        noise = self.raw_captchas[idx][2]\n",
    "        \n",
    "        image = np.subtract(np.divide(image, 255), 0.5)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return label, image, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "taken-spice",
   "metadata": {
    "id": "taken-spice"
   },
   "outputs": [],
   "source": [
    "def make_loarders(BATCH_SIZE, raw_samples):\n",
    "    dataloaders = [] # dataloaders for different num of char\n",
    "    for lst in raw_samples:\n",
    "        if lst:\n",
    "            ds = CaptchaDataset(lst)\n",
    "            dataloader = DataLoader(ds, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True, num_workers=0, drop_last=True)\n",
    "            dataloaders.append(dataloader)\n",
    "    return dataloaders\n",
    "\n",
    "def make_batches(dataloaders):\n",
    "    all_batches = []\n",
    "    for dl in dataloaders:\n",
    "        for i_batch, sample in enumerate(dl):\n",
    "            all_batches.append(sample)\n",
    "    random.shuffle(all_batches)\n",
    "    random.shuffle(all_batches)\n",
    "    return all_batches\n",
    "\n",
    "TrainLoaders = make_loarders(BATCH_SIZE=batch_size, raw_samples=captcha_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arabic-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, img_size, out_size = 1):\n",
    "        \"\"\"\n",
    "        Network for learning noise in a captcha\n",
    "        \"\"\"\n",
    "        super(NoiseNet, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.fc0 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
    "        self.fc1 = nn.Linear(img_size[0] * img_size[1], 1024)\n",
    "\n",
    "        self.fc21 = nn.Linear(1024, out_size)\n",
    "        self.fc22 = nn.Linear(1024, out_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = img.reshape(-1, self.img_size[0] * self.img_size[1])\n",
    "        hidden = F.relu(self.fc0(img))\n",
    "        hidden = self.fc1(hidden)\n",
    "        # mean of noise, used in normal distribution\n",
    "        mean =  torch.tanh(self.fc21(F.relu(hidden)))\n",
    "        # std used in normal distribution\n",
    "        sigma = self.softplus(self.fc22(F.relu(hidden)))\n",
    "        return mean, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-penguin",
   "metadata": {
    "id": "supposed-penguin"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patient-sunset",
   "metadata": {
    "id": "patient-sunset"
   },
   "outputs": [],
   "source": [
    "class NumNet(nn.Module):\n",
    "    def __init__(self, img_size, out_size = 3):\n",
    "        \"\"\"\n",
    "        Network for learning N, number of letters in a captcha\n",
    "        \"\"\"\n",
    "        super(NumNet, self).__init__()\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(img_size[0] * img_size[1] * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_size),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "  \n",
    "    def forward(self, img):\n",
    "        img = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
    "        prob = self.neural_net(img)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authorized-sender",
   "metadata": {
    "id": "authorized-sender"
   },
   "outputs": [],
   "source": [
    "class CharNetSingle(nn.Module):\n",
    "    def __init__(self, img_size, output_size, hidden_size=512, N_num_class=10, input_size=1024, num_layers=1):\n",
    "        \"\"\"\n",
    "        Network for letters in a captcha, given the noise and number of letters\n",
    "        \"\"\"\n",
    "        super(CharNetSingle, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.N_num_class = N_num_class\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, nonlinearity='relu', dropout=0.2)\n",
    "        \n",
    "        # output proposal layers\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(hidden_size, output_size) for i in range(N_num_class)])\n",
    "\n",
    "        #self.dropout = nn.Dropout()\n",
    "        \n",
    "        # observe layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.pfc1 = nn.Linear(8832, 2048)\n",
    "        self.pfc2 = nn.Linear(2048, 1024)\n",
    "        self.convBN1 = nn.BatchNorm2d(32)\n",
    "        self.convBN2 = nn.BatchNorm2d(64)\n",
    "        self.h_0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "\n",
    "    def forward(self, img, N, noise_batched):\n",
    "        BATCH_SIZE = img.shape[0]\n",
    "        \n",
    "        # observe layers\n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
    "\n",
    "        img = self.pool(F.relu(self.convBN1(self.conv1(img))))\n",
    "        img = self.pool(F.relu(self.convBN2(self.conv2(img))))\n",
    "        \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 8832))\n",
    "\n",
    "        img = F.relu(self.pfc1(img))\n",
    "        \n",
    "        img = F.relu(self.pfc2(img))\n",
    "        \n",
    "        img = torch.reshape(img, (1, BATCH_SIZE, 1024))\n",
    "        \n",
    "        img = img.repeat(N, 1, 1)\n",
    "\n",
    "        x = torch.reshape(img, (N, BATCH_SIZE, self.input_size))\n",
    "\n",
    "        h_0_contig = self.h_0.expand(self.num_layers, BATCH_SIZE, self.hidden_size).contiguous()\n",
    "\n",
    "        outputs, hn = self.rnn(x, h_0_contig)\n",
    "        \n",
    "        # probosal layer, map to output shape\n",
    "        outputs = torch.stack([self.linear_layers[i](outputs[i]) for i in range(outputs.shape[0])])\n",
    "\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        \n",
    "        # transpose to <Batch, Length of Sequence, Character Space>\n",
    "        outputs = torch.transpose(outputs, 0, 1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overhead-meditation",
   "metadata": {
    "id": "overhead-meditation"
   },
   "outputs": [],
   "source": [
    "def inference(t, use_cuda=False):\n",
    "    \"\"\"\n",
    "    one epoch of inference (iterate the training set once)\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    length = TrainingSample\n",
    "    loss_group = []\n",
    "    all_batches = make_batches(TrainLoaders)\n",
    "    for i_batch, sample_batched in enumerate(all_batches):\n",
    "        \n",
    "        img = sample_batched[1]\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        IMG = {\"captcha\" : img}\n",
    "        imme_loss = csis.step(observations=IMG)\n",
    "        loss += imme_loss / length\n",
    "\n",
    "    print(\"loss at epoch {} is {}\".format(t, loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "agreed-provincial",
   "metadata": {
    "id": "agreed-provincial"
   },
   "outputs": [],
   "source": [
    "def test(n = 0, use_train=False, verbose=False, use_cuda=False):\n",
    "    \"\"\"\n",
    "    benchmarking performance on customized or training set\n",
    "    \"\"\"\n",
    "    if use_train:\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
    "    else:\n",
    "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
    "    \n",
    "    total_correct = 0\n",
    "    char_correct = 0\n",
    "    total_char = 0\n",
    "    all_batches = make_batches(TestLoaders)\n",
    "    for i_batch, t in enumerate(all_batches):\n",
    "\n",
    "        label = t[0][0]\n",
    "        gt_noise = t[2][0]\n",
    "        img = t[1]\n",
    "\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        \n",
    "        IMG = {\"captcha\" : img}\n",
    "        \n",
    "        posterior = csis.run(observations=IMG)\n",
    "        marginal_num = pyro.infer.EmpiricalMarginal(posterior, \"num_char\")\n",
    "        marginal_noise = pyro.infer.EmpiricalMarginal(posterior, \"noise\")\n",
    "        marginal_char = pyro.infer.EmpiricalMarginal(posterior, \"chars\")\n",
    "        with torch.no_grad():\n",
    "\n",
    "            N_index = marginal_num()\n",
    "            noise = captchaModel._map_to_noise_range(marginal_noise()[0])\n",
    "            char_indices = marginal_char()[0]\n",
    "        \n",
    "        N = N_index + captchaModel.num_char_domain[0]\n",
    "\n",
    "        if use_cuda:\n",
    "            char_indices.cpu()\n",
    "        chars = \"\"\n",
    "        for i in range(len(char_indices)):\n",
    "            c = char_indices[i]\n",
    "            chars +=  captchaModel.char_dict[c]\n",
    "        correct = 0\n",
    "        \n",
    "        for p_char, t_char in zip(chars, label):\n",
    "            if p_char == t_char:\n",
    "                correct += 1\n",
    "        if not verbose:\n",
    "            print(\"N_predicted:\", int(N), \"| Actual N:\", len(label), \"| Predicted Noise:\", round(float(noise), 3), \"| Actual Noise:\", round(float(gt_noise), 3), \"| Predicted Text:\", chars, \"| Actual Text:\", label, \"| Correct:\", correct)\n",
    "        if correct == len(label) and int(N) == len(label):\n",
    "            total_correct += 1\n",
    "        char_correct += correct\n",
    "        total_char += len(label)\n",
    "    num_test_samples = i_batch + 1\n",
    "    accuracy = total_correct / num_test_samples\n",
    "    char_accuracy = char_correct / total_char\n",
    "    print(\"use_train =\", use_train, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "occupied-invitation",
   "metadata": {
    "id": "occupied-invitation"
   },
   "outputs": [],
   "source": [
    "def test_cycle(use_cuda):\n",
    "    \n",
    "    # disable dropout\n",
    "    #captchaModel.numNet.eval()\n",
    "    #captchaModel.charNetSingle.eval()\n",
    "    test(use_train=True, verbose=True, use_cuda=use_cuda)\n",
    "    test(1000, use_train=False, verbose=True, use_cuda=use_cuda)\n",
    "    #test(10, use_train=True, verbose=False, use_cuda=use_cuda)\n",
    "    test(10, use_train=False, verbose=False, use_cuda=use_cuda)\n",
    "    # enable dropout\n",
    "    #captchaModel.numNet.train()\n",
    "    #captchaModel.charNetSingle.train()\n",
    "\n",
    "def optimize(use_cuda=False):\n",
    "    \"\"\"\n",
    "    Training/Inferencing Stage\n",
    "    \"\"\"\n",
    "    loss_sequence = []\n",
    "    pause = 10\n",
    "    print(\"Optimizing...\")\n",
    "    for t in range(1, num_steps + 1):\n",
    "        L = inference(t, use_cuda)\n",
    "        loss_sequence.append(L)\n",
    "        if (t % pause == 0) and (t > 0):\n",
    "            test_cycle(use_cuda=use_cuda)\n",
    "    plt.plot(loss_sequence)\n",
    "    plt.title(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "composite-secretary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "composite-secretary",
    "outputId": "3bd06fad-f788-49a0-f707-a180bacabbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n",
      "loss at epoch 1 is 7.646132027149205\n",
      "loss at epoch 2 is 5.469611179256439\n",
      "loss at epoch 3 is 4.224119418346879\n",
      "loss at epoch 4 is 3.285399221396442\n",
      "loss at epoch 5 is 2.688474649989603\n",
      "loss at epoch 6 is 2.237982876223324\n",
      "loss at epoch 7 is 1.8871879493981598\n",
      "loss at epoch 8 is 1.605279732901882\n",
      "loss at epoch 9 is 1.4304112135256628\n",
      "loss at epoch 10 is 1.2942204477071233\n",
      "use_train = True Total correct: 2747 accuracy:2747/10000= 0.2747 char_accuracy:28169/39845= 0.7069644873886309\n",
      "use_train = False Total correct: 279 accuracy:279/1000= 0.279 char_accuracy:2798/3978= 0.7033685268979387\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.416 | Actual Noise: 0.391 | Predicted Text: 749 | Actual Text: 749 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.727 | Actual Noise: 0.677 | Predicted Text: 801 | Actual Text: 801 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.769 | Actual Noise: 0.833 | Predicted Text: 20065 | Actual Text: 20065 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.251 | Actual Noise: 0.129 | Predicted Text: 68197 | Actual Text: 68905 | Correct: 2\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.762 | Actual Noise: 0.939 | Predicted Text: 56541 | Actual Text: 55541 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.327 | Actual Noise: 0.334 | Predicted Text: 5486 | Actual Text: 5485 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.76 | Actual Noise: 0.762 | Predicted Text: 1753 | Actual Text: 1763 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.329 | Actual Noise: 0.14 | Predicted Text: 93580 | Actual Text: 94880 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.304 | Actual Noise: 0.024 | Predicted Text: 67509 | Actual Text: 77600 | Correct: 2\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.647 | Actual Noise: 0.692 | Predicted Text: 65952 | Actual Text: 66952 | Correct: 4\n",
      "use_train = False Total correct: 3 accuracy:3/10= 0.3 char_accuracy:32/44= 0.7272727272727273\n",
      "loss at epoch 11 is 1.17360653950585\n",
      "loss at epoch 12 is 1.0382842238845464\n",
      "loss at epoch 13 is 0.9516650081351172\n",
      "loss at epoch 14 is 0.8730637471040537\n",
      "loss at epoch 15 is 0.801689151005082\n",
      "loss at epoch 16 is 0.7266878299155669\n",
      "loss at epoch 17 is 0.6391310373918107\n",
      "loss at epoch 18 is 0.5685165349600628\n",
      "loss at epoch 19 is 0.525261029537046\n",
      "loss at epoch 20 is 0.4430925280899981\n",
      "use_train = True Total correct: 4680 accuracy:4680/10000= 0.468 char_accuracy:32671/39845= 0.8199523152214833\n",
      "use_train = False Total correct: 444 accuracy:444/1000= 0.444 char_accuracy:3316/4042= 0.8203859475507175\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.277 | Actual Noise: 0.085 | Predicted Text: 568 | Actual Text: 368 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.724 | Actual Noise: 0.772 | Predicted Text: 874 | Actual Text: 874 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.494 | Actual Noise: 0.528 | Predicted Text: 140 | Actual Text: 140 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.336 | Actual Noise: 0.914 | Predicted Text: 84731 | Actual Text: 84731 | Correct: 5\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.741 | Actual Noise: 0.836 | Predicted Text: 077 | Actual Text: 077 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.398 | Actual Noise: 0.382 | Predicted Text: 8334 | Actual Text: 8334 | Correct: 4\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.443 | Actual Noise: 0.477 | Predicted Text: 916 | Actual Text: 916 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.544 | Actual Noise: 0.555 | Predicted Text: 04354 | Actual Text: 04361 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.716 | Actual Noise: 0.717 | Predicted Text: 5495 | Actual Text: 6496 | Correct: 2\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.489 | Actual Noise: 0.493 | Predicted Text: 724 | Actual Text: 724 | Correct: 3\n",
      "use_train = False Total correct: 7 accuracy:7/10= 0.7 char_accuracy:31/36= 0.8611111111111112\n",
      "loss at epoch 21 is 0.4139571950408889\n",
      "loss at epoch 22 is 0.3463085258934246\n",
      "loss at epoch 23 is 0.29855658794238576\n",
      "loss at epoch 24 is 0.23767201023492573\n",
      "loss at epoch 25 is 0.18181653305405168\n",
      "loss at epoch 26 is 0.12333188876393335\n",
      "loss at epoch 27 is 0.06865470860242129\n",
      "loss at epoch 28 is -0.02118603293246777\n",
      "loss at epoch 29 is -0.0586259873203788\n",
      "loss at epoch 30 is -0.11015929019948913\n",
      "use_train = True Total correct: 6586 accuracy:6586/10000= 0.6586 char_accuracy:35787/39845= 0.8981553519889572\n",
      "use_train = False Total correct: 686 accuracy:686/1000= 0.686 char_accuracy:3620/3998= 0.9054527263631816\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.645 | Actual Noise: 0.596 | Predicted Text: 739 | Actual Text: 239 | Correct: 2\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.462 | Actual Noise: 0.434 | Predicted Text: 2744 | Actual Text: 2744 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.324 | Actual Noise: 0.21 | Predicted Text: 8955 | Actual Text: 8956 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.844 | Actual Noise: 0.836 | Predicted Text: 12317 | Actual Text: 12367 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.289 | Actual Noise: 0.017 | Predicted Text: 1055 | Actual Text: 1055 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.711 | Actual Noise: 0.791 | Predicted Text: 9023 | Actual Text: 9023 | Correct: 4\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.933 | Actual Noise: 0.816 | Predicted Text: 034 | Actual Text: 034 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.722 | Actual Noise: 0.787 | Predicted Text: 646 | Actual Text: 646 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.448 | Actual Noise: 0.417 | Predicted Text: 95501 | Actual Text: 95504 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.383 | Actual Noise: 0.442 | Predicted Text: 45976 | Actual Text: 45979 | Correct: 4\n",
      "use_train = False Total correct: 5 accuracy:5/10= 0.5 char_accuracy:35/40= 0.875\n",
      "loss at epoch 31 is -0.1446669570928073\n",
      "loss at epoch 32 is -0.17471479060008707\n",
      "loss at epoch 33 is -0.1892153245088022\n",
      "loss at epoch 34 is -0.24612704438757474\n",
      "loss at epoch 35 is -0.2801619580003324\n",
      "loss at epoch 36 is -0.312239314422615\n",
      "loss at epoch 37 is -0.3479767515081698\n",
      "loss at epoch 38 is -0.35115607147644406\n",
      "loss at epoch 39 is -0.3793964680866647\n",
      "loss at epoch 40 is -0.4147277218035202\n",
      "use_train = True Total correct: 7771 accuracy:7771/10000= 0.7771 char_accuracy:37341/39845= 0.9371564813652905\n",
      "use_train = False Total correct: 781 accuracy:781/1000= 0.781 char_accuracy:3752/3998= 0.9384692346173087\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.301 | Actual Noise: 0.017 | Predicted Text: 922 | Actual Text: 922 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.313 | Actual Noise: 0.943 | Predicted Text: 46601 | Actual Text: 46201 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.285 | Actual Noise: 0.156 | Predicted Text: 71456 | Actual Text: 71455 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.426 | Actual Noise: 0.877 | Predicted Text: 3183 | Actual Text: 3193 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.457 | Actual Noise: 0.426 | Predicted Text: 434 | Actual Text: 434 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.264 | Actual Noise: 0.172 | Predicted Text: 995 | Actual Text: 995 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.518 | Actual Noise: 0.497 | Predicted Text: 9716 | Actual Text: 9715 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.568 | Actual Noise: 0.959 | Predicted Text: 916 | Actual Text: 916 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.773 | Actual Noise: 0.778 | Predicted Text: 654 | Actual Text: 654 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.315 | Actual Noise: 0.33 | Predicted Text: 345 | Actual Text: 345 | Correct: 3\n",
      "use_train = False Total correct: 6 accuracy:6/10= 0.6 char_accuracy:32/36= 0.8888888888888888\n",
      "loss at epoch 41 is -0.45841174171989757\n",
      "loss at epoch 42 is -0.47284826089636905\n",
      "loss at epoch 43 is -0.5204762357727086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 44 is -0.5146730407097775\n",
      "loss at epoch 45 is -0.542247487564399\n",
      "loss at epoch 46 is -0.569509466498173\n",
      "loss at epoch 47 is -0.5741104436522987\n",
      "loss at epoch 48 is -0.5818605141298141\n",
      "loss at epoch 49 is -0.6123641027272206\n",
      "loss at epoch 50 is -0.616038865340816\n",
      "use_train = True Total correct: 8217 accuracy:8217/10000= 0.8217 char_accuracy:37911/39845= 0.9514619149203162\n",
      "use_train = False Total correct: 813 accuracy:813/1000= 0.813 char_accuracy:3830/4043= 0.9473163492456097\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.306 | Actual Noise: 0.214 | Predicted Text: 46125 | Actual Text: 46126 | Correct: 4\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.794 | Actual Noise: 0.822 | Predicted Text: 647 | Actual Text: 647 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.419 | Actual Noise: 0.428 | Predicted Text: 6056 | Actual Text: 6056 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.61 | Actual Noise: 0.617 | Predicted Text: 7904 | Actual Text: 7904 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.367 | Actual Noise: 0.356 | Predicted Text: 79208 | Actual Text: 79208 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.26 | Actual Noise: 0.064 | Predicted Text: 54966 | Actual Text: 54965 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.353 | Actual Noise: 0.347 | Predicted Text: 71367 | Actual Text: 71367 | Correct: 5\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.284 | Actual Noise: 0.049 | Predicted Text: 25094 | Actual Text: 25094 | Correct: 5\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.374 | Actual Noise: 0.312 | Predicted Text: 203 | Actual Text: 203 | Correct: 3\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.332 | Actual Noise: 0.184 | Predicted Text: 569 | Actual Text: 569 | Correct: 3\n",
      "use_train = False Total correct: 8 accuracy:8/10= 0.8 char_accuracy:40/42= 0.9523809523809523\n",
      "loss at epoch 51 is -0.6313959768216266\n",
      "loss at epoch 52 is -0.6443333337348298\n",
      "loss at epoch 53 is -0.6764484415586716\n",
      "loss at epoch 54 is -0.6745109578876183\n",
      "loss at epoch 55 is -0.639702212346834\n",
      "loss at epoch 56 is -0.7087588846144676\n",
      "loss at epoch 57 is -0.7141739598552784\n",
      "loss at epoch 58 is -0.7159755952724197\n",
      "loss at epoch 59 is -0.7450682004437241\n",
      "loss at epoch 60 is -0.7411052182397382\n",
      "use_train = True Total correct: 8601 accuracy:8601/10000= 0.8601 char_accuracy:38351/39845= 0.962504705734722\n",
      "use_train = False Total correct: 860 accuracy:860/1000= 0.86 char_accuracy:3816/3962= 0.9631499242806664\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.31 | Actual Noise: 0.273 | Predicted Text: 9506 | Actual Text: 9506 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.326 | Actual Noise: 0.191 | Predicted Text: 53196 | Actual Text: 33195 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.291 | Actual Noise: 0.157 | Predicted Text: 55150 | Actual Text: 55150 | Correct: 5\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.327 | Actual Noise: 0.388 | Predicted Text: 952 | Actual Text: 952 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.275 | Actual Noise: 0.109 | Predicted Text: 2448 | Actual Text: 2448 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.342 | Actual Noise: 0.242 | Predicted Text: 25745 | Actual Text: 25745 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.328 | Actual Noise: 0.25 | Predicted Text: 5725 | Actual Text: 5725 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.252 | Actual Noise: 0.021 | Predicted Text: 93231 | Actual Text: 93231 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.696 | Actual Noise: 0.712 | Predicted Text: 6942 | Actual Text: 6942 | Correct: 4\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.313 | Actual Noise: 0.263 | Predicted Text: 982 | Actual Text: 982 | Correct: 3\n",
      "use_train = False Total correct: 9 accuracy:9/10= 0.9 char_accuracy:40/42= 0.9523809523809523\n",
      "loss at epoch 61 is -0.7633336137748872\n",
      "loss at epoch 62 is -0.7627993846330101\n",
      "loss at epoch 63 is -0.7796041882522099\n",
      "loss at epoch 64 is -0.7808653382099237\n",
      "loss at epoch 65 is -0.8157006402120286\n",
      "loss at epoch 66 is -0.7952372421022028\n",
      "loss at epoch 67 is -0.8286685349262123\n",
      "loss at epoch 68 is -0.8320850411822416\n",
      "loss at epoch 69 is -0.8199661428313234\n",
      "loss at epoch 70 is -0.8392307234670525\n",
      "use_train = True Total correct: 8551 accuracy:8551/10000= 0.8551 char_accuracy:38298/39845= 0.9611745513866231\n",
      "use_train = False Total correct: 849 accuracy:849/1000= 0.849 char_accuracy:3832/3990= 0.9604010025062657\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.493 | Actual Noise: 0.52 | Predicted Text: 234 | Actual Text: 234 | Correct: 3\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.294 | Actual Noise: 0.14 | Predicted Text: 7696 | Actual Text: 7696 | Correct: 4\n",
      "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.693 | Actual Noise: 0.692 | Predicted Text: 977 | Actual Text: 477 | Correct: 2\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.615 | Actual Noise: 0.89 | Predicted Text: 58161 | Actual Text: 58161 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.694 | Actual Noise: 0.812 | Predicted Text: 1911 | Actual Text: 1951 | Correct: 3\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.337 | Actual Noise: 0.215 | Predicted Text: 39271 | Actual Text: 39271 | Correct: 5\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.907 | Actual Noise: 0.954 | Predicted Text: 5363 | Actual Text: 5388 | Correct: 2\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.326 | Actual Noise: 0.083 | Predicted Text: 61666 | Actual Text: 61665 | Correct: 4\n",
      "N_predicted: 4 | Actual N: 4 | Predicted Noise: 0.752 | Actual Noise: 0.74 | Predicted Text: 2002 | Actual Text: 2002 | Correct: 4\n",
      "N_predicted: 5 | Actual N: 5 | Predicted Noise: 0.286 | Actual Noise: 0.049 | Predicted Text: 81943 | Actual Text: 81943 | Correct: 5\n",
      "use_train = False Total correct: 6 accuracy:6/10= 0.6 char_accuracy:37/42= 0.8809523809523809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8426eb52f083>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[0mtest_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3dc889407d51>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(use_cuda)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimizing...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mloss_sequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpause\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-6b4856846cff>\u001b[0m in \u001b[0;36minference\u001b[1;34m(t, use_cuda)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mIMG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"captcha\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mimme_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIMG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mimme_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \"\"\"\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, grads, batch, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparticle_param_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mguide_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_matched_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             batch = (self._sample_from_joint(*args, **kwargs)\n\u001b[0m\u001b[0;32m     99\u001b[0m                      for _ in range(self.training_batch_size))\n\u001b[0;32m    100\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\infer\\csis.py\u001b[0m in \u001b[0;36m_sample_from_joint\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m    197\u001b[0m         \u001b[0munconditioned_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muncondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munconditioned_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \"\"\"\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\poutine\\messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[1;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-8426eb52f083>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mchars\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[0mrendered_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f1445ba574c5>\u001b[0m in \u001b[0;36mrender_image\u001b[1;34m(chars, fonts, size, margin, resample, noise, use_cuda)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# the generator is gray scale, only keep one channel is enough\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mrendered_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\URA\\claptchagen\\claptcha\\claptcha.py\u001b[0m in \u001b[0;36mimage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# Resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   1933\u001b[0m                 )\n\u001b[0;32m   1934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1935\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1937\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    \"\"\"\n",
    "    network, model and guide wrapper class\n",
    "    \"\"\"\n",
    "    def __init__(self, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.num_char_domain = torch.arange(MIN_N, MAX_N + 1)\n",
    "        if use_cuda:\n",
    "            self.num_char_domain = self.num_char_domain.cuda()\n",
    "\n",
    "        self.numNet = NumNet((captchaHeight, captchaWidth), len(self.num_char_domain))\n",
    "        self.noiseNet = NoiseNet((captchaHeight, captchaWidth), 1)\n",
    "        self.char_dict = char_dict # letter dictionary\n",
    "        self.rnn_hidden_size = 512\n",
    "        self.rnn_num_layer = 2\n",
    "        self.charNetSingle = CharNetSingle((captchaHeight, captchaWidth), len(self.char_dict), N_num_class=max(self.num_char_domain), input_size=1024, hidden_size=self.rnn_hidden_size, num_layers=self.rnn_num_layer)\n",
    "        self.noise_constraint = torch.distributions.constraints.interval(MIN_NOISE, MAX_NOISE)\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "    def _map_to_noise_range(self, input):\n",
    "        \"\"\"\n",
    "        map input number to the valid noise range\n",
    "        \"\"\"\n",
    "        input = torch.distributions.transform_to(self.noise_constraint)(input)\n",
    "        return input\n",
    "\n",
    "    def guide(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        pyro.module(\"guide\", self)\n",
    "        img = observations[\"captcha\"].float()\n",
    "        \n",
    "        # posterior to the number of letters\n",
    "        prob = self.numNet(img)\n",
    "        prob = torch.mean(prob, dim=0)\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(prob))\n",
    "        N_index = torch.add(N_index, self.num_char_domain[0])\n",
    "        \n",
    "        with pyro.plate(\"data\", img.shape[0]):\n",
    "            \n",
    "            # posterior to the noise\n",
    "            noise_mean, noise_sig = self.noiseNet(img)\n",
    "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "            \n",
    "            # posterior to the characters, given number of letters and noise\n",
    "            charP = self.charNetSingle(img, N_index, noise_batch)\n",
    "            pyro.sample(\"chars\", dist.Categorical(charP).to_event(1))\n",
    "    \n",
    "    def model(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
    "        \n",
    "        BS = observations[\"captcha\"].shape[0]\n",
    "        \n",
    "        num_p = torch.tensor(1 / len(self.num_char_domain)).repeat(len(self.num_char_domain))\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            num_p = num_p.cuda()\n",
    "        \n",
    "        # sample the number of characters\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(num_p))\n",
    "        N_index = torch.add(N_index,  self.num_char_domain[0])\n",
    "        \n",
    "        with pyro.plate(\"data\", BS):\n",
    "            \n",
    "            noise_mean = torch.tensor((MAX_NOISE - MIN_NOISE) / 2).repeat((BS, 1))\n",
    "            noise_sig = torch.tensor(0.5).repeat((BS, 1))\n",
    "\n",
    "            if self.use_cuda:\n",
    "                noise_mean = noise_mean.cuda()\n",
    "                noise_sig = noise_sig.cuda()\n",
    "\n",
    "            # sample the noise\n",
    "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
    "            noise_batch = self._map_to_noise_range(noise_batch)\n",
    "\n",
    "            num_c = torch.tensor(1 / len(self.char_dict)).repeat((BS, N_index, len(self.char_dict)))\n",
    "            if self.use_cuda:\n",
    "                    num_c = num_c.cuda()\n",
    "                    \n",
    "            # sample the character indices\n",
    "            c = pyro.sample(\"chars\", dist.Categorical(num_c).to_event(1)) # maybe 2 here\n",
    "            rendered_images = []\n",
    "            for i in range(c.shape[0]):\n",
    "                chars = \"\"\n",
    "                for j in range(N_index):\n",
    "                    chars += self.char_dict[c[i][j]]\n",
    "        \n",
    "                rendered_image = render_image(chars, noise=float(noise_batch[i]), use_cuda=self.use_cuda)\n",
    "                rendered_images.append(rendered_image)\n",
    "                \n",
    "        rendered_images = torch.stack(rendered_images)\n",
    "        sigma = torch.tensor(0.000001)\n",
    "        if self.use_cuda:\n",
    "                sigma = sigma.cuda()\n",
    "\n",
    "        pyro.sample(\"captcha\", dist.Normal(rendered_images, sigma).to_event(2), obs=observations[\"captcha\"])\n",
    "\n",
    "captchaModel = CaptchaModel(USE_CUDA)\n",
    "\n",
    "optimiser = pyro.optim.Adam({'lr': 5e-5})\n",
    "csis = pyro.infer.CSIS(captchaModel.model, captchaModel.guide, optimiser, num_inference_samples=1)\n",
    "\n",
    "\n",
    "optimize(USE_CUDA)\n",
    "test_cycle(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-sister",
   "metadata": {
    "id": "swiss-sister"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-difficulty",
   "metadata": {
    "id": "genetic-difficulty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-territory",
   "metadata": {
    "id": "lovely-territory"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Captcha-Simple-CSIS-CUDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
