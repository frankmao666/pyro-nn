{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Captcha_SVI_CUDA_Clean_IS_Copy2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arranged-collective"
      },
      "source": [
        "uncomment if executing in google colab"
      ],
      "id": "arranged-collective"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "statutory-shopper",
        "outputId": "11e7db0d-6ddf-4234-f632-4d5badd7673c"
      },
      "source": [
        "! pip uninstall pyro-ppl\n",
        "! pip install pyro-ppl==1.5.1\n",
        "! unzip fonts.zip \n",
        "! unzip claptchagen.zip\n",
        "! unzip csis\n",
        "! cp csis.py /usr/local/lib/python3.7/dist-packages/pyro/infer"
      ],
      "id": "statutory-shopper",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping pyro-ppl as it is not installed.\u001b[0m\n",
            "Collecting pyro-ppl==1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/6c/60e3d9c258d0a145013e7b88d667879ac7ae131c3dd30bb5971548f101bb/pyro_ppl-1.5.1-py3-none-any.whl (607kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.5.1) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.5.1) (1.19.5)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.5.1) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.5.1) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pyro-ppl==1.5.1) (3.7.4.3)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.5.1\n",
            "Archive:  fonts.zip\n",
            "   creating: fonts/\n",
            "  inflating: fonts/FreeMono.ttf      \n",
            "  inflating: fonts/FreeSans.ttf      \n",
            "Archive:  claptchagen.zip\n",
            "   creating: claptchagen/\n",
            " extracting: claptchagen/.gitignore  \n",
            "   creating: claptchagen/claptcha/\n",
            "  inflating: claptchagen/claptcha/claptcha.py  \n",
            "  inflating: claptchagen/claptcha/__init__.py  \n",
            "   creating: claptchagen/claptcha/__pycache__/\n",
            "  inflating: claptchagen/claptcha/__pycache__/claptcha.cpython-38.pyc  \n",
            "  inflating: claptchagen/claptcha/__pycache__/__init__.cpython-38.pyc  \n",
            "   creating: claptchagen/examples/\n",
            "  inflating: claptchagen/examples/claptcha-noise.png  \n",
            "  inflating: claptchagen/examples/claptcha1.png  \n",
            "  inflating: claptchagen/examples/claptcha2.png  \n",
            "  inflating: claptchagen/LICENSE     \n",
            "  inflating: claptchagen/README.md   \n",
            "  inflating: claptchagen/setup.py    \n",
            "Archive:  csis.zip\n",
            "  inflating: csis.py                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "intimate-postage",
        "outputId": "50711e7e-bfb3-41ae-d407-72445a77f110"
      },
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pyro\n",
        "import numpy as np\n",
        "import pyro.optim as optim\n",
        "import pyro.distributions as dist\n",
        "import pyro.infer\n",
        "import pyro.optim\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
        "from PIL import Image\n",
        "from claptchagen.claptcha import Claptcha\n",
        "from torch.distributions import constraints\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "print(pyro.__version__)\n",
        "\n",
        "captcha_folder = 'generated_captchas'\n",
        "captchaHeight = 32\n",
        "captchaWidth = 100\n",
        "captchaMarginX = 4\n",
        "captchaMarginY = 4\n",
        "batch_size = 10\n",
        "\n",
        "#char_dict = string.ascii_lowercase\n",
        "char_dict = string.digits\n",
        "#char_dict = \"abc\"\n",
        "USE_CUDA = True\n",
        "MAX_N = 3 # maximum number of letters in a captcha \n",
        "MIN_N = 1 # minimum number of letters in a captcha\n",
        "MIN_NOISE = 0.01 # minimum noise\n",
        "MAX_NOISE = 0.99 # maximum noise\n",
        "smoke_test = False\n",
        "num_steps = 1000 if not smoke_test else 10\n",
        "TrainingSample = 5000 if not smoke_test else 100 # number of captchas generated for training\n",
        "\n",
        "def randomString():\n",
        "    \"\"\"\n",
        "    return a string with <num_char> random letters\n",
        "    \"\"\"\n",
        "    k = random.randint(MIN_N, MAX_N) # sample number of characters\n",
        "    \n",
        "    rndLetters = (random.choice(char_dict) for _ in range(k))\n",
        "    \n",
        "    pad_spaces = MAX_N - k # pad the string so the captcha is close to center\n",
        "    space = \" \" * (pad_spaces // 2)\n",
        "    \n",
        "    return space + \"\".join(rndLetters) + space\n",
        "\n",
        "def ramdomNoise():\n",
        "    \"\"\"\n",
        "    return a float between MIN_NOISE, MAX_NOISE\n",
        "    \"\"\"\n",
        "    return random.uniform(MIN_NOISE, MAX_NOISE)\n",
        "\n",
        "def generate_random_captcha(n, save=False):\n",
        "    \"\"\"\n",
        "    generate n random captchas,\n",
        "    return a list of texts on the captchas\n",
        "    \"\"\"\n",
        "    # Initialize Claptcha object with random text, FreeMono as font, of size\n",
        "    # 100x30px, using bicubic resampling filter and adding a bit of white noise\n",
        "    c = Claptcha(randomString, \"fonts/FreeSans.ttf\", (captchaWidth, captchaHeight), (captchaMarginX, captchaMarginY),\n",
        "             resample=Image.BILINEAR, noise=0)\n",
        "    captcha_generated = [ [] for i in range(MAX_N)]\n",
        "    for i in range(n):\n",
        "        c.noise = ramdomNoise()\n",
        "        if save:\n",
        "            text, _ = c.write(os.path.join(captcha_folder, 'captcha{}.png'.format(i)))\n",
        "            os.rename(os.path.join(captcha_folder, 'captcha{}.png'.format(i)),os.path.join(captcha_folder, '{}.png'.format(text + \"_\" + str(i))))\n",
        "        text, image = c.image\n",
        "        text = text.strip()\n",
        "        image = np.array(image)[:, :, 0] # the generator is gray scale, only keep one channel is enough\n",
        "        captcha_generated[len(text) - 1].append((text, image, c.noise))\n",
        "    return captcha_generated\n",
        "    \n",
        "captcha_generated = generate_random_captcha(TrainingSample, save=False)\n",
        "for lst in captcha_generated:\n",
        "    print(\"number of samples in group\", len(lst))\n",
        "    # print some sample captcha information generated\n",
        "    for i, t in enumerate(lst):\n",
        "        print(\"text\", t[0], \"captcha shape\", t[1].shape, \"noise\", t[2])\n",
        "        if i >= 10:\n",
        "            break"
      ],
      "id": "intimate-postage",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1\n",
            "number of samples in group 1709\n",
            "text 4 captcha shape (32, 100) noise 0.9432912456753579\n",
            "text 7 captcha shape (32, 100) noise 0.8003251122539908\n",
            "text 1 captcha shape (32, 100) noise 0.7643297603633865\n",
            "text 1 captcha shape (32, 100) noise 0.5912592071384082\n",
            "text 2 captcha shape (32, 100) noise 0.143579775904275\n",
            "text 8 captcha shape (32, 100) noise 0.401533300305846\n",
            "text 7 captcha shape (32, 100) noise 0.6789588296347708\n",
            "text 2 captcha shape (32, 100) noise 0.35719787152570415\n",
            "text 4 captcha shape (32, 100) noise 0.7936610460060156\n",
            "text 1 captcha shape (32, 100) noise 0.9357264835466635\n",
            "text 9 captcha shape (32, 100) noise 0.8997307057600851\n",
            "number of samples in group 1611\n",
            "text 41 captcha shape (32, 100) noise 0.9188828086969897\n",
            "text 92 captcha shape (32, 100) noise 0.11615353722111252\n",
            "text 94 captcha shape (32, 100) noise 0.07250533932740745\n",
            "text 56 captcha shape (32, 100) noise 0.8752016120638614\n",
            "text 54 captcha shape (32, 100) noise 0.7054467607743158\n",
            "text 31 captcha shape (32, 100) noise 0.20272560347529764\n",
            "text 62 captcha shape (32, 100) noise 0.9658657849959568\n",
            "text 06 captcha shape (32, 100) noise 0.12577415544256673\n",
            "text 38 captcha shape (32, 100) noise 0.12904193627829497\n",
            "text 28 captcha shape (32, 100) noise 0.4122860586082363\n",
            "text 02 captcha shape (32, 100) noise 0.40642899244130803\n",
            "number of samples in group 1680\n",
            "text 595 captcha shape (32, 100) noise 0.23874103450836842\n",
            "text 096 captcha shape (32, 100) noise 0.8406316238740009\n",
            "text 030 captcha shape (32, 100) noise 0.5542419514969953\n",
            "text 901 captcha shape (32, 100) noise 0.3756507322748741\n",
            "text 803 captcha shape (32, 100) noise 0.4049017104371931\n",
            "text 958 captcha shape (32, 100) noise 0.23624032282806226\n",
            "text 956 captcha shape (32, 100) noise 0.8690973039664006\n",
            "text 544 captcha shape (32, 100) noise 0.8441084652079155\n",
            "text 377 captcha shape (32, 100) noise 0.7821027210253064\n",
            "text 738 captcha shape (32, 100) noise 0.5331162381286699\n",
            "text 673 captcha shape (32, 100) noise 0.7245511521704809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "negative-underwear"
      },
      "source": [
        "def render_image(chars, fonts=\"fonts/FreeSans.ttf\", size=(captchaWidth, captchaHeight), \n",
        "                 margin=(captchaMarginX, captchaMarginY), resample=Image.BILINEAR, noise=0.3, use_cuda=False):\n",
        "    #noise = noise.data.item()\n",
        "    #print(chars, noise)\n",
        "    pad_spaces = MAX_N - len(chars)\n",
        "    space = \" \" * (pad_spaces // 2)\n",
        "    chars = space + chars + space\n",
        "    render = Claptcha(chars, fonts, size, margin, resample=resample, noise=noise)\n",
        "\n",
        "    \n",
        "    _ , rendered_image = render.image\n",
        "    rendered_image = np.array(rendered_image)[:,:,0] # the generator is gray scale, only keep one channel is enough\n",
        "    rendered_image = np.subtract(np.divide(rendered_image, 255), 0.5)\n",
        "    rendered_image = torch.from_numpy(rendered_image)\n",
        "    if use_cuda:\n",
        "        rendered_image = rendered_image.cuda()\n",
        "    return rendered_image"
      ],
      "id": "negative-underwear",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "contrary-lobby"
      },
      "source": [
        "class CaptchaDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, raw_captchas, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.raw_captchas = raw_captchas\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_captchas)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.raw_captchas[idx][0]\n",
        "        image = self.raw_captchas[idx][1]\n",
        "        noise = self.raw_captchas[idx][2]\n",
        "        \n",
        "        image = np.subtract(np.divide(image, 255), 0.5)\n",
        "        image = torch.from_numpy(image).float()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return label, image, noise"
      ],
      "id": "contrary-lobby",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taken-spice"
      },
      "source": [
        "def make_loarders(BATCH_SIZE, raw_samples):\n",
        "    dataloaders = [] # dataloaders for different num of char\n",
        "    for lst in raw_samples:\n",
        "        if lst:\n",
        "            ds = CaptchaDataset(lst)\n",
        "            dataloader = DataLoader(ds, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True, num_workers=0, drop_last=True)\n",
        "            dataloaders.append(dataloader)\n",
        "    return dataloaders\n",
        "\n",
        "def make_batches(dataloaders):\n",
        "    all_batches = []\n",
        "    for dl in dataloaders:\n",
        "        for i_batch, sample in enumerate(dl):\n",
        "            all_batches.append(sample)\n",
        "    random.shuffle(all_batches)\n",
        "    random.shuffle(all_batches)\n",
        "    return all_batches\n",
        "\n",
        "TrainLoaders = make_loarders(BATCH_SIZE=batch_size, raw_samples=captcha_generated)"
      ],
      "id": "taken-spice",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arabic-rocket"
      },
      "source": [
        "class NoiseNet(nn.Module):\n",
        "\n",
        "    def __init__(self, img_size, out_size = 1):\n",
        "        \"\"\"\n",
        "        Network for learning noise in a captcha\n",
        "        \"\"\"\n",
        "        super(NoiseNet, self).__init__()\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.fc0 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1])\n",
        "        self.fc1 = nn.Linear(img_size[0] * img_size[1], 1024)\n",
        "\n",
        "        self.fc21 = nn.Linear(1024, out_size)\n",
        "        self.fc22 = nn.Linear(1024, out_size)\n",
        "        self.softplus = nn.Softplus()\n",
        "    \n",
        "    def forward(self, img):\n",
        "        img = img.reshape(-1, self.img_size[0] * self.img_size[1])\n",
        "        hidden = F.relu(self.fc0(img))\n",
        "        hidden = self.fc1(hidden)\n",
        "        # mean of noise, used in normal distribution\n",
        "        mean =  torch.tanh(self.fc21(F.relu(hidden)))\n",
        "        # std used in normal distribution\n",
        "        sigma = self.softplus(self.fc22(F.relu(hidden)))\n",
        "        return mean, sigma"
      ],
      "id": "arabic-rocket",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "supposed-penguin"
      },
      "source": [
        ""
      ],
      "id": "supposed-penguin",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "patient-sunset"
      },
      "source": [
        "class NumNet(nn.Module):\n",
        "    def __init__(self, img_size, out_size = 3):\n",
        "        \"\"\"\n",
        "        Network for learning N, number of letters in a captcha\n",
        "        \"\"\"\n",
        "        super(NumNet, self).__init__()\n",
        "        self.neural_net = nn.Sequential(\n",
        "            nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(img_size[0] * img_size[1] * 2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, out_size),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "  \n",
        "    def forward(self, img):\n",
        "        img = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
        "        prob = self.neural_net(img)\n",
        "        return prob"
      ],
      "id": "patient-sunset",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "authorized-sender"
      },
      "source": [
        "class CharNetSingle(nn.Module):\n",
        "    def __init__(self, img_size, output_size, hidden_size=512, N_num_class=10, input_size=1024, num_layers=1):\n",
        "        \"\"\"\n",
        "        Network for letters in a captcha, given the noise and number of letters\n",
        "        \"\"\"\n",
        "        super(CharNetSingle, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.N_num_class = N_num_class\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, nonlinearity='relu', dropout=0.2)\n",
        "        \n",
        "        # output proposal layers\n",
        "        self.linear_layers = nn.ModuleList([nn.Linear(hidden_size, output_size) for i in range(N_num_class)])\n",
        "\n",
        "        #self.dropout = nn.Dropout()\n",
        "        \n",
        "        # observe layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.pfc1 = nn.Linear(8832, 2048)\n",
        "        self.pfc2 = nn.Linear(2048, 1024)\n",
        "        self.convBN1 = nn.BatchNorm2d(32)\n",
        "        self.convBN2 = nn.BatchNorm2d(64)\n",
        "        self.h_0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
        "        #self.c_0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size)) # define if use LSTM\n",
        "\n",
        "    def forward(self, img, N, noise_batched):\n",
        "        BATCH_SIZE = img.shape[0]\n",
        "        i = torch.arange(0, int(N))\n",
        "        if USE_CUDA:\n",
        "            i = i.cuda()\n",
        "        i_onehot = F.one_hot(i, num_classes=self.N_num_class).float() # one hot format of N and index of letter\n",
        "        i_onehot = torch.reshape(i_onehot, (N, 1, self.N_num_class)).repeat(1, BATCH_SIZE, 1)\n",
        "        N_onehot = F.one_hot(N-1, num_classes=self.N_num_class).repeat(N, BATCH_SIZE, 1).float()\n",
        "        \n",
        "        # observe layers\n",
        "        img = torch.reshape(img, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
        "\n",
        "        img = self.pool(F.relu(self.convBN1(self.conv1(img))))\n",
        "        img = self.pool(F.relu(self.convBN2(self.conv2(img))))\n",
        "        \n",
        "        img = torch.reshape(img, (BATCH_SIZE, 8832))\n",
        "\n",
        "        img = F.relu(self.pfc1(img))\n",
        "        \n",
        "        img = F.relu(self.pfc2(img))\n",
        "        \n",
        "        img = torch.reshape(img, (1, BATCH_SIZE, 1024))\n",
        "        \n",
        "        img = img.repeat(N, 1, 1)\n",
        "        \n",
        "        # cat observed images, N, i and noise \n",
        "        noise_batched = noise_batched.repeat(N, 1, 1)\n",
        "\n",
        "        x = torch.cat((img, N_onehot, i_onehot, noise_batched), dim=2)\n",
        "        x = torch.reshape(x, (N, BATCH_SIZE, self.input_size))\n",
        "\n",
        "        h_0_contig = self.h_0.expand(self.num_layers, BATCH_SIZE, self.hidden_size).contiguous()\n",
        "\n",
        "        outputs, hn = self.rnn(x, h_0_contig)\n",
        "        \n",
        "        # probosal layer, map to output shape\n",
        "        outputs = torch.stack([self.linear_layers[i](outputs[i]) for i in range(outputs.shape[0])])\n",
        "\n",
        "        outputs = F.log_softmax(outputs, dim=2)\n",
        "        \n",
        "        # transpose to <Batch, Length of Sequence, Character Space>\n",
        "        outputs = torch.transpose(outputs, 0, 1)\n",
        "        \n",
        "        return outputs"
      ],
      "id": "authorized-sender",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "overhead-meditation"
      },
      "source": [
        "def inference(t, use_cuda=False):\n",
        "    \"\"\"\n",
        "    one epoch of inference (iterate the training set once)\n",
        "    \"\"\"\n",
        "    loss = 0\n",
        "    length = TrainingSample\n",
        "    loss_group = []\n",
        "    all_batches = make_batches(TrainLoaders)\n",
        "    for i_batch, sample_batched in enumerate(all_batches):\n",
        "        \n",
        "        img = sample_batched[1]\n",
        "        if use_cuda:\n",
        "            img = img.cuda()\n",
        "        IMG = {\"captcha\" : img}\n",
        "        imme_loss = svi.step(observations=IMG)\n",
        "        loss += imme_loss / length\n",
        "\n",
        "    print(\"loss at epoch {} is {}\".format(t, loss))\n",
        "    return loss"
      ],
      "id": "overhead-meditation",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agreed-provincial"
      },
      "source": [
        "def test_old(n = 0, use_train=False, verbose=False, use_cuda=False):\n",
        "    \"\"\"\n",
        "    benchmarking performance on customized or training set\n",
        "    \"\"\"\n",
        "    if use_train:\n",
        "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
        "    else:\n",
        "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
        "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
        "    \n",
        "    total_correct = 0\n",
        "    char_correct = 0\n",
        "    total_char = 0\n",
        "    all_batches = make_batches(TestLoaders)\n",
        "    for i_batch, t in enumerate(all_batches):\n",
        "\n",
        "        label = t[0][0]\n",
        "        gt_noise = t[2][0]\n",
        "        img = t[1]\n",
        "\n",
        "        if use_cuda:\n",
        "            img = img.cuda()\n",
        "        \n",
        "        IMG = {\"captcha\" : img}\n",
        "        \n",
        "        num_p = captchaModel.numNet(img)\n",
        "        N = dist.Categorical(num_p[0]).sample()\n",
        "        N = torch.add(N, captchaModel.num_char_domain[0])\n",
        "        #sig = torch.tensor(0.0001)\n",
        "        #h0 = dist.Normal(N_predicted/max(captchaModel.num_char_domain), sig).sample(torch.Size((len(captchaModel.char_dict) * captchaModel.rnn_num_layer,)))\n",
        "        noise_mean, noise_sig = captchaModel.noiseNet(img)\n",
        "        noise = dist.Normal(noise_mean, noise_sig).sample()\n",
        "        noise = captchaModel._map_to_noise_range(noise)\n",
        "        \n",
        "        charP = captchaModel.charNetSingle(img, N, noise)\n",
        "        \n",
        "        charP = charP[0]\n",
        "        if use_cuda:\n",
        "            charP.cpu()\n",
        "        \n",
        "        chars = \"\"\n",
        "        for i in range(N):\n",
        "            cp = charP[i]\n",
        "            c_index = int(dist.Categorical(cp).sample())\n",
        "            chars += captchaModel.char_dict[c_index]\n",
        "        correct = 0\n",
        "        \n",
        "        for p_char, t_char in zip(chars, label):\n",
        "            if p_char == t_char:\n",
        "                correct += 1\n",
        "        if not verbose:\n",
        "            print(\"N_predicted:\", int(N), \"| Actual N:\", len(label), \"| Predicted Noise:\", round(float(noise), 3), \"| Actual Noise:\", round(float(gt_noise), 3), \"| Predicted Text:\", chars, \"| Actual Text:\", label, \"| Correct:\", correct)\n",
        "        if correct == len(label) and int(N) == len(label):\n",
        "            total_correct += 1\n",
        "        char_correct += correct\n",
        "        total_char += len(label)\n",
        "    num_test_samples = i_batch + 1\n",
        "    accuracy = total_correct / num_test_samples\n",
        "    char_accuracy = char_correct / total_char\n",
        "    print(\"use_train =\", use_train, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
      ],
      "id": "agreed-provincial",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "combined-simpson"
      },
      "source": [
        "import numbers\n",
        "class PadEmpiricalMarginal(pyro.infer.EmpiricalMarginal):\n",
        "    \"\"\"\n",
        "    this class is used for sampling character lists\n",
        "    we will need to pad the sampled character lsits because they may not have the same length\n",
        "    \"\"\"\n",
        "    def __init__(self, trace_posterior, max_shape, use_cuda, sites=None, validate_args=None):\n",
        "        self.max_shape = max_shape\n",
        "        self.use_cuda = use_cuda\n",
        "        super().__init__(trace_posterior, sites, validate_args)\n",
        "    def _add_sample(self, value, log_weight=None, chain_id=0):\n",
        "        # Apply default weight of 1.0.\n",
        "        if log_weight is None:\n",
        "            log_weight = 0.0\n",
        "        if self._validate_args and not isinstance(log_weight, numbers.Number) and log_weight.dim() > 0:\n",
        "            raise ValueError(\"``weight.dim() > 0``, but weight should be a scalar.\")\n",
        "    \n",
        "        # pad the sample with -1, so sample will have the same shape\n",
        "        new_val = torch.negative(torch.ones(1, self.max_shape))\n",
        "        if self.use_cuda:\n",
        "            new_val.cuda()\n",
        "        new_val[:,:value.shape[1]] = value\n",
        "        # Append to the buffer list\n",
        "        self._samples_buffer[chain_id].append(new_val)\n",
        "        self._weights_buffer[chain_id].append(log_weight)\n",
        "        self._num_chains = max(self._num_chains, chain_id + 1)"
      ],
      "id": "combined-simpson",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crazy-freedom"
      },
      "source": [
        "def test(n = 0, use_train=False, verbose=False, use_cuda=False, is_num_samples=100):\n",
        "    \"\"\"\n",
        "    benchmarking performance on customized or training set\n",
        "    \"\"\"\n",
        "    if use_train:\n",
        "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
        "    else:\n",
        "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
        "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
        "    \n",
        "    total_correct = 0\n",
        "    char_correct = 0\n",
        "    total_char = 0\n",
        "    all_batches = make_batches(TestLoaders)\n",
        "    Importance_model = pyro.infer.Importance(captchaModel.model, captchaModel.guide, num_samples=is_num_samples)\n",
        "    print(\"IS num_samples:\", is_num_samples)\n",
        "    for i_batch, t in enumerate(all_batches):\n",
        "\n",
        "        label = t[0][0]\n",
        "        gt_noise = t[2][0]\n",
        "        img = t[1]\n",
        "\n",
        "        if use_cuda:\n",
        "            img = img.cuda()\n",
        "        \n",
        "        IMG = {\"captcha\" : img}\n",
        "        \n",
        "        posterior = Importance_model.run(observations=IMG)\n",
        "        marginal_num = pyro.infer.EmpiricalMarginal(posterior, \"num_char\")\n",
        "        marginal_noise = pyro.infer.EmpiricalMarginal(posterior, \"noise\")\n",
        "        marginal_char = PadEmpiricalMarginal(posterior, MAX_N, use_cuda, \"chars\")\n",
        "        with torch.no_grad():\n",
        "\n",
        "            N_index = marginal_num()\n",
        "            noise = captchaModel._map_to_noise_range(marginal_noise()[0])\n",
        "            char_indices = marginal_char()[0]\n",
        "        \n",
        "        N = N_index + captchaModel.num_char_domain[0]\n",
        "\n",
        "        if use_cuda:\n",
        "            char_indices.cpu()\n",
        "        #print(\"char_indices\", char_indices)\n",
        "        chars = \"\"\n",
        "        for i in range(len(char_indices)):\n",
        "            c = int(char_indices[i])\n",
        "            #print(\"c, i\", c, i)\n",
        "            if c < 0:\n",
        "                break\n",
        "            chars +=  captchaModel.char_dict[c]\n",
        "        correct = 0\n",
        "        \n",
        "        for p_char, t_char in zip(chars, label):\n",
        "            if p_char == t_char:\n",
        "                correct += 1\n",
        "        if not verbose:\n",
        "            print(\"N_predicted:\", int(N), \"| Actual N:\", len(label), \"| Predicted Noise:\", round(float(noise), 3), \"| Actual Noise:\", round(float(gt_noise), 3), \"| Predicted Text:\", chars, \"| Actual Text:\", label, \"| Correct:\", correct)\n",
        "        if correct == len(label) and int(N) == len(label):\n",
        "            total_correct += 1\n",
        "        char_correct += correct\n",
        "        total_char += len(label)\n",
        "    num_test_samples = i_batch + 1\n",
        "    accuracy = total_correct / num_test_samples\n",
        "    char_accuracy = char_correct / total_char\n",
        "    print(\"use_train =\", use_train, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
      ],
      "id": "crazy-freedom",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occupied-invitation"
      },
      "source": [
        "def test_cycle(use_cuda):\n",
        "    \n",
        "    # disable dropout\n",
        "    captchaModel.numNet.eval()\n",
        "    captchaModel.charNetSingle.eval()\n",
        "    captchaModel.noiseNet.eval()\n",
        "    print(\"directly sampling from guide:\")\n",
        "    #test_old(use_train=True, verbose=True, use_cuda=use_cuda)\n",
        "    test_old(1000, use_train=False, verbose=True, use_cuda=use_cuda)\n",
        "    print(\"use Imporant Sampling:\")\n",
        "    #test(use_train=True, verbose=True, use_cuda=use_cuda)\n",
        "    test(500, use_train=False, verbose=True, use_cuda=use_cuda, is_num_samples=500)\n",
        "    test(500, use_train=False, verbose=True, use_cuda=use_cuda, is_num_samples=300)\n",
        "    test(500, use_train=False, verbose=True, use_cuda=use_cuda, is_num_samples=100)\n",
        "    #test(10, use_train=True, verbose=False, use_cuda=use_cuda)\n",
        "    test(10, use_train=False, verbose=False, use_cuda=use_cuda)\n",
        "    # enable dropout\n",
        "    captchaModel.numNet.train()\n",
        "    captchaModel.charNetSingle.train()\n",
        "    captchaModel.noiseNet.train()\n",
        "\n",
        "def optimize(use_cuda=False):\n",
        "    \"\"\"\n",
        "    Training/Inferencing Stage\n",
        "    \"\"\"\n",
        "    loss_sequence = []\n",
        "    pause = 100\n",
        "    print(\"Optimizing...\")\n",
        "    for t in range(1, num_steps + 1):\n",
        "        L = inference(t, use_cuda)\n",
        "        loss_sequence.append(L)\n",
        "        if (t % pause == 0) and (t > 0):\n",
        "            test_cycle(use_cuda=use_cuda)\n",
        "    plt.plot(loss_sequence)\n",
        "    plt.title(\"loss\")\n",
        "    plt.show()"
      ],
      "id": "occupied-invitation",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "composite-secretary",
        "outputId": "bb290559-7909-4c9a-fd60-6eadcb51c32f"
      },
      "source": [
        "class CaptchaModel(nn.Module):\n",
        "    \"\"\"\n",
        "    network, model and guide wrapper class\n",
        "    \"\"\"\n",
        "    def __init__(self, use_cuda=False):\n",
        "        super().__init__()\n",
        "        self.num_char_domain = torch.arange(MIN_N, MAX_N + 1)\n",
        "        if use_cuda:\n",
        "            self.num_char_domain = self.num_char_domain.cuda()\n",
        "\n",
        "        self.numNet = NumNet((captchaHeight, captchaWidth), len(self.num_char_domain))\n",
        "        self.noiseNet = NoiseNet((captchaHeight, captchaWidth), 1)\n",
        "        self.char_dict = char_dict # letter dictionary\n",
        "        self.rnn_hidden_size = 512\n",
        "        self.rnn_num_layer = 2\n",
        "        self.charNetSingle = CharNetSingle((captchaHeight, captchaWidth), len(self.char_dict), N_num_class=max(self.num_char_domain), input_size=1024 + max(self.num_char_domain) * 2 + 1, hidden_size=self.rnn_hidden_size, num_layers=self.rnn_num_layer)\n",
        "        self.noise_constraint = torch.distributions.constraints.interval(MIN_NOISE, MAX_NOISE)\n",
        "        if use_cuda:\n",
        "            self.cuda()\n",
        "        self.use_cuda = use_cuda\n",
        "    \n",
        "    def _map_to_noise_range(self, input):\n",
        "        \"\"\"\n",
        "        map input number to the valid noise range\n",
        "        \"\"\"\n",
        "        input = torch.distributions.transform_to(self.noise_constraint)(input)\n",
        "        return input\n",
        "\n",
        "    def guide(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
        "        pyro.module(\"guide\", self)\n",
        "        img = observations[\"captcha\"].float()\n",
        "        \n",
        "        # posterior to the number of letters\n",
        "        prob = self.numNet(img)\n",
        "        prob = torch.mean(prob, dim=0)\n",
        "        N_index = pyro.sample(\"num_char\", dist.Categorical(prob))\n",
        "        N_index = torch.add(N_index, self.num_char_domain[0])\n",
        "        \n",
        "        with pyro.plate(\"data\", img.shape[0]):\n",
        "            \n",
        "            # posterior to the noise\n",
        "            noise_mean, noise_sig = self.noiseNet(img)\n",
        "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
        "            noise_batch = self._map_to_noise_range(noise_batch)\n",
        "            \n",
        "            # posterior to the characters, given number of letters and noise\n",
        "            charP = self.charNetSingle(img, N_index, noise_batch)\n",
        "            pyro.sample(\"chars\", dist.Categorical(charP).to_event(1))\n",
        "    \n",
        "    def model(self, observations={\"captcha\": torch.rand(1, captchaHeight, captchaWidth)}):\n",
        "        \n",
        "        BS = observations[\"captcha\"].shape[0]\n",
        "        \n",
        "        num_p = torch.tensor(1 / len(self.num_char_domain)).repeat(len(self.num_char_domain))\n",
        "        \n",
        "        if self.use_cuda:\n",
        "            num_p = num_p.cuda()\n",
        "        \n",
        "        # sample the number of characters\n",
        "        N_index = pyro.sample(\"num_char\", dist.Categorical(num_p))\n",
        "        N_index = torch.add(N_index,  self.num_char_domain[0])\n",
        "        \n",
        "        with pyro.plate(\"data\", BS):\n",
        "            \n",
        "            noise_mean = torch.tensor((MAX_NOISE - MIN_NOISE) / 2).repeat((BS, 1))\n",
        "            noise_sig = torch.tensor(0.5).repeat((BS, 1))\n",
        "\n",
        "            if self.use_cuda:\n",
        "                noise_mean = noise_mean.cuda()\n",
        "                noise_sig = noise_sig.cuda()\n",
        "\n",
        "            # sample the noise\n",
        "            noise_batch = pyro.sample(\"noise\", dist.Normal(noise_mean, noise_sig).to_event(1))\n",
        "            noise_batch = self._map_to_noise_range(noise_batch)\n",
        "\n",
        "            num_c = torch.tensor(1 / len(self.char_dict)).repeat((BS, N_index, len(self.char_dict)))\n",
        "            if self.use_cuda:\n",
        "                    num_c = num_c.cuda()\n",
        "                    \n",
        "            # sample the character indices\n",
        "            c = pyro.sample(\"chars\", dist.Categorical(num_c).to_event(1)) # maybe 2 here\n",
        "            rendered_images = []\n",
        "            for i in range(c.shape[0]):\n",
        "                chars = \"\"\n",
        "                for j in range(N_index):\n",
        "                    chars += self.char_dict[c[i][j]]\n",
        "        \n",
        "                rendered_image = render_image(chars, noise=float(noise_batch[i]), use_cuda=self.use_cuda)\n",
        "                rendered_images.append(rendered_image)\n",
        "                \n",
        "        rendered_images = torch.stack(rendered_images)\n",
        "        sigma = torch.tensor(0.000001)\n",
        "        if self.use_cuda:\n",
        "                sigma = sigma.cuda()\n",
        "\n",
        "        pyro.sample(\"captcha\", dist.Normal(rendered_images, sigma).to_event(2), obs=observations[\"captcha\"])\n",
        "\n",
        "captchaModel = CaptchaModel(USE_CUDA)\n",
        "\n",
        "optimiser = pyro.optim.Adam({'lr': 1e-6})\n",
        "svi = SVI(captchaModel.model, captchaModel.guide, optimiser, loss=Trace_ELBO())\n",
        "#csis = pyro.infer.CSIS(captchaModel.model, captchaModel.guide, optimiser, num_inference_samples=1)\n",
        "\n",
        "\n",
        "optimize(USE_CUDA)\n",
        "test_cycle(USE_CUDA)"
      ],
      "id": "composite-secretary",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizing...\n",
            "loss at epoch 1 is 66736250371323.65\n",
            "loss at epoch 2 is 69193640975334.77\n",
            "loss at epoch 3 is 68584695303091.875\n",
            "loss at epoch 4 is 67642692822357.3\n",
            "loss at epoch 5 is 66663873714570.08\n",
            "loss at epoch 6 is 67653843899211.69\n",
            "loss at epoch 7 is 67377597453113.32\n",
            "loss at epoch 8 is 67786610440725.26\n",
            "loss at epoch 9 is 67449309239432.48\n",
            "loss at epoch 10 is 66706538380274.44\n",
            "loss at epoch 11 is 65445725293069.2\n",
            "loss at epoch 12 is 67034682913698.586\n",
            "loss at epoch 13 is 65689064208198.24\n",
            "loss at epoch 14 is 64883483124258.664\n",
            "loss at epoch 15 is 64450804304648.51\n",
            "loss at epoch 16 is 64064492881508.25\n",
            "loss at epoch 17 is 64585671219429.73\n",
            "loss at epoch 18 is 63267932174486.0\n",
            "loss at epoch 19 is 62538551097717.45\n",
            "loss at epoch 20 is 64426745909006.59\n",
            "loss at epoch 21 is 63938657767344.06\n",
            "loss at epoch 22 is 64194753345063.77\n",
            "loss at epoch 23 is 66031697969580.98\n",
            "loss at epoch 24 is 64306389408691.4\n",
            "loss at epoch 25 is 63854062598941.76\n",
            "loss at epoch 26 is 64106762884233.15\n",
            "loss at epoch 27 is 64768813187386.86\n",
            "loss at epoch 28 is 65477559019618.8\n",
            "loss at epoch 29 is 63883960652076.87\n",
            "loss at epoch 30 is 64789058606167.89\n",
            "loss at epoch 31 is 65022104620862.445\n",
            "loss at epoch 32 is 64490012902228.2\n",
            "loss at epoch 33 is 65344073307276.79\n",
            "loss at epoch 34 is 65642642701538.88\n",
            "loss at epoch 35 is 64892075828057.29\n",
            "loss at epoch 36 is 65319023565678.13\n",
            "loss at epoch 37 is 66792991417081.25\n",
            "loss at epoch 38 is 65941807272011.97\n",
            "loss at epoch 39 is 65652230266322.82\n",
            "loss at epoch 40 is 65446787480685.94\n",
            "loss at epoch 41 is 65593867731298.445\n",
            "loss at epoch 42 is 66610605281009.055\n",
            "loss at epoch 43 is 67332458434639.03\n",
            "loss at epoch 44 is 65855646743313.67\n",
            "loss at epoch 45 is 66079233198885.734\n",
            "loss at epoch 46 is 64955476274490.02\n",
            "loss at epoch 47 is 64556997275199.24\n",
            "loss at epoch 48 is 65042111160638.74\n",
            "loss at epoch 49 is 65061303653753.79\n",
            "loss at epoch 50 is 66042271066202.85\n",
            "loss at epoch 51 is 65113341711533.945\n",
            "loss at epoch 52 is 65747793450618.266\n",
            "loss at epoch 53 is 64071750907381.45\n",
            "loss at epoch 54 is 64930596702661.59\n",
            "loss at epoch 55 is 64431277497572.086\n",
            "loss at epoch 56 is 64512228509262.25\n",
            "loss at epoch 57 is 65040319903069.58\n",
            "loss at epoch 58 is 64696225579226.93\n",
            "loss at epoch 59 is 63714537736151.54\n",
            "loss at epoch 60 is 64177133662851.12\n",
            "loss at epoch 61 is 64319069146446.78\n",
            "loss at epoch 62 is 64316735520554.94\n",
            "loss at epoch 63 is 63947422515526.125\n",
            "loss at epoch 64 is 64404066737972.74\n",
            "loss at epoch 65 is 63257272166694.58\n",
            "loss at epoch 66 is 64382326730545.086\n",
            "loss at epoch 67 is 63905427929084.83\n",
            "loss at epoch 68 is 63818099221865.59\n",
            "loss at epoch 69 is 63646749321832.23\n",
            "loss at epoch 70 is 63659016762611.15\n",
            "loss at epoch 71 is 63683448594617.61\n",
            "loss at epoch 72 is 63894235700133.586\n",
            "loss at epoch 73 is 64528077502629.305\n",
            "loss at epoch 74 is 62719792014417.27\n",
            "loss at epoch 75 is 63065850285709.22\n",
            "loss at epoch 76 is 63736195038502.29\n",
            "loss at epoch 77 is 62425792928146.94\n",
            "loss at epoch 78 is 63433382645926.15\n",
            "loss at epoch 79 is 63604066420641.73\n",
            "loss at epoch 80 is 63236695470821.8\n",
            "loss at epoch 81 is 64615839351981.59\n",
            "loss at epoch 82 is 64276413003479.18\n",
            "loss at epoch 83 is 62571979614388.26\n",
            "loss at epoch 84 is 63178714091508.48\n",
            "loss at epoch 85 is 63115217612091.12\n",
            "loss at epoch 86 is 62297916908102.16\n",
            "loss at epoch 87 is 62989694385622.79\n",
            "loss at epoch 88 is 63604132692754.86\n",
            "loss at epoch 89 is 62746670261091.03\n",
            "loss at epoch 90 is 62317539233703.58\n",
            "loss at epoch 91 is 62707192689851.51\n",
            "loss at epoch 92 is 63244891803596.87\n",
            "loss at epoch 93 is 61920605574069.67\n",
            "loss at epoch 94 is 62222880006970.336\n",
            "loss at epoch 95 is 62890805795800.4\n",
            "loss at epoch 96 is 63142503487600.91\n",
            "loss at epoch 97 is 63470294186950.64\n",
            "loss at epoch 98 is 62420908191261.95\n",
            "loss at epoch 99 is 62257659538074.89\n",
            "loss at epoch 100 is 62656785721026.16\n",
            "directly sampling from guide:\n",
            "use_train = False Total correct: 40 accuracy:40/1000= 0.04 char_accuracy:178/1967= 0.09049313675648195\n",
            "use Imporant Sampling:\n",
            "IS num_samples: 500\n",
            "use_train = False Total correct: 296 accuracy:296/500= 0.592 char_accuracy:725/1009= 0.7185332011892963\n",
            "IS num_samples: 300\n",
            "use_train = False Total correct: 271 accuracy:271/500= 0.542 char_accuracy:687/991= 0.693239152371342\n",
            "IS num_samples: 100\n",
            "use_train = False Total correct: 218 accuracy:218/500= 0.436 char_accuracy:577/997= 0.5787362086258776\n",
            "IS num_samples: 100\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.686 | Actual Noise: 0.759 | Predicted Text: 9 | Actual Text: 9 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.557 | Actual Noise: 0.355 | Predicted Text: 958 | Actual Text: 858 | Correct: 2\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.751 | Actual Noise: 0.768 | Predicted Text: 0 | Actual Text: 0 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.573 | Actual Noise: 0.392 | Predicted Text: 323 | Actual Text: 328 | Correct: 2\n",
            "N_predicted: 1 | Actual N: 3 | Predicted Noise: 0.615 | Actual Noise: 0.068 | Predicted Text: 7 | Actual Text: 773 | Correct: 1\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.585 | Actual Noise: 0.717 | Predicted Text: 1 | Actual Text: 1 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.608 | Actual Noise: 0.336 | Predicted Text: 606 | Actual Text: 850 | Correct: 0\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.792 | Actual Noise: 0.956 | Predicted Text: 256 | Actual Text: 253 | Correct: 2\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.537 | Actual Noise: 0.648 | Predicted Text: 498 | Actual Text: 466 | Correct: 1\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.584 | Actual Noise: 0.17 | Predicted Text: 3 | Actual Text: 9 | Correct: 0\n",
            "use_train = False Total correct: 3 accuracy:3/10= 0.3 char_accuracy:11/22= 0.5\n",
            "loss at epoch 101 is 62594680058414.04\n",
            "loss at epoch 102 is 62235893610501.086\n",
            "loss at epoch 103 is 62968313422292.77\n",
            "loss at epoch 104 is 62031707264389.92\n",
            "loss at epoch 105 is 61656705913642.914\n",
            "loss at epoch 106 is 64035956409424.234\n",
            "loss at epoch 107 is 63105554336995.42\n",
            "loss at epoch 108 is 61345952504102.375\n",
            "loss at epoch 109 is 63360616650568.38\n",
            "loss at epoch 110 is 63052642769519.875\n",
            "loss at epoch 111 is 61613391538459.31\n",
            "loss at epoch 112 is 61476933014743.03\n",
            "loss at epoch 113 is 61316842068041.41\n",
            "loss at epoch 114 is 61382355367201.04\n",
            "loss at epoch 115 is 61816913978444.164\n",
            "loss at epoch 116 is 60863242456413.9\n",
            "loss at epoch 117 is 61027152913273.445\n",
            "loss at epoch 118 is 60904975927477.695\n",
            "loss at epoch 119 is 60964104652464.41\n",
            "loss at epoch 120 is 60712995079070.7\n",
            "loss at epoch 121 is 62111795714033.79\n",
            "loss at epoch 122 is 61440468141508.32\n",
            "loss at epoch 123 is 60764590258110.695\n",
            "loss at epoch 124 is 60898084049857.37\n",
            "loss at epoch 125 is 61525384672395.83\n",
            "loss at epoch 126 is 61313679398920.69\n",
            "loss at epoch 127 is 60838569596981.21\n",
            "loss at epoch 128 is 61141872469641.74\n",
            "loss at epoch 129 is 61263828804972.375\n",
            "loss at epoch 130 is 61220121951000.336\n",
            "loss at epoch 131 is 60465672049509.57\n",
            "loss at epoch 132 is 60285264759643.06\n",
            "loss at epoch 133 is 61373027997264.83\n",
            "loss at epoch 134 is 60986697371550.94\n",
            "loss at epoch 135 is 59959055509002.18\n",
            "loss at epoch 136 is 60262391031226.15\n",
            "loss at epoch 137 is 60210989926856.47\n",
            "loss at epoch 138 is 60529052735912.56\n",
            "loss at epoch 139 is 61169664288630.73\n",
            "loss at epoch 140 is 59953236880568.0\n",
            "loss at epoch 141 is 59625799464273.23\n",
            "loss at epoch 142 is 59523194207520.54\n",
            "loss at epoch 143 is 60208124977252.94\n",
            "loss at epoch 144 is 59882435209372.664\n",
            "loss at epoch 145 is 60259759316883.89\n",
            "loss at epoch 146 is 59380969651082.805\n",
            "loss at epoch 147 is 59040135355145.64\n",
            "loss at epoch 148 is 60242460653147.016\n",
            "loss at epoch 149 is 59853785517044.86\n",
            "loss at epoch 150 is 60024162906127.87\n",
            "loss at epoch 151 is 60566628897427.71\n",
            "loss at epoch 152 is 59540808123386.93\n",
            "loss at epoch 153 is 59777873372046.34\n",
            "loss at epoch 154 is 59732550966699.24\n",
            "loss at epoch 155 is 59800946340335.3\n",
            "loss at epoch 156 is 59863655533269.086\n",
            "loss at epoch 157 is 59436466740497.23\n",
            "loss at epoch 158 is 58912928530802.984\n",
            "loss at epoch 159 is 59549574486570.33\n",
            "loss at epoch 160 is 60007050320623.6\n",
            "loss at epoch 161 is 59251556980235.79\n",
            "loss at epoch 162 is 58622112262221.67\n",
            "loss at epoch 163 is 57955440531837.54\n",
            "loss at epoch 164 is 58715155807466.24\n",
            "loss at epoch 165 is 58717023216448.836\n",
            "loss at epoch 166 is 58316554444298.6\n",
            "loss at epoch 167 is 58306241374630.445\n",
            "loss at epoch 168 is 59681492567218.67\n",
            "loss at epoch 169 is 59192373479668.11\n",
            "loss at epoch 170 is 59589038784995.16\n",
            "loss at epoch 171 is 58653409340252.19\n",
            "loss at epoch 172 is 58851804495215.12\n",
            "loss at epoch 173 is 59215854958136.89\n",
            "loss at epoch 174 is 58793451934083.34\n",
            "loss at epoch 175 is 59530634483042.01\n",
            "loss at epoch 176 is 58430970674603.96\n",
            "loss at epoch 177 is 59592460671068.97\n",
            "loss at epoch 178 is 58042105461297.8\n",
            "loss at epoch 179 is 58437007948909.44\n",
            "loss at epoch 180 is 57631536274021.92\n",
            "loss at epoch 181 is 57771447814292.42\n",
            "loss at epoch 182 is 57568789374398.516\n",
            "loss at epoch 183 is 56883284284123.74\n",
            "loss at epoch 184 is 55963273948851.49\n",
            "loss at epoch 185 is 55168162616237.484\n",
            "loss at epoch 186 is 52114831612870.586\n",
            "loss at epoch 187 is 51331852412419.11\n",
            "loss at epoch 188 is 51815132487518.87\n",
            "loss at epoch 189 is 52277160992436.305\n",
            "loss at epoch 190 is 51463910479280.12\n",
            "loss at epoch 191 is 48915477632513.61\n",
            "loss at epoch 192 is 48425570919783.63\n",
            "loss at epoch 193 is 51054175800675.414\n",
            "loss at epoch 194 is 50063707444230.77\n",
            "loss at epoch 195 is 52003021461220.36\n",
            "loss at epoch 196 is 54044459925412.914\n",
            "loss at epoch 197 is 54576395159862.92\n",
            "loss at epoch 198 is 56078657256465.4\n",
            "loss at epoch 199 is 56508358230170.5\n",
            "loss at epoch 200 is 55644623463303.75\n",
            "directly sampling from guide:\n",
            "use_train = False Total correct: 34 accuracy:34/1000= 0.034 char_accuracy:218/2045= 0.10660146699266504\n",
            "use Imporant Sampling:\n",
            "IS num_samples: 500\n",
            "use_train = False Total correct: 330 accuracy:330/500= 0.66 char_accuracy:807/1013= 0.7966436327739388\n",
            "IS num_samples: 300\n",
            "use_train = False Total correct: 312 accuracy:312/500= 0.624 char_accuracy:730/975= 0.7487179487179487\n",
            "IS num_samples: 100\n",
            "use_train = False Total correct: 217 accuracy:217/500= 0.434 char_accuracy:647/1030= 0.6281553398058253\n",
            "IS num_samples: 100\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.614 | Actual Noise: 0.656 | Predicted Text: 20 | Actual Text: 20 | Correct: 2\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.671 | Actual Noise: 0.366 | Predicted Text: 343 | Actual Text: 840 | Correct: 1\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.664 | Actual Noise: 0.318 | Predicted Text: 5 | Actual Text: 5 | Correct: 1\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.632 | Actual Noise: 0.716 | Predicted Text: 3 | Actual Text: 3 | Correct: 1\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.71 | Actual Noise: 0.109 | Predicted Text: 91 | Actual Text: 01 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.69 | Actual Noise: 0.345 | Predicted Text: 680 | Actual Text: 680 | Correct: 3\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.743 | Actual Noise: 0.129 | Predicted Text: 71 | Actual Text: 77 | Correct: 1\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.625 | Actual Noise: 0.219 | Predicted Text: 36 | Actual Text: 66 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.76 | Actual Noise: 0.721 | Predicted Text: 678 | Actual Text: 678 | Correct: 3\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.593 | Actual Noise: 0.285 | Predicted Text: 36 | Actual Text: 86 | Correct: 1\n",
            "use_train = False Total correct: 5 accuracy:5/10= 0.5 char_accuracy:15/21= 0.7142857142857143\n",
            "loss at epoch 201 is 56652105799660.76\n",
            "loss at epoch 202 is 58634551985718.88\n",
            "loss at epoch 203 is 57808614636257.03\n",
            "loss at epoch 204 is 58258598775086.57\n",
            "loss at epoch 205 is 57357368360307.99\n",
            "loss at epoch 206 is 58807746521100.98\n",
            "loss at epoch 207 is 57509795729778.91\n",
            "loss at epoch 208 is 58511642735603.67\n",
            "loss at epoch 209 is 55134944881857.36\n",
            "loss at epoch 210 is 56547949970817.42\n",
            "loss at epoch 211 is 55751777786697.19\n",
            "loss at epoch 212 is 53124325632713.516\n",
            "loss at epoch 213 is 53522634976084.7\n",
            "loss at epoch 214 is 54775503686115.81\n",
            "loss at epoch 215 is 55133820355397.875\n",
            "loss at epoch 216 is 53103026354264.78\n",
            "loss at epoch 217 is 52417494423683.125\n",
            "loss at epoch 218 is 50511257273811.836\n",
            "loss at epoch 219 is 52993848914491.41\n",
            "loss at epoch 220 is 51089701921983.73\n",
            "loss at epoch 221 is 51402675757772.99\n",
            "loss at epoch 222 is 50457946314903.26\n",
            "loss at epoch 223 is 48145708606910.625\n",
            "loss at epoch 224 is 49350923068308.39\n",
            "loss at epoch 225 is 49601562088983.7\n",
            "loss at epoch 226 is 52318718280842.82\n",
            "loss at epoch 227 is 53006184015161.04\n",
            "loss at epoch 228 is 53576382150990.55\n",
            "loss at epoch 229 is 53916883782188.17\n",
            "loss at epoch 230 is 55799470380613.266\n",
            "loss at epoch 231 is 55493953038599.41\n",
            "loss at epoch 232 is 54791910891296.586\n",
            "loss at epoch 233 is 53595987067324.445\n",
            "loss at epoch 234 is 53294127644592.484\n",
            "loss at epoch 235 is 52592250447487.18\n",
            "loss at epoch 236 is 49953651578509.516\n",
            "loss at epoch 237 is 50318544238398.836\n",
            "loss at epoch 238 is 52189585285286.35\n",
            "loss at epoch 239 is 52097206435829.77\n",
            "loss at epoch 240 is 51448608534486.69\n",
            "loss at epoch 241 is 48534994263130.45\n",
            "loss at epoch 242 is 49069267734788.04\n",
            "loss at epoch 243 is 47552493692789.68\n",
            "loss at epoch 244 is 48116279158057.03\n",
            "loss at epoch 245 is 47648234621944.69\n",
            "loss at epoch 246 is 47701777980467.2\n",
            "loss at epoch 247 is 46246423259356.586\n",
            "loss at epoch 248 is 45904662469672.12\n",
            "loss at epoch 249 is 47075599048986.22\n",
            "loss at epoch 250 is 47596323486602.375\n",
            "loss at epoch 251 is 47484051241819.45\n",
            "loss at epoch 252 is 52288394377407.68\n",
            "loss at epoch 253 is 50179755952880.18\n",
            "loss at epoch 254 is 49364767760155.12\n",
            "loss at epoch 255 is 49479485356007.16\n",
            "loss at epoch 256 is 50629525078160.68\n",
            "loss at epoch 257 is 46859197264403.75\n",
            "loss at epoch 258 is 46808536035677.45\n",
            "loss at epoch 259 is 46452719637316.21\n",
            "loss at epoch 260 is 46209057999750.24\n",
            "loss at epoch 261 is 48231296430559.43\n",
            "loss at epoch 262 is 49319426417340.55\n",
            "loss at epoch 263 is 50060595922244.76\n",
            "loss at epoch 264 is 48906338241374.805\n",
            "loss at epoch 265 is 47019329387405.58\n",
            "loss at epoch 266 is 47279486019100.125\n",
            "loss at epoch 267 is 47044732910277.086\n",
            "loss at epoch 268 is 46691396921277.65\n",
            "loss at epoch 269 is 46865434245152.53\n",
            "loss at epoch 270 is 47585592362683.09\n",
            "loss at epoch 271 is 46227846325018.7\n",
            "loss at epoch 272 is 46166482781380.54\n",
            "loss at epoch 273 is 47348705993737.16\n",
            "loss at epoch 274 is 46754606787840.73\n",
            "loss at epoch 275 is 48802111572291.52\n",
            "loss at epoch 276 is 53080166828221.15\n",
            "loss at epoch 277 is 52618704665075.06\n",
            "loss at epoch 278 is 50392986607593.68\n",
            "loss at epoch 279 is 49728702958410.23\n",
            "loss at epoch 280 is 48533701969249.99\n",
            "loss at epoch 281 is 49778192398945.2\n",
            "loss at epoch 282 is 50515027981927.914\n",
            "loss at epoch 283 is 52579188367124.72\n",
            "loss at epoch 284 is 52372896655978.516\n",
            "loss at epoch 285 is 54564692268683.4\n",
            "loss at epoch 286 is 54564078989197.664\n",
            "loss at epoch 287 is 54312363184286.85\n",
            "loss at epoch 288 is 53727470163923.0\n",
            "loss at epoch 289 is 53543749129698.125\n",
            "loss at epoch 290 is 54220197028952.56\n",
            "loss at epoch 291 is 54780461707234.164\n",
            "loss at epoch 292 is 54705808221996.516\n",
            "loss at epoch 293 is 54739125344665.19\n",
            "loss at epoch 294 is 55412999732521.26\n",
            "loss at epoch 295 is 54359354356663.016\n",
            "loss at epoch 296 is 54048100474878.11\n",
            "loss at epoch 297 is 53578559028395.29\n",
            "loss at epoch 298 is 52322317889272.86\n",
            "loss at epoch 299 is 47938441892569.94\n",
            "loss at epoch 300 is 46578818537852.15\n",
            "directly sampling from guide:\n",
            "use_train = False Total correct: 70 accuracy:70/1000= 0.07 char_accuracy:293/2033= 0.1441219872110182\n",
            "use Imporant Sampling:\n",
            "IS num_samples: 500\n",
            "use_train = False Total correct: 354 accuracy:354/500= 0.708 char_accuracy:855/1019= 0.8390578999018645\n",
            "IS num_samples: 300\n",
            "use_train = False Total correct: 355 accuracy:355/500= 0.71 char_accuracy:793/962= 0.8243243243243243\n",
            "IS num_samples: 100\n",
            "use_train = False Total correct: 288 accuracy:288/500= 0.576 char_accuracy:693/966= 0.717391304347826\n",
            "IS num_samples: 100\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.457 | Actual Noise: 0.136 | Predicted Text: 69 | Actual Text: 69 | Correct: 2\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.629 | Actual Noise: 0.846 | Predicted Text: 103 | Actual Text: 198 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.517 | Actual Noise: 0.433 | Predicted Text: 303 | Actual Text: 303 | Correct: 3\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.43 | Actual Noise: 0.476 | Predicted Text: 9 | Actual Text: 9 | Correct: 1\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.454 | Actual Noise: 0.444 | Predicted Text: 088 | Actual Text: 080 | Correct: 2\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.353 | Actual Noise: 0.117 | Predicted Text: 3 | Actual Text: 3 | Correct: 1\n",
            "N_predicted: 2 | Actual N: 2 | Predicted Noise: 0.52 | Actual Noise: 0.55 | Predicted Text: 38 | Actual Text: 38 | Correct: 2\n",
            "N_predicted: 3 | Actual N: 3 | Predicted Noise: 0.45 | Actual Noise: 0.528 | Predicted Text: 163 | Actual Text: 183 | Correct: 2\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.5 | Actual Noise: 0.859 | Predicted Text: 9 | Actual Text: 9 | Correct: 1\n",
            "N_predicted: 1 | Actual N: 1 | Predicted Noise: 0.321 | Actual Noise: 0.215 | Predicted Text: 8 | Actual Text: 8 | Correct: 1\n",
            "use_train = False Total correct: 7 accuracy:7/10= 0.7 char_accuracy:16/20= 0.8\n",
            "loss at epoch 301 is 47065423595664.01\n",
            "loss at epoch 302 is 49778598790847.9\n",
            "loss at epoch 303 is 49681277327452.57\n",
            "loss at epoch 304 is 47378330610959.766\n",
            "loss at epoch 305 is 48725371710738.45\n",
            "loss at epoch 306 is 50783172790171.266\n",
            "loss at epoch 307 is 51554110733944.28\n",
            "loss at epoch 308 is 51609126605338.35\n",
            "loss at epoch 309 is 51397611265438.12\n",
            "loss at epoch 310 is 48272264293603.734\n",
            "loss at epoch 311 is 46008161693854.17\n",
            "loss at epoch 312 is 44868096596404.34\n",
            "loss at epoch 313 is 47020130077296.31\n",
            "loss at epoch 314 is 46254162305193.09\n",
            "loss at epoch 315 is 45852138324305.11\n",
            "loss at epoch 316 is 45712978859535.06\n",
            "loss at epoch 317 is 48461325760910.75\n",
            "loss at epoch 318 is 48544692279379.695\n",
            "loss at epoch 319 is 49589454556931.875\n",
            "loss at epoch 320 is 50273922161687.2\n",
            "loss at epoch 321 is 50786538877793.59\n",
            "loss at epoch 322 is 47760736803529.875\n",
            "loss at epoch 323 is 48142181663541.836\n",
            "loss at epoch 324 is 50178313588047.58\n",
            "loss at epoch 325 is 51187237836713.555\n",
            "loss at epoch 326 is 51452302710775.75\n",
            "loss at epoch 327 is 50623418767346.24\n",
            "loss at epoch 328 is 51089136634102.586\n",
            "loss at epoch 329 is 51098998499580.6\n",
            "loss at epoch 330 is 52005336772557.48\n",
            "loss at epoch 331 is 52667768897234.57\n",
            "loss at epoch 332 is 51811227824278.3\n",
            "loss at epoch 333 is 52767530382894.26\n",
            "loss at epoch 334 is 52106881489512.125\n",
            "loss at epoch 335 is 52754020867581.74\n",
            "loss at epoch 336 is 49245593696416.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlimited-spokesman"
      },
      "source": [
        ""
      ],
      "id": "unlimited-spokesman",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "returning-atlas"
      },
      "source": [
        ""
      ],
      "id": "returning-atlas",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swiss-sister"
      },
      "source": [
        ""
      ],
      "id": "swiss-sister",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "genetic-difficulty"
      },
      "source": [
        ""
      ],
      "id": "genetic-difficulty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovely-territory"
      },
      "source": [
        ""
      ],
      "id": "lovely-territory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "solar-athletics"
      },
      "source": [
        ""
      ],
      "id": "solar-athletics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjustable-granny"
      },
      "source": [
        ""
      ],
      "id": "adjustable-granny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "painful-transportation"
      },
      "source": [
        ""
      ],
      "id": "painful-transportation",
      "execution_count": null,
      "outputs": []
    }
  ]
}