{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-variance",
   "metadata": {
    "id": "great-variance"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import numpy as np\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from PIL import Image\n",
    "from claptchagen.claptcha import Claptcha\n",
    "from torch.distributions import constraints\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-session",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-louisiana",
   "metadata": {
    "id": "agreed-louisiana"
   },
   "outputs": [],
   "source": [
    "captcha_folder = 'generated_captchas' # folder to save generated captchas\n",
    "captchaHeight = 32\n",
    "captchaWidth = 100\n",
    "captchaMarginX = 4\n",
    "captchaMarginY = 4\n",
    "batch_size = 8\n",
    "char_dict = string.ascii_lowercase # letter dictionary\n",
    "USE_CUDA = True\n",
    "MAX_N = 6 # the max number of letters in a captcha\n",
    "smoke_test = True\n",
    "num_steps = 10000 if not smoke_test else 10\n",
    "TrainingSample = 6000 if not smoke_test else 100 # number of examples will be generated for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-airfare",
   "metadata": {},
   "source": [
    "Functions to generate capthas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-westminster",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "turned-westminster",
    "outputId": "c83295d1-96f2-49cb-a3f5-49d01ea02f0f"
   },
   "outputs": [],
   "source": [
    "def randomString():\n",
    "    \"\"\"\n",
    "    return a string with <k> random letters, where k is a random int from 1 to MAX_N, inclusive both\n",
    "    \"\"\"\n",
    "    k = random.randint(1, MAX_N)\n",
    "    \n",
    "    rndLetters = (random.choice(char_dict) for _ in range(k))\n",
    "    return \"\".join(rndLetters)\n",
    "\n",
    "def generate_random_captcha(n, save=False):\n",
    "    \"\"\"\n",
    "    generate n random captchas,\n",
    "    return a list of texts on the captchas\n",
    "    \"\"\"\n",
    "    # Initialize Claptcha object with random text, FreeMono as font, of size\n",
    "    # 100x32px, using bicubic resampling filter and adding a bit of white noise\n",
    "    c = Claptcha(randomString, \"fonts/FreeSans.ttf\", (captchaWidth, captchaHeight), (captchaMarginX, captchaMarginY),\n",
    "             resample=Image.BILINEAR, noise=0)\n",
    "    captcha_generated = [[] for i in range(MAX_N)]\n",
    "    for i in range(n):\n",
    "        if save:\n",
    "            text, _ = c.write(os.path.join(captcha_folder, 'captcha{}.png'.format(i)))\n",
    "            os.rename(os.path.join(captcha_folder, 'captcha{}.png'.format(i)),os.path.join(captcha_folder, '{}.png'.format(text + \"_\" + str(i))))\n",
    "        text, image = c.image\n",
    "        image = np.array(image)[:, :, 0] # the generator is gray scale, only keep one channel is enough\n",
    "        captcha_generated[len(text) - 1].append((text, image))\n",
    "    return captcha_generated\n",
    "\n",
    "captcha_generated = generate_random_captcha(TrainingSample, save=False)\n",
    "print(len(captcha_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-signal",
   "metadata": {
    "id": "noticed-signal"
   },
   "outputs": [],
   "source": [
    "def render_image(chars, fonts=\"fonts/FreeSans.ttf\", size=(captchaWidth, captchaHeight), \n",
    "                 margin=(captchaMarginX, captchaMarginY), resample=Image.BILINEAR, noise=0.3, use_cuda=False):\n",
    "    \"\"\"\n",
    "    generate a captcha with predicted chars and noise\n",
    "    \"\"\"\n",
    "    noise = noise.data.item()\n",
    "    render = Claptcha(chars, fonts, size, margin, resample=resample, noise=noise)\n",
    "\n",
    "    _ , rendered_image = render.image\n",
    "    rendered_image = np.array(rendered_image)[:,:,0] # the generator is gray scale, only keep one channel is enough\n",
    "    rendered_image = np.divide(rendered_image, 255)\n",
    "    rendered_image = torch.from_numpy(rendered_image)\n",
    "    if use_cuda:\n",
    "        rendered_image = rendered_image.cuda()\n",
    "    return rendered_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-person",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-universal",
   "metadata": {
    "id": "capable-universal"
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    \"\"\"Captcha dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, raw_captchas, transform=None):\n",
    "\n",
    "        self.raw_captchas = raw_captchas\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_captchas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.raw_captchas[idx][0]\n",
    "        image = self.raw_captchas[idx][1]\n",
    "        \n",
    "        image = np.divide(image, 255)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return label, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-southeast",
   "metadata": {
    "id": "canadian-southeast"
   },
   "outputs": [],
   "source": [
    "def make_loarders(BATCH_SIZE, raw_samples):\n",
    "    \"\"\"\n",
    "    create data loaders for different numbers of captcha samples\n",
    "    \"\"\"\n",
    "    dataloaders = [] # dataloaders for different num of char\n",
    "    for lst in raw_samples:\n",
    "        if lst:\n",
    "            ds = CaptchaDataset(lst)\n",
    "            dataloader = DataLoader(ds, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True, num_workers=0, drop_last=True)\n",
    "            dataloaders.append(dataloader)\n",
    "    return dataloaders\n",
    "\n",
    "def make_batches(dataloaders):\n",
    "    \"\"\"\n",
    "    make shuffled mini batches from dataloaders\n",
    "    all samples in the same mini batch have the same ground truth number of letters (N)\n",
    "    \"\"\"\n",
    "    all_batches = []\n",
    "    for dl in dataloaders:\n",
    "        for i_batch, sample in enumerate(dl):\n",
    "            all_batches.append(sample)\n",
    "    random.shuffle(all_batches)\n",
    "    random.shuffle(all_batches)\n",
    "    return all_batches\n",
    "\n",
    "TrainLoaders = make_loarders(BATCH_SIZE=batch_size, raw_samples=captcha_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-shark",
   "metadata": {
    "id": "specified-bankruptcy"
   },
   "source": [
    "Define the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-software",
   "metadata": {
    "id": "stylish-software"
   },
   "outputs": [],
   "source": [
    "class NumNet(nn.Module):\n",
    "    def __init__(self, img_size, out_size = 3):\n",
    "        \"\"\"\n",
    "        Network to predict the number of letters in a captcha image\n",
    "        \"\"\"\n",
    "        super(NumNet, self).__init__()\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(img_size[0] * img_size[1] * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_size),\n",
    "            nn.LogSoftmax())\n",
    "            \n",
    "    def forward(self, img):\n",
    "        img = torch.reshape(img, (img.shape[0], img.shape[1] * img.shape[2]))\n",
    "        prob = self.neural_net(img)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-mapping",
   "metadata": {
    "id": "engaging-mapping"
   },
   "outputs": [],
   "source": [
    "class NoiseNet(nn.Module):\n",
    "    def __init__(self, img_size, out_size = 1):\n",
    "        \"\"\"\n",
    "        Network to predict noise for a captcha image\n",
    "        noise should be inside of [0, 1]\n",
    "        \"\"\"\n",
    "        super(NoiseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2)\n",
    "        self.fc2 = nn.Linear(img_size[0] * img_size[1] * 2, out_size)\n",
    "        self.fc3 = nn.Linear(img_size[0] * img_size[1], img_size[0] * img_size[1] * 2)\n",
    "        self.fc4 = nn.Linear(img_size[0] * img_size[1] * 2, out_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = torch.reshape(img, (-1,))\n",
    "        alpha = F.relu(self.fc1(img))\n",
    "        alpha = self.softplus(self.fc2(alpha))\n",
    "        \n",
    "        beta = F.relu(self.fc3(img))\n",
    "        beta = self.softplus(self.fc4(beta))\n",
    "    \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-variety",
   "metadata": {
    "id": "comprehensive-variety"
   },
   "outputs": [],
   "source": [
    "class CharNet(nn.Module):\n",
    "    def __init__(self, img_size, output_size, hidden_size=512, N_num_class=10, input_size=1024, num_layers=1):\n",
    "        \"\"\"\n",
    "        Network to predict characters in the captcha\n",
    "        Consturcted by a series of conv and linear layers for f_observe, applies to the input image\n",
    "        and a LSTM to predict each letter, given the predicted number of letters N\n",
    "        \"\"\"\n",
    "        super(CharNet, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.N_num_class = N_num_class\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "        # linear layers for the outputs of LSTM\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(hidden_size, output_size) for i in range(N_num_class)])\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "        # conv layers apply to input image\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layers apply to the output of conv layers\n",
    "        self.pfc1 = nn.Linear(8832, 2048)\n",
    "        self.pfc2 = nn.Linear(2048, 1024)\n",
    "        self.softplus = nn.Softplus()\n",
    "        # hidden param and hidden cells for LSTM\n",
    "        self.h_0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        self.c_0 = nn.Parameter(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "    \n",
    "    def forward(self, img, N, noise):\n",
    "        BATCH_SIZE = img.shape[0]\n",
    "        i = torch.arange(0, N)\n",
    "        if USE_CUDA:\n",
    "            i = i.cuda()\n",
    "        \n",
    "        # transfrom the index of each letter into one-hot format as well as the predicted N\n",
    "        i_onehot = F.one_hot(i, num_classes=self.N_num_class).float()\n",
    "        i_onehot = torch.reshape(i_onehot, (N, 1, self.N_num_class)).repeat(1, BATCH_SIZE, 1)\n",
    "        N_onehot = F.one_hot(N-1, num_classes=self.N_num_class).repeat(N, BATCH_SIZE, 1).float()\n",
    "    \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 1, self.img_size[0], self.img_size[1]))\n",
    "\n",
    "        img = self.pool(F.relu(self.conv1(img)))\n",
    "        img = self.pool(F.relu(self.conv2(img)))\n",
    "        \n",
    "        img = torch.reshape(img, (BATCH_SIZE, 8832))\n",
    "        \n",
    "        img = F.relu(self.pfc1(img))\n",
    "        img = F.relu(self.pfc2(img))\n",
    "        \n",
    "        img = img.repeat(N, 1, 1)\n",
    "        \n",
    "        noise = torch.reshape(noise, (1, BATCH_SIZE, noise[1]))\n",
    "        noise = noise.repeat(N, 1, 1)\n",
    "        \n",
    "        x = torch.cat((img, N_onehot, noise, i_onehot), dim=2)\n",
    "        x = torch.reshape(x, (N, BATCH_SIZE, self.input_size))\n",
    "\n",
    "        h_0_contig = self.h_0.expand(self.num_layers, BATCH_SIZE, self.hidden_size).contiguous()\n",
    "        c_0_contig = self.h_0.expand(self.num_layers, BATCH_SIZE, self.hidden_size).contiguous()\n",
    "        outputs, hn = self.rnn(x, (h_0_contig, c_0_contig))\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        outputs = torch.stack([self.linear_layers[i](outputs[i]) for i in range(outputs.shape[0])])\n",
    "\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        \n",
    "        # we want the first dim to be the batch size\n",
    "        outputs = torch.transpose(outputs, 0, 1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-center",
   "metadata": {
    "id": "fuzzy-center"
   },
   "outputs": [],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    def __init__(self, use_cuda=False):\n",
    "        super().__init__()\n",
    "        self.num_char_domain = torch.arange(1, MAX_N + 1) # the domain of N\n",
    "        print(self.num_char_domain)\n",
    "        if use_cuda:\n",
    "          self.num_char_domain = self.num_char_domain.cuda()\n",
    "        self.char_dict = char_dict\n",
    "        self.numNet = NumNet((captchaHeight, captchaWidth), len(self.num_char_domain))\n",
    "        self.noiseNet = NoiseNet((captchaHeight, captchaWidth), 1)\n",
    "        self.rnn_hidden_size = 512\n",
    "        self.rnn_num_layer = 2\n",
    "        self.charNetSingle = CharNet((captchaHeight, captchaWidth), len(self.char_dict), N_num_class=max(self.num_char_domain), input_size=1024 + max(self.num_char_domain) * 2 + 1, hidden_size=self.rnn_hidden_size, num_layers=self.rnn_num_layer)\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "    def model(self, baseline_image):\n",
    "        pyro.module(\"captchasolver\", self)\n",
    "        \n",
    "        # prior of noise and N\n",
    "\n",
    "        num_p = torch.tensor(1 / len(self.num_char_domain)).repeat(len(self.num_char_domain))\n",
    "        noise = pyro.sample(\"noise\", dist.Uniform(0, 1))\n",
    "\n",
    "        if self.use_cuda:\n",
    "            num_p = num_p.cuda()\n",
    "\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(num_p))\n",
    "        N = N_index + self.num_char_domain[0]\n",
    "        if self.use_cuda:\n",
    "            N = N.cuda()\n",
    "        \n",
    "        with pyro.plate(\"data\", baseline_image.shape[0]):\n",
    "            \n",
    "            # prior of each letter\n",
    "            \n",
    "            num_c = torch.tensor(1 / len(self.char_dict)).repeat((batch_size, N, len(self.char_dict)))\n",
    "            if self.use_cuda:\n",
    "                num_c = num_c.cuda()\n",
    "            c = pyro.sample(\"chars\", dist.Categorical(num_c).to_event(1)) # maybe 2 here\n",
    "            \n",
    "            rendered_images = []\n",
    "            \n",
    "            for i in range(c.shape[0]):\n",
    "                chars = \"\"\n",
    "                \n",
    "                for j in range(c.shape[1]):\n",
    "                    chars += self.char_dict[c[i][j]]\n",
    "                \n",
    "                rendered_image = render_image(chars, noise=noise, use_cuda=self.use_cuda)\n",
    "                rendered_images.append(rendered_image)\n",
    "            \n",
    "            rendered_images = torch.stack(rendered_images)\n",
    "            \n",
    "            sigma = torch.tensor(0.0000001) # a very small sigma\n",
    "            if self.use_cuda:\n",
    "                sigma = sigma.cuda()\n",
    "                \n",
    "            # score the generated (predicted image with the groundtruth image)\n",
    "            pyro.sample(\"captcha\", dist.Normal(rendered_images, sigma).to_event(2), obs=baseline_image)\n",
    "\n",
    "    def guide(self, baseline_image):\n",
    "        pyro.module(\"captchasolver\", self)\n",
    "\n",
    "        num_p = self.numNet(baseline_image)\n",
    "        num_p = torch.mean(num_p, dim=0) # take the mean of predicted Ns for a batch\n",
    "                                         # we want ta single N (i.e. one N for each batch)\n",
    "        N_index = pyro.sample(\"num_char\", dist.Categorical(num_p))\n",
    "        N = N_index + self.num_char_domain[0]\n",
    "        \n",
    "        if self.use_cuda:\n",
    "                N = N.cuda()\n",
    "        \n",
    "        with pyro.plate(\"data\", baseline_image.shape[0]):\n",
    "            \n",
    "            alpha, beta = self.noiseNet(baseline_image)\n",
    "            noise = pyro.sample(\"noise\", dist.Beta(alpha, beta).to_event(1))\n",
    "            \n",
    "            charP = self.charNetSingle(baseline_image, N, noise)\n",
    "            c = pyro.sample(\"chars\", dist.Categorical(charP).to_event(1))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-divorce",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-event",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "respected-event",
    "outputId": "f033d7b9-44fe-4db4-a8e1-70fb3bac017a"
   },
   "outputs": [],
   "source": [
    "captchaModel = CaptchaModel(USE_CUDA)\n",
    "model = captchaModel.model\n",
    "guide = captchaModel.guide\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam({\"lr\":learning_rate})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-population",
   "metadata": {},
   "source": [
    "Optimize and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-special",
   "metadata": {
    "id": "considered-special"
   },
   "outputs": [],
   "source": [
    "def test_cycle(use_cuda):\n",
    "    captchaModel.numNet.eval()\n",
    "    captchaModel.charNetSingle.eval()\n",
    "    \n",
    "    # test on the train dataset\n",
    "    test(use_train=True, verbose=True, use_cuda=use_cuda)\n",
    "    # test on a new generated dataset\n",
    "    test(1000, use_train=False, verbose=True, use_cuda=use_cuda)\n",
    "    # we may want to see the predicted and groundtruth\n",
    "    test(10, use_train=False, verbose=False, use_cuda=use_cuda)\n",
    "    \n",
    "    captchaModel.numNet.train()\n",
    "    captchaModel.charNetSingle.train()\n",
    "\n",
    "def optimize(use_cuda=False):\n",
    "    LOSS = 0\n",
    "    pause = 5\n",
    "    print(\"Optimizing...\")\n",
    "    for t in range(1, num_steps + 1):\n",
    "        LOSS += inference(t, use_cuda)\n",
    "        if (t % pause == 0) and (t > 0):\n",
    "            print(\"at {} step loss is {}\".format(t, LOSS / pause))\n",
    "            LOSS = 0\n",
    "            test_cycle(use_cuda=use_cuda)\n",
    "\n",
    "def inference(t, use_cuda=False):\n",
    "    loss = 0\n",
    "    length = TrainingSample\n",
    "    loss_group = []\n",
    "    all_batches = make_batches(TrainLoaders)\n",
    "    for i_batch, sample_batched in enumerate(all_batches):\n",
    "        \n",
    "        # get a batch and extract the images\n",
    "        img = sample_batched[1]\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "\n",
    "        imme_loss = svi.step(img) / (length * 1000)\n",
    "        loss += imme_loss\n",
    "        loss_group.append(imme_loss)\n",
    "\n",
    "        if (i_batch > 0) and (i_batch % 10 == 0):\n",
    "            # compute the mean of losses, for making a plot\n",
    "            loss_mean = np.mean(np.array(loss_group))\n",
    "            loss_list.append(loss_mean)\n",
    "            loss_group = []\n",
    "    \n",
    "    print(\"loss at {} is {}\".format(t, loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-tamil",
   "metadata": {
    "id": "twenty-tamil"
   },
   "outputs": [],
   "source": [
    "def test(n = 0, use_train=False, verbose=False, use_cuda=False):\n",
    "    if use_train:\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=captcha_generated)\n",
    "    else:\n",
    "        test_captcha_generated = generate_random_captcha(n, save=False)\n",
    "        TestLoaders = make_loarders(BATCH_SIZE=1, raw_samples=test_captcha_generated)\n",
    "    \n",
    "    total_correct = 0\n",
    "    char_correct = 0\n",
    "    total_char = 0\n",
    "    all_batches = make_batches(TestLoaders)\n",
    "    for i_batch, t in enumerate(all_batches):\n",
    "        label = t[0][0]\n",
    "        img = t[1]\n",
    "        if use_cuda:\n",
    "            img = img.cuda()\n",
    "        # get predicted N\n",
    "        num_p = captchaModel.numNet(img)\n",
    "        N_index = dist.Categorical(num_p[0]).sample()\n",
    "        N = N_index + captchaModel.num_char_domain[0]\n",
    "        # get predicted noise\n",
    "        noise = captchaModel.noiseNet(img)\n",
    "        if use_cuda:\n",
    "            N = N.cuda()\n",
    "        charP = captchaModel.charNetSingle(img, N, noise) # size (N, self.char_dict)\n",
    "        charP = charP[0]\n",
    "        if use_cuda:\n",
    "            charP.cpu()\n",
    "        chars = \"\"\n",
    "        # get each predicted letter\n",
    "        for i in range(N):\n",
    "            cp = charP[i]\n",
    "            c_index = int(dist.Categorical(cp).sample())\n",
    "            chars +=  captchaModel.char_dict[c_index]\n",
    "        correct = 0\n",
    "        # compute the accuracy\n",
    "        for p_char, t_char in zip(chars, label):\n",
    "            if p_char == t_char:\n",
    "                correct += 1\n",
    "        if not verbose:\n",
    "            print(\"N_predicted:\", int(N), \"Actual N:\", len(label), \"Predicted Text:\", chars, \"Actual Text:\", label, \"Correct:\", correct)\n",
    "        if correct == len(label) and int(N) == len(label):\n",
    "            total_correct += 1\n",
    "        char_correct += correct\n",
    "        total_char += len(label)\n",
    "    num_test_samples = i_batch + 1\n",
    "    accuracy = total_correct / num_test_samples\n",
    "    char_accuracy = char_correct / total_char\n",
    "    print(\"use_train =\", use_train, \"Total correct:\", total_correct, \"accuracy:{}/{}=\".format(total_correct, num_test_samples), accuracy, \"char_accuracy:{}/{}=\".format(char_correct, total_char), char_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-classroom",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fewer-classroom",
    "outputId": "bef8f83d-e31b-4cc3-f979-8400b47e5a13"
   },
   "outputs": [],
   "source": [
    "optimize(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-intervention",
   "metadata": {
    "id": "lucky-intervention"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Captcha_ver2_simple_LSTM_FULL_CUDA-DROPOUT-LESS-CONV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
