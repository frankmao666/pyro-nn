{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standard-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[Step 10/100] Immediate Loss: 7.798764485716818 Accumlated Loss: 10.695049868911504\n",
      "[Step 20/100] Immediate Loss: 7.175654533207414 Accumlated Loss: 7.41971659642458\n",
      "[Step 30/100] Immediate Loss: 7.064808929860589 Accumlated Loss: 7.102920457333326\n",
      "[Step 40/100] Immediate Loss: 7.0074234905839 Accumlated Loss: 6.9630768875181674\n",
      "[Step 50/100] Immediate Loss: 6.9895634829998015 Accumlated Loss: 6.904858220517634\n",
      "[Step 60/100] Immediate Loss: 6.930768578052519 Accumlated Loss: 6.851308759361505\n",
      "[Step 70/100] Immediate Loss: 6.801801775097844 Accumlated Loss: 6.917650807946919\n",
      "[Step 80/100] Immediate Loss: 6.898209309875968 Accumlated Loss: 6.852221962392329\n",
      "[Step 90/100] Immediate Loss: 6.877323675155637 Accumlated Loss: 6.880460332095623\n",
      "[Step 100/100] Immediate Loss: 6.808387375473978 Accumlated Loss: 6.813448920100927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoNormal, AutoMultivariateNormal\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # guide 1\n",
    "        self.hidden_size_1 = 8\n",
    "        self.x1_net_1 = simpleNN()\n",
    "        self.x2_net_1 = simpleNN()\n",
    "        self.x3_net_1 = simpleNN()\n",
    "        self.x4_net_1 = simpleNN()\n",
    "        self.x5_net_1 = simpleNN()\n",
    "        self.x6_net_1 = simpleNN()\n",
    "        self.x7_net_1 = simpleNN()\n",
    "        self.x8_net_1 = simpleNN()\n",
    "        self.y1_net_1 = simpleNN()\n",
    "        self.y2_net_1 = simpleNN()\n",
    "        self.y3_net_1 = simpleNN()\n",
    "        self.y4_net_1 = simpleNN()\n",
    "        self.z1_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        self.z2_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        \n",
    "        self.h0_1 = nn.Parameter(torch.zeros(self.hidden_size_1))\n",
    "        self.hid_net_1 = simpleNN(self.hidden_size_1 + 8, out_size = self.hidden_size_1, t = \"mlp\")\n",
    "        \n",
    "        # guide 2\n",
    "        self.hidden_size_2 = 8\n",
    "        self.x1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x5_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x6_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x7_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x8_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.h0_2 = nn.Parameter(torch.zeros(self.hidden_size_2))\n",
    "        self.hid_net_2 = simpleNN(self.hidden_size_2 + 8, out_size = self.hidden_size_2, t = \"mlp\")\n",
    "        \n",
    "        # guide 3\n",
    "        self.hidden_size_3 = 8\n",
    "        self.x1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x5_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x6_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x7_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x8_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.z1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.z2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.h0_3 = nn.Parameter(torch.zeros(self.hidden_size_3))\n",
    "        self.hid_net_3 = simpleNN(self.hidden_size_3 + 8, out_size = self.hidden_size_3, t = \"mlp\")\n",
    "\n",
    "        # guide 4\n",
    "        self.hidden_size_4 = 8\n",
    "        self.x1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x5_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x6_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x7_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x8_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.z1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.z2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.h0_4 = nn.Parameter(torch.zeros(self.hidden_size_4))\n",
    "        self.hid_net_4 = simpleNN(self.hidden_size_4 + 8 + 4 + 2, out_size = self.hidden_size_4, t = \"mlp\")\n",
    "        \n",
    "        # guide 5\n",
    "        self.hidden_size_5 = 16\n",
    "        self.x1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x5_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x6_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x7_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x8_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.z1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.z2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.h0_5 = nn.Parameter(torch.zeros(self.hidden_size_5))\n",
    "        self.hid_net_5 = simpleNN(self.hidden_size_5 + 8 + 4 + 2, out_size = self.hidden_size_5, t = \"mlp\")\n",
    "        \n",
    "        # guide 6\n",
    "        self.hidden_size_6 = 8\n",
    "        self.x1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x5_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x6_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x7_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x8_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.z1_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.z2_net_6 = simpleNN(self.hidden_size_6)\n",
    "        self.z1_net_6_last = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.z2_net_6_last = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.h0_6 = nn.Parameter(torch.zeros(self.hidden_size_6))\n",
    "        self.hid_net_6 = simpleNN(self.hidden_size_6 + 8 + 4 + 2 + 1, out_size = self.hidden_size_6, t = \"mlp\")\n",
    "        self.hid_net_6_5 = simpleNN(self.hidden_size_6 + 8 + 4 + 2, out_size = self.hidden_size_6, t = \"mlp\")\n",
    "    \n",
    "        # guide 7\n",
    "        self.hidden_size_7 = 8\n",
    "        self.x1_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x2_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.x3_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x4_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.x5_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x6_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.x7_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.x8_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.y1_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.y2_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.y3_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.y4_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.z1_net_7 = simpleNN(self.hidden_size_7 + 2)\n",
    "        self.z2_net_7 = simpleNN(self.hidden_size_7 + 1)\n",
    "        self.h0_7 = nn.Parameter(torch.zeros(self.hidden_size_6))\n",
    "        self.hid_net_7 = simpleNN(self.hidden_size_7 + 2, out_size = self.hidden_size_7, t = \"mlp\")\n",
    "        \n",
    "    def model(self, n, obs):\n",
    "        def tree_model(i, mu):\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(mu, 1.0))\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(mu, 1.0))\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(mu, 1.0))\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(mu, 1.0))\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(mu, 1.0))\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(mu, 1.0))\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(mu, 1.0))\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(mu, 1.0))\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(x1+x2, 1.0))\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(x3+x4, 1.0))\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(x5+x6, 1.0))\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(x7+x8, 1.0))\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(y1+y2, 1.0))\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(y3+y4, 1.0))\n",
    "            return z1 + z2  \n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        mu = 0\n",
    "        for i in range(n):\n",
    "            mu = tree_model(i, mu)\n",
    "        \n",
    "        pyro.sample(\"obs\", dist.Normal(mu, 1.0), obs=obs)\n",
    "    \n",
    "    # guide 1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_1(self, n, obs):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obs, hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide_1_1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # different from guide_1 by sample from i = n-1, n-2, ..., 0\n",
    "    def guide_1_1(self, n, obs):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obs, hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 2 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_2(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_2([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_2([obs, hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_2([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_2([z2, hid])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_2([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_2([z1, hid])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_2([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_2([y4, hid])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_2([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_2([y3, hid])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_2([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_2([y2, hid])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_2([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_2([y1, hid])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_2([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_2\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_3(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3_1 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = n-1, n-2, ..., 1, 0\n",
    "    \n",
    "    def guide_3_1(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 4 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_4(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_4([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_4([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_4([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_4([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_4([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_4([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_4([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_4([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_4([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_4([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_4([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_4([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_4([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_4([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_4([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_4\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 5 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # increases hidden state dim from 8 to 16\n",
    "    def guide_5(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_5([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_5([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_5([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_5([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_5([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_5([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_5([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_5([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_5([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_5([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_5([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_5([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_5([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_5([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_5([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_5\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 6 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2, obs)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "\n",
    "    def guide_6(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_6([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_6([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_6([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_6([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_6([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_6([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_6([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_6([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_6([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_6([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_6([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_6([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_6([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_6([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_6([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_6\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # reverse order of guide 6\n",
    "    def guide_6_1(self, n, obs):\n",
    "        def tree_guide(i, hid, last=False):\n",
    "            if last: # n-1 iteration\n",
    "                z2_mean, z2_std = self.z2_net_6_last([obs, hid])\n",
    "                z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "                z1_mean, z1_std = self.z1_net_6_last([obs, hid, z2])\n",
    "                z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            else:\n",
    "                z2_mean, z2_std = self.z2_net_6([hid])\n",
    "                z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "                z1_mean, z1_std = self.z1_net_6([hid, z2])\n",
    "                z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "                \n",
    "            y4_mean, y4_std = self.y4_net_6([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_6([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_6([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_6([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_6([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_6([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_6([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_6([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_6([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_6([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_6([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_6([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_6([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_6\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid, i==n-1)\n",
    "    \n",
    "     # reverse order of guide 5\n",
    "    def guide_5_1(self, n, obs):\n",
    "        def tree_guide(i, hid, last=False):\n",
    "            if last: # n-1 iteration\n",
    "                z2_mean, z2_std = self.z2_net_6_last([obs, hid])\n",
    "                z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "                z1_mean, z1_std = self.z1_net_6_last([obs, hid, z2])\n",
    "                z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            else:\n",
    "                z2_mean, z2_std = self.z2_net_6([hid])\n",
    "                z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "                z1_mean, z1_std = self.z1_net_6([hid, z2])\n",
    "                z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "                \n",
    "            y4_mean, y4_std = self.y4_net_6([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_6([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_6([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_6([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_6([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_6([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_6([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_6([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_6([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_6([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_6([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_6([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_6_5([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_6\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid, i==n-1)\n",
    "            \n",
    "    # reverse order of guide 6\n",
    "    def guide_7_1(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_7([obs, hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_7([obs, hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_7([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_7([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_7([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_7([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_7([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_7([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_7([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_7([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_7([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_7([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_7([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_7([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_7([hid, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_7\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "\n",
    "def generate_data():\n",
    "    \n",
    "    n_min = 2\n",
    "    n_max = 4\n",
    "    n = random.randint(n_min, n_max)\n",
    "    mu = 0\n",
    "    x_len = 8\n",
    "    for i in range(n):\n",
    "        x_noise = torch.randn(x_len) / 4\n",
    "        x_mean = torch.zeros(x_len) + mu\n",
    "        xs = torch.normal(x_mean, 1) + x_noise\n",
    "        ys = []\n",
    "        j = 0\n",
    "        while j < len(xs):\n",
    "            y = dist.Normal(xs[j] + xs[j+1], 2).sample()\n",
    "            ys.append(y)\n",
    "            j +=2\n",
    "        \n",
    "        zs = []\n",
    "        j = 0\n",
    "        while j < len(ys):\n",
    "            z = dist.Normal(ys[j] + ys[j+1], 1.5).sample()\n",
    "            zs.append(z)\n",
    "            j +=2\n",
    "        \n",
    "        \n",
    "        mu = dist.Normal(zs[0] + zs[1], 1).sample() / 10\n",
    "        \n",
    "    return n, mu\n",
    "    \n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "print(len(data))\n",
    "experiment = Experiment()\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_5_1 # guide_1\n",
    "\n",
    "#guide = AutoNormal(experiment.model)\n",
    "#guide = AutoMultivariateNormal(experiment.model)\n",
    "#guide = AutoDiagonalNormal(experiment.model)\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "n_steps = 100\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for n, obs in data:\n",
    "        imme_loss += svi.step(n, obs) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-cooler",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-f53fe101f39d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-f53fe101f39d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [Step 10/100] Immediate Loss: 16.603609305918223 Accumlated Loss: 17.500606958180665\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# guide 1\n",
    "[Step 10/100] Immediate Loss: 16.603609305918223 Accumlated Loss: 17.500606958180665\n",
    "[Step 20/100] Immediate Loss: 16.855222098529346 Accumlated Loss: 16.53769266751409\n",
    "[Step 30/100] Immediate Loss: 16.61340282350778 Accumlated Loss: 16.44754036000371\n",
    "[Step 40/100] Immediate Loss: 16.639495956003664 Accumlated Loss: 16.511027759164573\n",
    "[Step 50/100] Immediate Loss: 16.672798728644846 Accumlated Loss: 16.288147088468072\n",
    "[Step 60/100] Immediate Loss: 15.51634753286839 Accumlated Loss: 16.147792665868998\n",
    "[Step 70/100] Immediate Loss: 16.15346024602652 Accumlated Loss: 16.479967122495175\n",
    "[Step 80/100] Immediate Loss: 16.921821166276924 Accumlated Loss: 16.31915638077259\n",
    "[Step 90/100] Immediate Loss: 16.854187341928487 Accumlated Loss: 16.46668990969658\n",
    "[Step 100/100] Immediate Loss: 16.871344230473042 Accumlated Loss: 16.57739174258709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_1_1\n",
    "[Step 10/100] Immediate Loss: 15.405036453008657 Accumlated Loss: 16.567898606568573\n",
    "[Step 20/100] Immediate Loss: 15.315322809517381 Accumlated Loss: 14.818533999025824\n",
    "[Step 30/100] Immediate Loss: 15.073404014706613 Accumlated Loss: 14.959100090563297\n",
    "[Step 40/100] Immediate Loss: 15.015228279531001 Accumlated Loss: 14.96936491960287\n",
    "[Step 50/100] Immediate Loss: 14.918855044841766 Accumlated Loss: 14.759386096328498\n",
    "[Step 60/100] Immediate Loss: 14.40674435824156 Accumlated Loss: 14.771602175533772\n",
    "[Step 70/100] Immediate Loss: 15.165615375936037 Accumlated Loss: 14.7810275374949\n",
    "[Step 80/100] Immediate Loss: 15.034084392786028 Accumlated Loss: 14.678286084234713\n",
    "[Step 90/100] Immediate Loss: 15.191696979701518 Accumlated Loss: 14.863868380397557\n",
    "[Step 100/100] Immediate Loss: 15.040978074073792 Accumlated Loss: 14.984134002029897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 2\n",
    "[Step 10/100] Immediate Loss: 16.53637493014335 Accumlated Loss: 17.82483194971085\n",
    "[Step 20/100] Immediate Loss: 16.898313095867625 Accumlated Loss: 16.53944434913993\n",
    "[Step 30/100] Immediate Loss: 16.60898330211639 Accumlated Loss: 16.47968623232841\n",
    "[Step 40/100] Immediate Loss: 16.916094422936442 Accumlated Loss: 16.544766229629516\n",
    "[Step 50/100] Immediate Loss: 16.653268249630926 Accumlated Loss: 16.30891268196702\n",
    "[Step 60/100] Immediate Loss: 15.60279467880726 Accumlated Loss: 16.188707690000534\n",
    "[Step 70/100] Immediate Loss: 16.153162809610365 Accumlated Loss: 16.51425990137458\n",
    "[Step 80/100] Immediate Loss: 16.824226024448862 Accumlated Loss: 16.28886511611939\n",
    "[Step 90/100] Immediate Loss: 16.817774320542814 Accumlated Loss: 16.44661551308632\n",
    "[Step 100/100] Immediate Loss: 16.876233668029304 Accumlated Loss: 16.555098087757827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3\n",
    "[Step 10/100] Immediate Loss: 8.415327407419678 Accumlated Loss: 11.498703305780886\n",
    "[Step 20/100] Immediate Loss: 8.043657022416593 Accumlated Loss: 8.405316677957774\n",
    "[Step 30/100] Immediate Loss: 8.108019524812699 Accumlated Loss: 8.060190771579743\n",
    "[Step 40/100] Immediate Loss: 7.697562502324582 Accumlated Loss: 7.9920230777263646\n",
    "[Step 50/100] Immediate Loss: 7.802509233653544 Accumlated Loss: 7.910115442633629\n",
    "[Step 60/100] Immediate Loss: 7.558712151944635 Accumlated Loss: 7.8478527779877165\n",
    "[Step 70/100] Immediate Loss: 7.722976427972315 Accumlated Loss: 7.957533201217653\n",
    "[Step 80/100] Immediate Loss: 8.078438448607923 Accumlated Loss: 7.904014632731676\n",
    "[Step 90/100] Immediate Loss: 7.835504165589809 Accumlated Loss: 7.93654251345992\n",
    "[Step 100/100] Immediate Loss: 8.02648012071848 Accumlated Loss: 7.913111192643644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3_1\n",
    "[Step 10/100] Immediate Loss: 7.976721602976321 Accumlated Loss: 11.208176284015178\n",
    "[Step 20/100] Immediate Loss: 7.340050332546234 Accumlated Loss: 7.611965912491085\n",
    "[Step 30/100] Immediate Loss: 7.174539146125315 Accumlated Loss: 7.194422878086567\n",
    "[Step 40/100] Immediate Loss: 6.969421552419663 Accumlated Loss: 7.003796048998833\n",
    "[Step 50/100] Immediate Loss: 6.85749923378229 Accumlated Loss: 6.960429052740335\n",
    "[Step 60/100] Immediate Loss: 6.770355449914931 Accumlated Loss: 6.947518035501241\n",
    "[Step 70/100] Immediate Loss: 6.968021876811979 Accumlated Loss: 6.909947348475457\n",
    "[Step 80/100] Immediate Loss: 6.7442953109741195 Accumlated Loss: 6.852114373832941\n",
    "[Step 90/100] Immediate Loss: 7.055515655577184 Accumlated Loss: 6.904237525612117\n",
    "[Step 100/100] Immediate Loss: 6.855357233881947 Accumlated Loss: 6.878291214913128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 4\n",
    "[Step 10/100] Immediate Loss: 8.412366735637185 Accumlated Loss: 11.58804526951909\n",
    "[Step 20/100] Immediate Loss: 7.620528174340723 Accumlated Loss: 8.117158968150616\n",
    "[Step 30/100] Immediate Loss: 7.507575120925904 Accumlated Loss: 7.495831482052805\n",
    "[Step 40/100] Immediate Loss: 7.241149998307226 Accumlated Loss: 7.271010927528143\n",
    "[Step 50/100] Immediate Loss: 7.176193792521955 Accumlated Loss: 7.2575744364559664\n",
    "[Step 60/100] Immediate Loss: 7.031586802303793 Accumlated Loss: 7.2102126263678095\n",
    "[Step 70/100] Immediate Loss: 7.122065619230268 Accumlated Loss: 7.232378738999365\n",
    "[Step 80/100] Immediate Loss: 7.09476718723774 Accumlated Loss: 7.145543646603825\n",
    "[Step 90/100] Immediate Loss: 7.227772540450097 Accumlated Loss: 7.208026203006506\n",
    "[Step 100/100] Immediate Loss: 7.177712733447549 Accumlated Loss: 7.156796397238969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5\n",
    "[Step 10/100] Immediate Loss: 7.679914959967138 Accumlated Loss: 11.146925537139177\n",
    "[Step 20/100] Immediate Loss: 7.402561833262443 Accumlated Loss: 7.687605341851713\n",
    "[Step 30/100] Immediate Loss: 7.527886668145655 Accumlated Loss: 7.457448011845348\n",
    "[Step 40/100] Immediate Loss: 7.222513418495657 Accumlated Loss: 7.313801758021116\n",
    "[Step 50/100] Immediate Loss: 7.16132085621357 Accumlated Loss: 7.257306525290014\n",
    "[Step 60/100] Immediate Loss: 6.999031591117379 Accumlated Loss: 7.231975407689809\n",
    "[Step 70/100] Immediate Loss: 7.138659704625605 Accumlated Loss: 7.257016090214251\n",
    "[Step 80/100] Immediate Loss: 7.159046270549299 Accumlated Loss: 7.169736366331577\n",
    "[Step 90/100] Immediate Loss: 7.258842664659023 Accumlated Loss: 7.2010674090683455\n",
    "[Step 100/100] Immediate Loss: 7.179027948081492 Accumlated Loss: 7.147476496934891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-pursuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 6\n",
    "[Step 10/100] Immediate Loss: 8.04401047885418 Accumlated Loss: 11.082960224151615\n",
    "[Step 20/100] Immediate Loss: 7.350265638232232 Accumlated Loss: 7.690995964407919\n",
    "[Step 30/100] Immediate Loss: 7.354677459895612 Accumlated Loss: 7.346195358514786\n",
    "[Step 40/100] Immediate Loss: 7.319640446305273 Accumlated Loss: 7.257187823802232\n",
    "[Step 50/100] Immediate Loss: 7.114424621164799 Accumlated Loss: 7.2349098056256755\n",
    "[Step 60/100] Immediate Loss: 7.000591119229795 Accumlated Loss: 7.190674315929415\n",
    "[Step 70/100] Immediate Loss: 7.1216690900921815 Accumlated Loss: 7.242568220317363\n",
    "[Step 80/100] Immediate Loss: 7.07743655323982 Accumlated Loss: 7.168465733110905\n",
    "[Step 90/100] Immediate Loss: 7.276139043867588 Accumlated Loss: 7.185225244760513\n",
    "[Step 100/100] Immediate Loss: 7.260971570909022 Accumlated Loss: 7.150297306448221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5_1 new (no obs in hid)\n",
    "[Step 10/100] Immediate Loss: 7.798764485716818 Accumlated Loss: 10.695049868911504\n",
    "[Step 20/100] Immediate Loss: 7.175654533207414 Accumlated Loss: 7.41971659642458\n",
    "[Step 30/100] Immediate Loss: 7.064808929860589 Accumlated Loss: 7.102920457333326\n",
    "[Step 40/100] Immediate Loss: 7.0074234905839 Accumlated Loss: 6.9630768875181674\n",
    "[Step 50/100] Immediate Loss: 6.9895634829998015 Accumlated Loss: 6.904858220517634\n",
    "[Step 60/100] Immediate Loss: 6.930768578052519 Accumlated Loss: 6.851308759361505\n",
    "[Step 70/100] Immediate Loss: 6.801801775097844 Accumlated Loss: 6.917650807946919\n",
    "[Step 80/100] Immediate Loss: 6.898209309875968 Accumlated Loss: 6.852221962392329\n",
    "[Step 90/100] Immediate Loss: 6.877323675155637 Accumlated Loss: 6.880460332095623\n",
    "[Step 100/100] Immediate Loss: 6.808387375473978 Accumlated Loss: 6.813448920100927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 6_1 (not faithful minimum z_{n-2} depends on obs)\n",
    "[Step 10/100] Immediate Loss: 7.885890662968158 Accumlated Loss: 11.057994169056414\n",
    "[Step 20/100] Immediate Loss: 7.1814592292904855 Accumlated Loss: 7.406067954629658\n",
    "[Step 30/100] Immediate Loss: 7.0591789925098425 Accumlated Loss: 7.035171322673558\n",
    "[Step 40/100] Immediate Loss: 6.9713214033842075 Accumlated Loss: 6.915649327993392\n",
    "[Step 50/100] Immediate Loss: 6.843805762827397 Accumlated Loss: 6.919330851316452\n",
    "[Step 60/100] Immediate Loss: 6.76589316159487 Accumlated Loss: 6.893545565813779\n",
    "[Step 70/100] Immediate Loss: 6.883703918159004 Accumlated Loss: 6.874835347026586\n",
    "[Step 80/100] Immediate Loss: 6.6349282276630435 Accumlated Loss: 6.812026571363211\n",
    "[Step 90/100] Immediate Loss: 7.005292106866837 Accumlated Loss: 6.86639387100935\n",
    "[Step 100/100] Immediate Loss: 6.807221605777738 Accumlated Loss: 6.843064952969551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 6_1 new\n",
    "[Step 10/100] Immediate Loss: 8.034564805030824 Accumlated Loss: 10.936746909648178\n",
    "[Step 20/100] Immediate Loss: 7.2499518311023685 Accumlated Loss: 7.311040770947934\n",
    "[Step 30/100] Immediate Loss: 7.010845541954039 Accumlated Loss: 7.095756838709114\n",
    "[Step 40/100] Immediate Loss: 7.101395113170147 Accumlated Loss: 6.971324785619975\n",
    "[Step 50/100] Immediate Loss: 6.966120596230027 Accumlated Loss: 6.913172000795602\n",
    "[Step 60/100] Immediate Loss: 7.045844776928422 Accumlated Loss: 6.8633523593246935\n",
    "[Step 70/100] Immediate Loss: 6.736625478863718 Accumlated Loss: 6.842792760789395\n",
    "[Step 80/100] Immediate Loss: 6.77222544580698 Accumlated Loss: 6.860924880445005\n",
    "[Step 90/100] Immediate Loss: 6.821978591084481 Accumlated Loss: 6.829650913029909\n",
    "[Step 100/100] Immediate Loss: 6.715206724703313 Accumlated Loss: 6.8137665010094635\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_7_1\n",
    "[Step 10/100] Immediate Loss: 8.38313128709793 Accumlated Loss: 10.969374058961867\n",
    "[Step 20/100] Immediate Loss: 7.69058747321367 Accumlated Loss: 7.877735597521067\n",
    "[Step 30/100] Immediate Loss: 7.495600021481516 Accumlated Loss: 7.5363140018284325\n",
    "[Step 40/100] Immediate Loss: 7.57074495017528 Accumlated Loss: 7.361504468172787\n",
    "[Step 50/100] Immediate Loss: 7.164207778871061 Accumlated Loss: 7.297698376446963\n",
    "[Step 60/100] Immediate Loss: 7.380789618790149 Accumlated Loss: 7.335570410102605\n",
    "[Step 70/100] Immediate Loss: 7.460530654788017 Accumlated Loss: 7.312247537493706\n",
    "[Step 80/100] Immediate Loss: 7.276985189020634 Accumlated Loss: 7.301681690573693\n",
    "[Step 90/100] Immediate Loss: 7.284309602677822 Accumlated Loss: 7.3195110925138\n",
    "[Step 100/100] Immediate Loss: 7.063885845839978 Accumlated Loss: 7.220875202089547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoNormal\n",
    "[Step 20/100] Immediate Loss: 231.93802900791167 Accumlated Loss: 200.761366689831\n",
    "[Step 30/100] Immediate Loss: 145.4057659590245 Accumlated Loss: 189.43566401064396\n",
    "[Step 40/100] Immediate Loss: 206.4568299674988 Accumlated Loss: 183.3614013262093\n",
    "[Step 50/100] Immediate Loss: 186.81535023331642 Accumlated Loss: 194.59418309175967\n",
    "[Step 60/100] Immediate Loss: 130.78142770648 Accumlated Loss: 197.2631957063079\n",
    "[Step 70/100] Immediate Loss: 293.09487274050707 Accumlated Loss: 193.73477647870777\n",
    "[Step 80/100] Immediate Loss: 198.1808698946237 Accumlated Loss: 183.9554884995222\n",
    "[Step 90/100] Immediate Loss: 185.13244871318344 Accumlated Loss: 191.2238412671089\n",
    "[Step 100/100] Immediate Loss: 194.92827344238745 Accumlated Loss: 188.82500050365925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoMultivariateNormal\n",
    "[Step 10/100] Immediate Loss: 1235.3812578570842 Accumlated Loss: 1236.1352865802646\n",
    "[Step 20/100] Immediate Loss: 1210.2978770101067 Accumlated Loss: 1216.1027867695093\n",
    "[Step 30/100] Immediate Loss: 1229.688204897046 Accumlated Loss: 1205.0053660194872\n",
    "[Step 40/100] Immediate Loss: 1200.555576323867 Accumlated Loss: 1192.0478162692784\n",
    "[Step 50/100] Immediate Loss: 1191.1188332122565 Accumlated Loss: 1196.5321274908779\n",
    "[Step 60/100] Immediate Loss: 1191.3697812026737 Accumlated Loss: 1206.1590484446883\n",
    "[Step 70/100] Immediate Loss: 1189.0993092578653 Accumlated Loss: 1185.5664499574898\n",
    "[Step 80/100] Immediate Loss: 1184.2317881757021 Accumlated Loss: 1193.5602444505096\n",
    "[Step 90/100] Immediate Loss: 1213.3458593541382 Accumlated Loss: 1189.3086517564059\n",
    "[Step 100/100] Immediate Loss: 1194.0520617479087 Accumlated Loss: 1196.8081811218856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDiagonalNormal\n",
    "[Step 10/100] Immediate Loss: 1235.8018628519776 Accumlated Loss: 1236.249700816393\n",
    "[Step 20/100] Immediate Loss: 1212.7352848732473 Accumlated Loss: 1217.2863890322446\n",
    "[Step 30/100] Immediate Loss: 1233.1168017601972 Accumlated Loss: 1208.195502301395\n",
    "[Step 40/100] Immediate Loss: 1205.5053979098793 Accumlated Loss: 1196.19749720788\n",
    "[Step 50/100] Immediate Loss: 1196.6777249866725 Accumlated Loss: 1201.5737289296987\n",
    "[Step 60/100] Immediate Loss: 1195.7460924953223 Accumlated Loss: 1211.1477473101022\n",
    "[Step 70/100] Immediate Loss: 1194.371914086938 Accumlated Loss: 1191.4428508981468\n",
    "[Step 80/100] Immediate Loss: 1189.6923706567293 Accumlated Loss: 1199.3408790806534\n",
    "[Step 90/100] Immediate Loss: 1220.8790620434281 Accumlated Loss: 1195.186482142985\n",
    "[Step 100/100] Immediate Loss: 1201.1263765621195 Accumlated Loss: 1203.2602218962313"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
