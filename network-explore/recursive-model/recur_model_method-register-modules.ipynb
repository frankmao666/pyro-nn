{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "established-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as TNF\n",
    "import pyro as P\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as PD\n",
    "from pyro.nn import PyroModule, PyroParam, PyroSample\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "\n",
    "\n",
    "class simpleNNNormal(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=16, out_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden)\n",
    "        self.loc_layer = nn.Linear(hidden, out_size)\n",
    "        self.std_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        x = TNF.relu(self.hidden_layer(x_list))\n",
    "        loc = self.loc_layer(x)\n",
    "        std = self.std_layer(x)\n",
    "        return loc, std\n",
    "\n",
    "class simpleNNHidden(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=16, out_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden)\n",
    "        self.out_layer = nn.Linear(hidden, out_size)\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        x = TNF.relu(self.hidden_layer(x_list))\n",
    "        return self.out_layer(x)\n",
    "\n",
    "\n",
    "hid_size = 3\n",
    "\n",
    "nn_model_core_hidden = simpleNNHidden(out_size=hid_size)\n",
    "nn_q__i = simpleNNHidden(input_size=hid_size)\n",
    "nn_xp__i = simpleNNNormal(input_size=hid_size)\n",
    "nn_y2__i = simpleNNNormal(input_size=hid_size + 1)\n",
    "nn_y1__i =  simpleNNNormal(input_size=hid_size + 1)\n",
    "nn_core_hidden = simpleNNHidden(input_size=hid_size, out_size=hid_size)\n",
    "#nn_core_hidden = simpleNNHidden(input_size=hid_size + 1, out_size=hid_size)\n",
    "\n",
    "def core_guide(hidden, x, i=0):\n",
    "    q__i_prob, = nn_q__i(hidden)\n",
    "    q = P.sample(f'q_{i}', PD.Bernoulli(T.sigmoid(q__i_prob)))\n",
    "    #cond = P.deterministic(f\"cond_{i}\", q < 0.5)\n",
    "    #if cond:\n",
    "    if q < 0.5:\n",
    "        return x\n",
    "    else:\n",
    "        xp__i_mean, xp__i_std = nn_xp__i(hidden)\n",
    "        xp = P.sample(f'xp_{i}', PD.Normal(xp__i_mean, TNF.softplus(xp__i_std)))\n",
    "        y2__i_mean, y2__i_std = nn_y2__i(T.cat([hidden, T.tensor([xp])]))\n",
    "        y2 = P.sample(f'y2_{i}', PD.Normal(y2__i_mean, TNF.softplus(y2__i_std)))\n",
    "        y1__i_mean, y1__i_std = nn_y1__i(T.cat([hidden, T.tensor([y2])]))\n",
    "        y1 = P.sample(f'y1_{i}', PD.Normal(y1__i_mean, TNF.softplus(y1__i_std)))\n",
    "        return core_guide(nn_core_hidden(hidden), xp, i + 1) # nn_core_hidden should take x\n",
    "        #return core_guide(nn_core_hidden(T.cat([hidden, T.tensor([q__i_prob])])), xp, i + 1) # nn_core_hidden should take x\n",
    "\n",
    "def guide(obs):\n",
    "    P.module(\"guidenn_1\", nn_model_core_hidden)\n",
    "    P.module(\"guidenn_2\", nn_q__i)\n",
    "    P.module(\"guidenn_3\", nn_xp__i)\n",
    "    P.module(\"guidenn_4\", nn_y2__i)\n",
    "    P.module(\"guidenn_5\", nn_y1__i)\n",
    "    P.module(\"guidenn_6\", nn_core_hidden)\n",
    "    r = core_guide(nn_model_core_hidden(T.tensor([obs])), 0.0, i=0)\n",
    "\n",
    "def core_model(x, i=0):\n",
    "    q = P. sample (f\"q_{i}\", PD. Bernoulli (T. tensor (0.5)))\n",
    "    if q < 0.5:\n",
    "        return x\n",
    "    else :\n",
    "        y1 = P.sample (f'y1_{i}', PD.Normal(x, 0.1))\n",
    "        y2 = P.sample (f'y2_{i}', PD.Normal(y1 , 0.1))\n",
    "        xp = P.sample (f'xp_{i}', PD.Normal(y2 , 0.1))\n",
    "        return core_model(xp , i+1) + x\n",
    "\n",
    "def model(obs):\n",
    "    r = core_model(0.0,i=0)\n",
    "    return P.sample(\"r\", PD.Normal(r ,0.01) , obs=obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10/200] Immediate Loss: 451.4602196265757 Accumlated Loss: 793.7536484837383\n",
      "[Step 20/200] Immediate Loss: 229.44013524167252 Accumlated Loss: 358.7724746289477\n",
      "[Step 30/200] Immediate Loss: 99.74989255601537 Accumlated Loss: 199.42344435065334\n",
      "[Step 40/200] Immediate Loss: 56.224246747265575 Accumlated Loss: 141.6763683039278\n",
      "[Step 50/200] Immediate Loss: 148.46230420928856 Accumlated Loss: 135.958261369531\n",
      "[Step 60/200] Immediate Loss: 129.8268276126356 Accumlated Loss: 60.237155390869496\n",
      "[Step 70/200] Immediate Loss: 26.011371933324412 Accumlated Loss: 30.07615272825404\n",
      "[Step 80/200] Immediate Loss: 11.038791142533391 Accumlated Loss: 19.472201776273987\n",
      "[Step 90/200] Immediate Loss: 6.9147539241502285 Accumlated Loss: 7.6087177703324445\n",
      "[Step 100/200] Immediate Loss: 3.6030296424641994 Accumlated Loss: 5.132802795604141\n",
      "[Step 110/200] Immediate Loss: 4.247810385392296 Accumlated Loss: 10.262509550340054\n",
      "[Step 120/200] Immediate Loss: 3.620147859739383 Accumlated Loss: 3.79602208092677\n",
      "[Step 130/200] Immediate Loss: 3.356815615184042 Accumlated Loss: 4.066431196454624\n"
     ]
    }
   ],
   "source": [
    "def gen_data(n=100):\n",
    "    d = []\n",
    "    for _ in range(n):\n",
    "        d.append(model(obs=None))\n",
    "    return d\n",
    "\n",
    "data = gen_data()\n",
    "P.clear_param_store()\n",
    "num_data = len(data)\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 200\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    for obs in data:\n",
    "        imme_loss += svi.step(obs) / num_data\n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "\n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-bundle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
