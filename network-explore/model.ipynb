{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optional-directory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10/200] Immediate Loss: 9.739119054973125 Accumlated Loss: 26.231376632422215\n",
      "[Step 20/200] Immediate Loss: 8.562010218501092 Accumlated Loss: 9.004294203996658\n",
      "[Step 30/200] Immediate Loss: 7.791197156310078 Accumlated Loss: 7.894150669425726\n",
      "[Step 40/200] Immediate Loss: 6.953114957809449 Accumlated Loss: 7.290794907361269\n",
      "[Step 50/200] Immediate Loss: 6.470913594663144 Accumlated Loss: 7.313350498646497\n",
      "[Step 60/200] Immediate Loss: 7.192049302458762 Accumlated Loss: 7.292813739836216\n",
      "[Step 70/200] Immediate Loss: 6.985135128498076 Accumlated Loss: 6.960749062150716\n",
      "[Step 80/200] Immediate Loss: 7.511157349348067 Accumlated Loss: 6.920082948744298\n",
      "[Step 90/200] Immediate Loss: 6.9557847833633435 Accumlated Loss: 6.778018771708012\n",
      "[Step 100/200] Immediate Loss: 6.37305668503046 Accumlated Loss: 6.9952442568838595\n",
      "[Step 110/200] Immediate Loss: 6.0351421809196495 Accumlated Loss: 6.663454451084136\n",
      "[Step 120/200] Immediate Loss: 6.581840452551844 Accumlated Loss: 6.540336384534834\n",
      "[Step 130/200] Immediate Loss: 6.6818000665307045 Accumlated Loss: 6.712281311541796\n",
      "[Step 140/200] Immediate Loss: 6.617580278217792 Accumlated Loss: 6.496850828737021\n",
      "[Step 150/200] Immediate Loss: 7.234807396829125 Accumlated Loss: 6.653334019452332\n",
      "[Step 160/200] Immediate Loss: 5.998593208491804 Accumlated Loss: 6.719098333090543\n",
      "[Step 170/200] Immediate Loss: 6.206380138993265 Accumlated Loss: 6.537967252045871\n",
      "[Step 180/200] Immediate Loss: 7.530555124878885 Accumlated Loss: 6.638299534082414\n",
      "[Step 190/200] Immediate Loss: 6.48846746265888 Accumlated Loss: 6.428936375379562\n",
      "[Step 200/200] Immediate Loss: 6.436221255958077 Accumlated Loss: 6.4630335935950285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32):\n",
    "        super().__init__()\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        self.loc_layer = nn.Linear(hidden, 1)\n",
    "        self.std_layer = nn.Linear(hidden, 1)\n",
    "        self.softplus = nn.Softplus()\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 0:\n",
    "            x = torch.unsqueeze(x, dim=0)\n",
    "        hid = F.relu(self.hiddeen_layer(x))\n",
    "        # return loc, std\n",
    "        return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "\n",
    "# NN used for p(h | x, obs, n)\n",
    "class simpleHidNN(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden=32):\n",
    "        super().__init__()\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        self.loc_layer = nn.Linear(hidden, 1)\n",
    "        self.std_layer = nn.Linear(hidden, 1)\n",
    "        self.softplus = nn.Softplus()\n",
    "    def forward(self, x, obs, n):\n",
    "        if x.dim() == 0:\n",
    "            x = torch.unsqueeze(x, dim=0)\n",
    "        if obs.dim() == 0:\n",
    "            obs = torch.unsqueeze(obs, dim=0)\n",
    "        if n.dim() == 0:\n",
    "            n = torch.unsqueeze(n, dim=0)\n",
    "        \n",
    "        input_x = torch.cat([x, obs, n]) # one hot n\n",
    "        #print(input_x)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "\n",
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=32, max_l=5, max_t=3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size + max_l + max_t, hidden_size=hidden_size, nonlinearity='relu',\n",
    "                          batch_first=True, num_layers=1)\n",
    "        self.h_0 = nn.Parameter(torch.zeros((1, 1, hidden_size)))\n",
    "        self.out_loc = nn.Linear(hidden_size, 1)\n",
    "        self.out_std = nn.Linear(hidden_size, 1)\n",
    "        self.max_l = max_l # max time steps\n",
    "        self.max_t = max_t # type of random variables, ex. y1 y2 next_x\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x, obs, l, t):\n",
    "        \"\"\"\n",
    "        x: x0\n",
    "        obs: R\n",
    "        l: length\n",
    "        t: type, y1, y2 or next_x\n",
    "        \"\"\"\n",
    "        length = l * 3\n",
    "        input_x = x.repeat((int(length), 1))\n",
    "        input_obs = obs.repeat((int(length), 1))\n",
    "        input_l = []\n",
    "        input_t = []\n",
    "        \n",
    "        for n in range(int(l)):\n",
    "            \n",
    "            for i in range(int(t)):\n",
    "                input_l.append(n)\n",
    "                input_t.append(i)\n",
    "        input_l = F.one_hot(torch.tensor(input_l), self.max_l) \n",
    "        input_t = F.one_hot(torch.tensor(input_t), self.max_t) \n",
    "        \n",
    "        input_ = torch.unsqueeze(torch.cat([input_x, input_obs, input_l, input_t], -1), 0)\n",
    "        \n",
    "        # the input is [x, obs, onehot(l), onehot(t)]\n",
    "        rnn_output, _ = self.rnn(input_, self.h_0)\n",
    "        rnn_output = torch.squeeze(rnn_output, 0)\n",
    "        out_loc = self.out_loc(F.relu(rnn_output))\n",
    "        out_std = self.softplus(self.out_std(F.relu(rnn_output)))\n",
    "        # the first outputs are y_1_1, y_2_1, next_x_1; y_1_2, y_2_2, next_x_2\n",
    "        return torch.squeeze(out_loc, 1), torch.squeeze(out_std, 1) # shape l * t\n",
    "        \n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x_y1_nn = simpleNN()\n",
    "        self.y1_y2_nn = simpleNN()\n",
    "        self.y_h_nn = simpleHidNN()\n",
    "        self.simrnn = simpleRNN()\n",
    "    \n",
    "    # assume the model has two latent variables in each time step (note that groundtruth data gen has 3)\n",
    "    # as we cannot build the perfect model in real life problems\n",
    "    def model(self, x0, l, obs_R):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_model(x, n):\n",
    "            r = torch.tanh(x)\n",
    "            if n <= 0:\n",
    "                return r\n",
    "            else:\n",
    "                y_1 = pyro.sample(\"y_1_{}\".format(n), dist.Normal(x, 0.5))\n",
    "             \n",
    "                y_2 = pyro.sample(\"y_2_{}\".format(n), dist.Normal(y_1, 0.5))\n",
    "            \n",
    "                next_x = pyro.sample(\"next_x_{}\".format(n), dist.Normal(y_2, 0.5))\n",
    "                return rec_model(next_x, n - 1) + r\n",
    "    \n",
    "        R = rec_model(x0, l)\n",
    "    \n",
    "        pyro.sample(\"obs_R\", dist.Normal(R, 0.1), obs=obs_R)\n",
    "    \n",
    "    # guide uses simple and individual NN for each random variable\n",
    "    def guide1(self, x0, l, obs_R):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_guide(x, n, obs_R):\n",
    "            r = torch.tanh(x)\n",
    "            if n <= 0:\n",
    "                return r\n",
    "            else:\n",
    "                y_1_loc, y_1_std = self.x_y1_nn(x) # maybe input n as well\n",
    "                y_1 = pyro.sample(\"y_1_{}\".format(n), dist.Normal(y_1_loc, y_1_std))\n",
    "                \n",
    "                y_2_loc, y_2_std = self.y1_y2_nn(y_1) # maybe input n as well\n",
    "                y_2 = pyro.sample(\"y_2_{}\".format(n), dist.Normal(y_2_loc, y_2_std))\n",
    "                \n",
    "                h_1_loc, h_1_std = self.y_h_nn(y_2, obs_R, n)\n",
    "            \n",
    "                next_x = pyro.sample(\"next_x_{}\".format(n), dist.Normal(h_1_loc, h_1_std))\n",
    "                return rec_guide(next_x, n - 1, obs_R) + r\n",
    "    \n",
    "        rec_guide(x0, l, obs_R)\n",
    "    \n",
    "    # guide uses a RNN to estimate distributions of all random variables\n",
    "    def guide_rnn(self, x0, l, obs_R):\n",
    "        pyro.module(\"model\", self)\n",
    "        t = 3\n",
    "        out_loc, out_std = self.simrnn(x0, obs_R, l, t)\n",
    "        \n",
    "        for i in range(int(l)):\n",
    "            pyro.sample(\"y_1_{}\".format(l - i), dist.Normal(out_loc[i * t], out_std[i * t])) # maybe i here?\n",
    "            pyro.sample(\"y_2_{}\".format(l - i), dist.Normal(out_loc[i * t + 1], out_std[i * t + 1])) # maybe i here?\n",
    "            pyro.sample(\"next_x_{}\".format(l - i), dist.Normal(out_loc[i * t + 2], out_std[i * t + 2])) # maybe i here?\n",
    "        \n",
    "def generate_data():\n",
    "    # the actual data generation has three latent variables (y_1, y_2, y_3)\n",
    "    x0 = torch.tensor(random.random())\n",
    "    base_std = 0.6\n",
    "    l = torch.tensor(random.randint(2, 5))\n",
    "    R = 0\n",
    "    x = x0\n",
    "    for i in range(l):\n",
    "        # standard deviation is decreasing\n",
    "        std = base_std - i * 0.1\n",
    "        R += torch.tanh(x)\n",
    "        \n",
    "        y_1 = dist.Normal(x, std).sample()\n",
    "        # add some noise\n",
    "        noise1 = random.random() / 5\n",
    "        \n",
    "        y_2 = dist.Normal(y_1 + noise1, std).sample()\n",
    "        # add some noise\n",
    "        \n",
    "        noise2 = random.random() / 5\n",
    "        \n",
    "        y_3 = dist.Normal(y_2 + noise2, std).sample()\n",
    "        # add some noise\n",
    "        \n",
    "        noise3 = random.random() / 5\n",
    "        \n",
    "        x = dist.Normal(y_3 + noise3, std).sample()\n",
    "    return x0.float(), l.float(), R.float()\n",
    "\n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "experiment = Experiment()\n",
    "\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_rnn # guide1\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 200\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for x0, l, R in data:\n",
    "        imme_loss += svi.step(x0, l, R) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "correct-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 1\n",
    "# [Step 10/200] Immediate Loss: 12.392816262543208 Accumlated Loss: 61.896947796434155\n",
    "# [Step 20/200] Immediate Loss: 12.534820085167881 Accumlated Loss: 13.437604224234818\n",
    "# [Step 30/200] Immediate Loss: 13.17098607122898 Accumlated Loss: 12.086684818983079\n",
    "# [Step 40/200] Immediate Loss: 9.71128015607596 Accumlated Loss: 10.062380458921194\n",
    "# [Step 50/200] Immediate Loss: 9.27166577726603 Accumlated Loss: 9.88789534020424\n",
    "# [Step 60/200] Immediate Loss: 9.207814403772359 Accumlated Loss: 9.479010441660883\n",
    "# [Step 70/200] Immediate Loss: 9.252625642120845 Accumlated Loss: 8.992603824317458\n",
    "# [Step 80/200] Immediate Loss: 10.557749922871592 Accumlated Loss: 9.136339780330657\n",
    "# [Step 90/200] Immediate Loss: 8.99829298526049 Accumlated Loss: 8.37839320459962\n",
    "# [Step 100/200] Immediate Loss: 8.004938696920869 Accumlated Loss: 8.489488927960394\n",
    "# [Step 110/200] Immediate Loss: 7.89229125648737 Accumlated Loss: 8.379414085894823\n",
    "# [Step 120/200] Immediate Loss: 8.129241148531435 Accumlated Loss: 8.318989044874906\n",
    "# [Step 130/200] Immediate Loss: 8.806422461569312 Accumlated Loss: 8.2210233835876\n",
    "# [Step 140/200] Immediate Loss: 8.71400465488434 Accumlated Loss: 7.94223985156417\n",
    "# [Step 150/200] Immediate Loss: 8.694025435447697 Accumlated Loss: 8.274115405738355\n",
    "# [Step 160/200] Immediate Loss: 8.1806405210495 Accumlated Loss: 8.218478974461554\n",
    "# [Step 170/200] Immediate Loss: 8.359754337966441 Accumlated Loss: 8.31694264242053\n",
    "# [Step 180/200] Immediate Loss: 8.479736644029616 Accumlated Loss: 8.105229493767023\n",
    "# [Step 190/200] Immediate Loss: 7.703390654921531 Accumlated Loss: 7.726879477888346\n",
    "# [Step 200/200] Immediate Loss: 8.911449470818045 Accumlated Loss: 8.240651454150676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "destroyed-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide rnn\n",
    "# [Step 10/200] Immediate Loss: 9.739119054973125 Accumlated Loss: 26.231376632422215\n",
    "# [Step 20/200] Immediate Loss: 8.562010218501092 Accumlated Loss: 9.004294203996658\n",
    "# [Step 30/200] Immediate Loss: 7.791197156310078 Accumlated Loss: 7.894150669425726\n",
    "# [Step 40/200] Immediate Loss: 6.953114957809449 Accumlated Loss: 7.290794907361269\n",
    "# [Step 50/200] Immediate Loss: 6.470913594663144 Accumlated Loss: 7.313350498646497\n",
    "# [Step 60/200] Immediate Loss: 7.192049302458762 Accumlated Loss: 7.292813739836216\n",
    "# [Step 70/200] Immediate Loss: 6.985135128498076 Accumlated Loss: 6.960749062150716\n",
    "# [Step 80/200] Immediate Loss: 7.511157349348067 Accumlated Loss: 6.920082948744298\n",
    "# [Step 90/200] Immediate Loss: 6.9557847833633435 Accumlated Loss: 6.778018771708012\n",
    "# [Step 100/200] Immediate Loss: 6.37305668503046 Accumlated Loss: 6.9952442568838595\n",
    "# [Step 110/200] Immediate Loss: 6.0351421809196495 Accumlated Loss: 6.663454451084136\n",
    "# [Step 120/200] Immediate Loss: 6.581840452551844 Accumlated Loss: 6.540336384534834\n",
    "# [Step 130/200] Immediate Loss: 6.6818000665307045 Accumlated Loss: 6.712281311541796\n",
    "# [Step 140/200] Immediate Loss: 6.617580278217792 Accumlated Loss: 6.496850828737021\n",
    "# [Step 150/200] Immediate Loss: 7.234807396829125 Accumlated Loss: 6.653334019452332\n",
    "# [Step 160/200] Immediate Loss: 5.998593208491804 Accumlated Loss: 6.719098333090543\n",
    "# [Step 170/200] Immediate Loss: 6.206380138993265 Accumlated Loss: 6.537967252045871\n",
    "# [Step 180/200] Immediate Loss: 7.530555124878885 Accumlated Loss: 6.638299534082414\n",
    "# [Step 190/200] Immediate Loss: 6.48846746265888 Accumlated Loss: 6.428936375379562\n",
    "# [Step 200/200] Immediate Loss: 6.436221255958077 Accumlated Loss: 6.4630335935950285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-geology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-snowboard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-father",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-sixth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-athens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-essay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
