{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standard-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10/100] Immediate Loss: 133.2505471915007 Accumlated Loss: 151.00078135699033\n",
      "[Step 20/100] Immediate Loss: 131.09676937043668 Accumlated Loss: 131.77195127099753\n",
      "[Step 30/100] Immediate Loss: 130.5309797182679 Accumlated Loss: 130.8939816444516\n",
      "[Step 40/100] Immediate Loss: 130.90671580255034 Accumlated Loss: 130.66879585793612\n",
      "[Step 50/100] Immediate Loss: 130.40981076270342 Accumlated Loss: 130.5509652917683\n",
      "[Step 60/100] Immediate Loss: 130.4613345116377 Accumlated Loss: 130.49925536295774\n",
      "[Step 70/100] Immediate Loss: 130.44797495543955 Accumlated Loss: 130.4517231901586\n",
      "[Step 80/100] Immediate Loss: 130.47368122369053 Accumlated Loss: 130.4738130722344\n",
      "[Step 90/100] Immediate Loss: 130.42225397557016 Accumlated Loss: 130.38270727610586\n",
      "[Step 100/100] Immediate Loss: 130.53060866862532 Accumlated Loss: 130.35955410438777\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoNormal, AutoMultivariateNormal\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # guide 1\n",
    "        self.hidden_size_1 = 8\n",
    "        self.x1_net_1 = simpleNN()\n",
    "        self.x2_net_1 = simpleNN()\n",
    "        self.x3_net_1 = simpleNN()\n",
    "        self.x4_net_1 = simpleNN()\n",
    "        self.x5_net_1 = simpleNN()\n",
    "        self.x6_net_1 = simpleNN()\n",
    "        self.x7_net_1 = simpleNN()\n",
    "        self.x8_net_1 = simpleNN()\n",
    "        self.y1_net_1 = simpleNN()\n",
    "        self.y2_net_1 = simpleNN()\n",
    "        self.y3_net_1 = simpleNN()\n",
    "        self.y4_net_1 = simpleNN()\n",
    "        self.z1_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        self.z2_net_1 = simpleNN(self.hidden_size_1 + 1)\n",
    "        \n",
    "        self.h0_1 = nn.Parameter(torch.zeros(self.hidden_size_1))\n",
    "        self.hid_net_1 = simpleNN(self.hidden_size_1 + 8, out_size = self.hidden_size_1, t = \"mlp\")\n",
    "        \n",
    "        # guide 2\n",
    "        self.hidden_size_2 = 8\n",
    "        self.x1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x5_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x6_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x7_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.x8_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y3_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.y4_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z1_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.z2_net_2 = simpleNN(self.hidden_size_2 + 1)\n",
    "        self.h0_2 = nn.Parameter(torch.zeros(self.hidden_size_2))\n",
    "        self.hid_net_2 = simpleNN(self.hidden_size_2 + 8, out_size = self.hidden_size_2, t = \"mlp\")\n",
    "        \n",
    "        # guide 3\n",
    "        self.hidden_size_3 = 8\n",
    "        self.x1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x5_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x6_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.x7_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.x8_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.y3_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.y4_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.z1_net_3 = simpleNN(self.hidden_size_3 + 2)\n",
    "        self.z2_net_3 = simpleNN(self.hidden_size_3 + 1)\n",
    "        self.h0_3 = nn.Parameter(torch.zeros(self.hidden_size_3))\n",
    "        self.hid_net_3 = simpleNN(self.hidden_size_3 + 8, out_size = self.hidden_size_3, t = \"mlp\")\n",
    "\n",
    "        # guide 4\n",
    "        self.hidden_size_4 = 8\n",
    "        self.x1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x5_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x6_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.x7_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.x8_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.y3_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.y4_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.z1_net_4 = simpleNN(self.hidden_size_4 + 2)\n",
    "        self.z2_net_4 = simpleNN(self.hidden_size_4 + 1)\n",
    "        self.h0_4 = nn.Parameter(torch.zeros(self.hidden_size_4))\n",
    "        self.hid_net_4 = simpleNN(self.hidden_size_4 + 8 + 4 + 2, out_size = self.hidden_size_4, t = \"mlp\")\n",
    "        \n",
    "        # guide 5\n",
    "        self.hidden_size_5 = 16\n",
    "        self.x1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x5_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x6_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.x7_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.x8_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.y3_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.y4_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.z1_net_5 = simpleNN(self.hidden_size_5 + 2)\n",
    "        self.z2_net_5 = simpleNN(self.hidden_size_5 + 1)\n",
    "        self.h0_5 = nn.Parameter(torch.zeros(self.hidden_size_5))\n",
    "        self.hid_net_5 = simpleNN(self.hidden_size_5 + 8 + 4 + 2, out_size = self.hidden_size_5, t = \"mlp\")\n",
    "        \n",
    "        # guide 6\n",
    "        self.hidden_size_6 = 8\n",
    "        self.x1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x5_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x6_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.x7_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.x8_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.y3_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.y4_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.z1_net_6 = simpleNN(self.hidden_size_6 + 2)\n",
    "        self.z2_net_6 = simpleNN(self.hidden_size_6 + 1)\n",
    "        self.h0_6 = nn.Parameter(torch.zeros(self.hidden_size_6))\n",
    "        self.hid_net_6 = simpleNN(self.hidden_size_6 + 8 + 4 + 2 + 1, out_size = self.hidden_size_6, t = \"mlp\")\n",
    "    \n",
    "    def model(self, n, obses):\n",
    "        def tree_model(i, mu):\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(mu, 1.0))\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(mu, 1.0))\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(mu, 1.0))\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(mu, 1.0))\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(mu, 1.0))\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(mu, 1.0))\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(mu, 1.0))\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(mu, 1.0))\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(x1+x2, 1.0))\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(x3+x4, 1.0))\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(x5+x6, 1.0))\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(x7+x8, 1.0))\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(y1+y2, 1.0))\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(y3+y4, 1.0))\n",
    "            return pyro.sample(f\"obs{i}\", dist.Normal(z1+z2, 1.0), obs=obses[i])\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        mu = 0\n",
    "        for i in range(n):\n",
    "            mu = tree_model(i, mu)\n",
    "    \n",
    "    # guide 1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_1(self, n, obses):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide_1_1 basically inverse the arrows in the model, add hidden states that z2 depends on\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # different from guide_1 by sample from i = n-1, n-2, ..., 0\n",
    "    def guide_1_1(self, n, obses):\n",
    "        \n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_1([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_1([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_1([z2])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_1([z2])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_1([z1])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_1([z1])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_1([y4])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_1([y4])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_1([y3])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_1([y3])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_1([y2])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_1([y2])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_1([y1])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_1([y1])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_1([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_1\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 2 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    def guide_2(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_2([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_2([obses[i], hid])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_2([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_2([z2, hid])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_2([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_2([z1, hid])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_2([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_2([y4, hid])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_2([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_2([y3, hid])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_2([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_2([y2, hid])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_2([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_2([y1, hid])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_2([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_2\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_3(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 3_1 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled xs (x1,x2...x8)\n",
    "    # sample from i = n-1, n-2, ..., 1, 0\n",
    "    \n",
    "    def guide_3_1(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_3([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_3([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_3([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_3([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_3([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_3([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_3([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_3([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_3([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_3([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_3([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_3([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_3([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_3([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_3([hid, x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_3\n",
    "        for i in range(n-1, -1, -1):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 4 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    \n",
    "    def guide_4(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_4([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_4([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_4([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_4([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_4([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_4([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_4([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_4([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_4([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_4([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_4([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_4([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_4([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_4([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_4([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_4\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 5 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # increases hidden state dim from 8 to 16\n",
    "    def guide_5(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_5([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_5([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_5([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_5([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_5([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_5([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_5([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_5([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_5([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_5([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_5([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_5([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_5([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_5([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_5([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_5\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "    \n",
    "    # guide 6 basically inverse the arrows in the model, add hidden states that each RV\n",
    "    # each RV also dependes on its neighbour at the same level\n",
    "    # similar to guide_4 in tree\n",
    "    # hid dependes on its old values and all sampled RVs in current iteration (x1,x2...x8, y1,...y4, z1,z2, obs)\n",
    "    # sample from i = 0, 1, ..., n-2, n-1\n",
    "    # different from guide_4 by adding obses[i] as an extra dependecy when updating hid\n",
    "\n",
    "    def guide_6(self, n, obs):\n",
    "        def tree_guide(i, hid):\n",
    "            z2_mean, z2_std = self.z2_net_6([obses[i], hid])\n",
    "            z2 = pyro.sample(f\"z2{i}\", dist.Normal(z2_mean, z2_std))\n",
    "            z1_mean, z1_std = self.z1_net_6([obses[i], hid, z2])\n",
    "            z1 = pyro.sample(f\"z1{i}\", dist.Normal(z1_mean, z1_std))\n",
    "            y4_mean, y4_std = self.y4_net_6([z2, hid])\n",
    "            y4 = pyro.sample(f\"y4{i}\", dist.Normal(y4_mean, y4_std))\n",
    "            y3_mean, y3_std = self.y3_net_6([z2, hid, y4])\n",
    "            y3 = pyro.sample(f\"y3{i}\", dist.Normal(y3_mean, y3_std))\n",
    "            y2_mean, y2_std = self.y2_net_6([z1, hid])\n",
    "            y2 = pyro.sample(f\"y2{i}\", dist.Normal(y2_mean, y2_std))\n",
    "            y1_mean, y1_std = self.y1_net_6([z1, hid, y2])\n",
    "            y1 = pyro.sample(f\"y1{i}\", dist.Normal(y1_mean, y1_std))\n",
    "            x8_mean, x8_std = self.x8_net_6([y4, hid])\n",
    "            x8 = pyro.sample(f\"x8{i}\", dist.Normal(x8_mean, x8_std))\n",
    "            x7_mean, x7_std = self.x7_net_6([y4, hid, x8])\n",
    "            x7 = pyro.sample(f\"x7{i}\", dist.Normal(x7_mean, x7_std))\n",
    "            x6_mean, x6_std = self.x6_net_6([y3, hid])\n",
    "            x6 = pyro.sample(f\"x6{i}\", dist.Normal(x6_mean, x6_std))\n",
    "            x5_mean, x5_std = self.x5_net_6([y3, hid, x6])\n",
    "            x5 = pyro.sample(f\"x5{i}\", dist.Normal(x5_mean, x5_std))\n",
    "            x4_mean, x4_std = self.x4_net_6([y2, hid])\n",
    "            x4 = pyro.sample(f\"x4{i}\", dist.Normal(x4_mean, x4_std))\n",
    "            x3_mean, x3_std = self.x3_net_6([y2, hid, x4])\n",
    "            x3 = pyro.sample(f\"x3{i}\", dist.Normal(x3_mean, x3_std))\n",
    "            x2_mean, x2_std = self.x2_net_6([y1, hid])\n",
    "            x2 = pyro.sample(f\"x2{i}\", dist.Normal(x2_mean, x2_std))\n",
    "            x1_mean, x1_std = self.x1_net_6([y1, hid, x2])\n",
    "            x1 = pyro.sample(f\"x1{i}\", dist.Normal(x1_mean, x1_std))\n",
    "            hid = self.hid_net_6([hid, x1, x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obses[i]])\n",
    "            return hid\n",
    "            \n",
    "        pyro.module(\"model\", self)\n",
    "        hid = self.h0_6\n",
    "        for i in range(n):\n",
    "            hid = tree_guide(i, hid)\n",
    "def generate_data():\n",
    "    \n",
    "    n_min = 2\n",
    "    n_max = 4\n",
    "    n = random.randint(n_min, n_max)\n",
    "    obses = []\n",
    "    mu = 0\n",
    "    x_len = 8\n",
    "    for i in range(n):\n",
    "        x_noise = torch.randn(x_len) / 4\n",
    "        x_mean = torch.zeros(x_len) + mu\n",
    "        xs = torch.normal(x_mean, 1) + x_noise\n",
    "        ys = []\n",
    "        j = 0\n",
    "        while j < len(xs):\n",
    "            y = dist.Normal(xs[j] + xs[j+1], 2).sample()\n",
    "            ys.append(y)\n",
    "            j +=2\n",
    "        \n",
    "        zs = []\n",
    "        j = 0\n",
    "        while j < len(ys):\n",
    "            z = dist.Normal(ys[j] + ys[j+1], 1.5).sample()\n",
    "            zs.append(z)\n",
    "            j +=2\n",
    "        \n",
    "        \n",
    "        obs = dist.Normal(zs[0] + zs[1], 1).sample()\n",
    "        obses.append(obs)\n",
    "        \n",
    "    return n, obses\n",
    "    \n",
    "        \n",
    "\n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "#print(data)\n",
    "experiment = Experiment()\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_6 # guide_1\n",
    "\n",
    "#guide = AutoNormal(experiment.model)\n",
    "#guide = AutoMultivariateNormal(experiment.model)\n",
    "#guide = AutoDiagonalNormal(experiment.model)\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "n_steps = 100\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for n, obses in data:\n",
    "        imme_loss += svi.step(n, obses) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-cooler",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6002a8a76388>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6002a8a76388>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [Step 10/100] Immediate Loss: 205.02005288749922 Accumlated Loss: 229.93057604810593\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# guide 1\n",
    "[Step 10/100] Immediate Loss: 205.02005288749922 Accumlated Loss: 229.93057604810593\n",
    "[Step 20/100] Immediate Loss: 193.44546516716488 Accumlated Loss: 197.67716926190258\n",
    "[Step 30/100] Immediate Loss: 189.72216062426574 Accumlated Loss: 192.7044314104617\n",
    "[Step 40/100] Immediate Loss: 191.6670883595943 Accumlated Loss: 192.4000375045538\n",
    "[Step 50/100] Immediate Loss: 192.85603537023067 Accumlated Loss: 191.965986341089\n",
    "[Step 60/100] Immediate Loss: 189.7273656892775 Accumlated Loss: 191.2137057619691\n",
    "[Step 70/100] Immediate Loss: 193.29120927006005 Accumlated Loss: 191.3552865049243\n",
    "[Step 80/100] Immediate Loss: 191.55413781136275 Accumlated Loss: 190.50370052289958\n",
    "[Step 90/100] Immediate Loss: 189.8036905479431 Accumlated Loss: 190.74393684166665\n",
    "[Step 100/100] Immediate Loss: 191.4137462487817 Accumlated Loss: 191.34739547252656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_1_1\n",
    "[Step 10/100] Immediate Loss: 243.17567226558916 Accumlated Loss: 249.93117425850028\n",
    "[Step 20/100] Immediate Loss: 244.72659548014403 Accumlated Loss: 242.8565336660445\n",
    "[Step 30/100] Immediate Loss: 240.5080971556902 Accumlated Loss: 242.6165884468257\n",
    "[Step 40/100] Immediate Loss: 242.08676910877227 Accumlated Loss: 242.84494205495716\n",
    "[Step 50/100] Immediate Loss: 242.76524257272482 Accumlated Loss: 244.14858736667034\n",
    "[Step 60/100] Immediate Loss: 241.0754128733278 Accumlated Loss: 242.2538581807018\n",
    "[Step 70/100] Immediate Loss: 243.60054168164731 Accumlated Loss: 242.72385012498495\n",
    "[Step 80/100] Immediate Loss: 242.04735180199143 Accumlated Loss: 242.54857986423377\n",
    "[Step 90/100] Immediate Loss: 244.95454502999777 Accumlated Loss: 242.92264006292822\n",
    "[Step 100/100] Immediate Loss: 240.45793809533114 Accumlated Loss: 241.56808622214197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 2\n",
    "[Step 10/100] Immediate Loss: 161.72037420719855 Accumlated Loss: 206.97543536764383\n",
    "[Step 20/100] Immediate Loss: 154.42872785031793 Accumlated Loss: 156.8636066983342\n",
    "[Step 30/100] Immediate Loss: 154.89385166198016 Accumlated Loss: 155.554997610718\n",
    "[Step 40/100] Immediate Loss: 152.9510755580663 Accumlated Loss: 153.27333305451273\n",
    "[Step 50/100] Immediate Loss: 154.33259579449893 Accumlated Loss: 152.67802670937778\n",
    "[Step 60/100] Immediate Loss: 151.32435389369724 Accumlated Loss: 152.40955043360594\n",
    "[Step 70/100] Immediate Loss: 152.12359817773108 Accumlated Loss: 151.92007436320185\n",
    "[Step 80/100] Immediate Loss: 151.63909643739467 Accumlated Loss: 151.64953022274378\n",
    "[Step 90/100] Immediate Loss: 150.09802410513163 Accumlated Loss: 151.33765858772398\n",
    "[Step 100/100] Immediate Loss: 151.99334681153297 Accumlated Loss: 151.38464494919774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3\n",
    "[Step 10/100] Immediate Loss: 156.54970044404274 Accumlated Loss: 205.49120853278043\n",
    "[Step 20/100] Immediate Loss: 146.21416290223593 Accumlated Loss: 151.73081569635866\n",
    "[Step 30/100] Immediate Loss: 145.99762244373565 Accumlated Loss: 148.037068867147\n",
    "[Step 40/100] Immediate Loss: 144.90703502684838 Accumlated Loss: 146.81886969110366\n",
    "[Step 50/100] Immediate Loss: 154.47853491395713 Accumlated Loss: 146.8090178412497\n",
    "[Step 60/100] Immediate Loss: 144.7315254962444 Accumlated Loss: 145.9859772133231\n",
    "[Step 70/100] Immediate Loss: 144.5153875619173 Accumlated Loss: 144.81224406862256\n",
    "[Step 80/100] Immediate Loss: 145.71405132502315 Accumlated Loss: 144.49057878816132\n",
    "[Step 90/100] Immediate Loss: 142.99038626790053 Accumlated Loss: 144.68658062565328\n",
    "[Step 100/100] Immediate Loss: 144.86714501202107 Accumlated Loss: 144.51566709992287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3_1\n",
    "[Step 10/100] Immediate Loss: 237.95079532623285 Accumlated Loss: 244.41158370643853\n",
    "[Step 20/100] Immediate Loss: 235.0609086954593 Accumlated Loss: 237.2647152982056\n",
    "[Step 30/100] Immediate Loss: 239.3422497320175 Accumlated Loss: 237.2776778906882\n",
    "[Step 40/100] Immediate Loss: 231.52443150669333 Accumlated Loss: 236.76619076043366\n",
    "[Step 50/100] Immediate Loss: 236.21208954542874 Accumlated Loss: 235.64118742516632\n",
    "[Step 60/100] Immediate Loss: 235.87248040288685 Accumlated Loss: 235.92637273627525\n",
    "[Step 70/100] Immediate Loss: 234.67147369980813 Accumlated Loss: 235.32963036370276\n",
    "[Step 80/100] Immediate Loss: 235.51996728897092 Accumlated Loss: 235.26592883837222\n",
    "[Step 90/100] Immediate Loss: 235.32647399485114 Accumlated Loss: 235.39784914121034\n",
    "[Step 100/100] Immediate Loss: 234.3285268226264 Accumlated Loss: 236.0535413537621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 4\n",
    "[Step 10/100] Immediate Loss: 136.67552889168263 Accumlated Loss: 171.65901040324567\n",
    "[Step 20/100] Immediate Loss: 134.46544417381284 Accumlated Loss: 136.2050290864408\n",
    "[Step 30/100] Immediate Loss: 133.56331461280584 Accumlated Loss: 133.82781182029842\n",
    "[Step 40/100] Immediate Loss: 133.42557626813652 Accumlated Loss: 133.1396080618799\n",
    "[Step 50/100] Immediate Loss: 132.9371324226259 Accumlated Loss: 132.9935011680722\n",
    "[Step 60/100] Immediate Loss: 132.42990424573418 Accumlated Loss: 132.64160733377935\n",
    "[Step 70/100] Immediate Loss: 132.5175514909625 Accumlated Loss: 132.90345291566848\n",
    "[Step 80/100] Immediate Loss: 132.891668445766 Accumlated Loss: 132.6192719244957\n",
    "[Step 90/100] Immediate Loss: 132.40696921557188 Accumlated Loss: 132.36135414510966\n",
    "[Step 100/100] Immediate Loss: 133.0058055579662 Accumlated Loss: 132.72950833249092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5\n",
    "[Step 10/100] Immediate Loss: 137.6395178815722 Accumlated Loss: 161.69517275613546\n",
    "[Step 20/100] Immediate Loss: 134.848082999885 Accumlated Loss: 136.15659867483376\n",
    "[Step 30/100] Immediate Loss: 133.76911400049923 Accumlated Loss: 134.251332498014\n",
    "[Step 40/100] Immediate Loss: 133.32945654392245 Accumlated Loss: 133.28956336176395\n",
    "[Step 50/100] Immediate Loss: 132.86999615460635 Accumlated Loss: 133.24745962142947\n",
    "[Step 60/100] Immediate Loss: 132.82050257802007 Accumlated Loss: 133.2022660382092\n",
    "[Step 70/100] Immediate Loss: 133.0186079853774 Accumlated Loss: 133.04267943680287\n",
    "[Step 80/100] Immediate Loss: 132.48377571076156 Accumlated Loss: 132.91993908631804\n",
    "[Step 90/100] Immediate Loss: 132.986798030138 Accumlated Loss: 132.58449679705498\n",
    "[Step 100/100] Immediate Loss: 132.66238063335425 Accumlated Loss: 132.46512776604297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 6 ### best\n",
    "[Step 10/100] Immediate Loss: 133.2505471915007 Accumlated Loss: 151.00078135699033\n",
    "[Step 20/100] Immediate Loss: 131.09676937043668 Accumlated Loss: 131.77195127099753\n",
    "[Step 30/100] Immediate Loss: 130.5309797182679 Accumlated Loss: 130.8939816444516\n",
    "[Step 40/100] Immediate Loss: 130.90671580255034 Accumlated Loss: 130.66879585793612\n",
    "[Step 50/100] Immediate Loss: 130.40981076270342 Accumlated Loss: 130.5509652917683\n",
    "[Step 60/100] Immediate Loss: 130.4613345116377 Accumlated Loss: 130.49925536295774\n",
    "[Step 70/100] Immediate Loss: 130.44797495543955 Accumlated Loss: 130.4517231901586\n",
    "[Step 80/100] Immediate Loss: 130.47368122369053 Accumlated Loss: 130.4738130722344\n",
    "[Step 90/100] Immediate Loss: 130.42225397557016 Accumlated Loss: 130.38270727610586\n",
    "[Step 100/100] Immediate Loss: 130.53060866862532 Accumlated Loss: 130.35955410438777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoNormal\n",
    "[Step 10/100] Immediate Loss: 1233.5509329861402 Accumlated Loss: 1227.3371018108132\n",
    "[Step 20/100] Immediate Loss: 1223.710170497894 Accumlated Loss: 1198.8953249975439\n",
    "[Step 30/100] Immediate Loss: 1214.6601654508706 Accumlated Loss: 1199.9680957393944\n",
    "[Step 40/100] Immediate Loss: 1164.4792316886785 Accumlated Loss: 1196.4807624239027\n",
    "[Step 50/100] Immediate Loss: 1185.8603583538534 Accumlated Loss: 1201.2587032988667\n",
    "[Step 60/100] Immediate Loss: 1168.790014993846 Accumlated Loss: 1197.5709460456371\n",
    "[Step 70/100] Immediate Loss: 1175.152639506459 Accumlated Loss: 1194.480629557699\n",
    "[Step 80/100] Immediate Loss: 1200.5110745263096 Accumlated Loss: 1204.2938371902703\n",
    "[Step 90/100] Immediate Loss: 1210.800975180566 Accumlated Loss: 1195.3925600020586\n",
    "[Step 100/100] Immediate Loss: 1179.5571283224222 Accumlated Loss: 1201.02371161443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoMultivariateNormal\n",
    "[Step 10/100] Immediate Loss: 1235.3812578570842 Accumlated Loss: 1236.1352865802646\n",
    "[Step 20/100] Immediate Loss: 1210.2978770101067 Accumlated Loss: 1216.1027867695093\n",
    "[Step 30/100] Immediate Loss: 1229.688204897046 Accumlated Loss: 1205.0053660194872\n",
    "[Step 40/100] Immediate Loss: 1200.555576323867 Accumlated Loss: 1192.0478162692784\n",
    "[Step 50/100] Immediate Loss: 1191.1188332122565 Accumlated Loss: 1196.5321274908779\n",
    "[Step 60/100] Immediate Loss: 1191.3697812026737 Accumlated Loss: 1206.1590484446883\n",
    "[Step 70/100] Immediate Loss: 1189.0993092578653 Accumlated Loss: 1185.5664499574898\n",
    "[Step 80/100] Immediate Loss: 1184.2317881757021 Accumlated Loss: 1193.5602444505096\n",
    "[Step 90/100] Immediate Loss: 1213.3458593541382 Accumlated Loss: 1189.3086517564059\n",
    "[Step 100/100] Immediate Loss: 1194.0520617479087 Accumlated Loss: 1196.8081811218856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDiagonalNormal\n",
    "[Step 10/100] Immediate Loss: 1235.8018628519776 Accumlated Loss: 1236.249700816393\n",
    "[Step 20/100] Immediate Loss: 1212.7352848732473 Accumlated Loss: 1217.2863890322446\n",
    "[Step 30/100] Immediate Loss: 1233.1168017601972 Accumlated Loss: 1208.195502301395\n",
    "[Step 40/100] Immediate Loss: 1205.5053979098793 Accumlated Loss: 1196.19749720788\n",
    "[Step 50/100] Immediate Loss: 1196.6777249866725 Accumlated Loss: 1201.5737289296987\n",
    "[Step 60/100] Immediate Loss: 1195.7460924953223 Accumlated Loss: 1211.1477473101022\n",
    "[Step 70/100] Immediate Loss: 1194.371914086938 Accumlated Loss: 1191.4428508981468\n",
    "[Step 80/100] Immediate Loss: 1189.6923706567293 Accumlated Loss: 1199.3408790806534\n",
    "[Step 90/100] Immediate Loss: 1220.8790620434281 Accumlated Loss: 1195.186482142985\n",
    "[Step 100/100] Immediate Loss: 1201.1263765621195 Accumlated Loss: 1203.2602218962313"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
