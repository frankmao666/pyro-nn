{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "secret-episode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10/100] Immediate Loss: 29.661400873661044 Accumlated Loss: 34.381083221018315\n",
      "[Step 20/100] Immediate Loss: 21.721210796236996 Accumlated Loss: 24.125531654298307\n",
      "[Step 30/100] Immediate Loss: 20.717992586493505 Accumlated Loss: 20.629015110522506\n",
      "[Step 40/100] Immediate Loss: 20.31778262376786 Accumlated Loss: 20.401564517676828\n",
      "[Step 50/100] Immediate Loss: 21.517062507569797 Accumlated Loss: 20.607605726897724\n",
      "[Step 60/100] Immediate Loss: 20.558893247246754 Accumlated Loss: 20.390989627033466\n",
      "[Step 70/100] Immediate Loss: 20.57022605895995 Accumlated Loss: 20.47847183179855\n",
      "[Step 80/100] Immediate Loss: 19.823867598176 Accumlated Loss: 20.282766120791436\n",
      "[Step 90/100] Immediate Loss: 20.220103700757026 Accumlated Loss: 20.263966775059696\n",
      "[Step 100/100] Immediate Loss: 20.07956038057804 Accumlated Loss: 20.539366428911684\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal, AutoNormal, AutoMultivariateNormal\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # guide 1\n",
    "        \n",
    "        self.x1_net_1 = simpleNN()\n",
    "        self.x2_net_1 = simpleNN()\n",
    "        self.x3_net_1 = simpleNN()\n",
    "        self.x4_net_1 = simpleNN()\n",
    "        self.x5_net_1 = simpleNN()\n",
    "        self.x6_net_1 = simpleNN()\n",
    "        self.x7_net_1 = simpleNN()\n",
    "        self.x8_net_1 = simpleNN()\n",
    "        self.y1_net_1 = simpleNN()\n",
    "        self.y2_net_1 = simpleNN()\n",
    "        self.y3_net_1 = simpleNN()\n",
    "        self.y4_net_1 = simpleNN()\n",
    "        self.z1_net_1 = simpleNN()\n",
    "        self.z2_net_1 = simpleNN()\n",
    "        \n",
    "        # guide 2\n",
    "        self.x1_net_2 = simpleNN(2)\n",
    "        self.x2_net_2 = simpleNN(2)\n",
    "        self.x3_net_2 = simpleNN(2)\n",
    "        self.x4_net_2 = simpleNN(2)\n",
    "        self.x5_net_2 = simpleNN(2)\n",
    "        self.x6_net_2 = simpleNN(2)\n",
    "        self.x7_net_2 = simpleNN(2)\n",
    "        self.x8_net_2 = simpleNN(2)\n",
    "        self.y1_net_2 = simpleNN(2)\n",
    "        self.y2_net_2 = simpleNN(2)\n",
    "        self.y3_net_2 = simpleNN(2)\n",
    "        self.y4_net_2 = simpleNN(2)\n",
    "        self.z1_net_2 = simpleNN()\n",
    "        self.z2_net_2 = simpleNN()\n",
    "        \n",
    "        # guide 3\n",
    "        self.x1_net_3 = simpleNN(7)\n",
    "        self.x2_net_3 = simpleNN(7)\n",
    "        self.x3_net_3 = simpleNN(7)\n",
    "        self.x4_net_3 = simpleNN(7)\n",
    "        self.x5_net_3 = simpleNN(7)\n",
    "        self.x6_net_3 = simpleNN(7)\n",
    "        self.x7_net_3 = simpleNN(7)\n",
    "        self.x8_net_3 = simpleNN(7)\n",
    "        self.y1_net_3 = simpleNN(3)\n",
    "        self.y2_net_3 = simpleNN(3)\n",
    "        self.y3_net_3 = simpleNN(3)\n",
    "        self.y4_net_3 = simpleNN(3)\n",
    "        self.z1_net_3 = simpleNN()\n",
    "        self.z2_net_3 = simpleNN()\n",
    "\n",
    "        # guide 4\n",
    "        self.x1_net_4 = simpleNN(2)\n",
    "        self.x2_net_4 = simpleNN()\n",
    "        self.x3_net_4 = simpleNN(2)\n",
    "        self.x4_net_4 = simpleNN()\n",
    "        self.x5_net_4 = simpleNN(2)\n",
    "        self.x6_net_4 = simpleNN()\n",
    "        self.x7_net_4 = simpleNN(2)\n",
    "        self.x8_net_4 = simpleNN()\n",
    "        self.y1_net_4 = simpleNN(2)\n",
    "        self.y2_net_4 = simpleNN()\n",
    "        self.y3_net_4 = simpleNN(2)\n",
    "        self.y4_net_4 = simpleNN()\n",
    "        self.z1_net_4 = simpleNN(2)\n",
    "        self.z2_net_4 = simpleNN()\n",
    "        \n",
    "        # guide 5\n",
    "        self.x1_net_5 = simpleNN(14)\n",
    "        self.x2_net_5 = simpleNN(13)\n",
    "        self.x3_net_5 = simpleNN(12)\n",
    "        self.x4_net_5 = simpleNN(11)\n",
    "        self.x5_net_5 = simpleNN(10)\n",
    "        self.x6_net_5 = simpleNN(9)\n",
    "        self.x7_net_5 = simpleNN(8)\n",
    "        self.x8_net_5 = simpleNN(7)\n",
    "        self.y1_net_5 = simpleNN(6)\n",
    "        self.y2_net_5 = simpleNN(5)\n",
    "        self.y3_net_5 = simpleNN(4)\n",
    "        self.y4_net_5 = simpleNN(3)\n",
    "        self.z1_net_5 = simpleNN(2)\n",
    "        self.z2_net_5 = simpleNN()\n",
    "        \n",
    "        # guide 6\n",
    "        self.x1_net_6 = simpleNN()\n",
    "        self.x2_net_6 = simpleNN()\n",
    "        self.x3_net_6 = simpleNN()\n",
    "        self.x4_net_6 = simpleNN()\n",
    "        self.x5_net_6 = simpleNN()\n",
    "        self.x6_net_6 = simpleNN()\n",
    "        self.x7_net_6 = simpleNN()\n",
    "        self.x8_net_6 = simpleNN()\n",
    "        self.y1_net_6 = simpleNN(2)\n",
    "        self.y2_net_6 = simpleNN(2)\n",
    "        self.y3_net_6 = simpleNN(2)\n",
    "        self.y4_net_6 = simpleNN(2)\n",
    "        self.z1_net_6 = simpleNN(2)\n",
    "        self.z2_net_6 = simpleNN(2)\n",
    "        \n",
    "        # guide 7\n",
    "        self.x1_net_7 = simpleNN()\n",
    "        self.x2_net_7 = simpleNN(2)\n",
    "        self.x3_net_7 = simpleNN()\n",
    "        self.x4_net_7 = simpleNN(2)\n",
    "        self.x5_net_7 = simpleNN()\n",
    "        self.x6_net_7 = simpleNN(2)\n",
    "        self.x7_net_7 = simpleNN()\n",
    "        self.x8_net_7 = simpleNN(2)\n",
    "        self.y1_net_7 = simpleNN(2)\n",
    "        self.y2_net_7 = simpleNN(3)\n",
    "        self.y3_net_7 = simpleNN(2)\n",
    "        self.y4_net_7 = simpleNN(3)\n",
    "        self.z1_net_7 = simpleNN(2)\n",
    "        self.z2_net_7 = simpleNN(3)\n",
    "    \n",
    "    # a tree model\n",
    "    def model(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(0, 1.0))\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(0, 1.0))\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(0, 1.0))\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(0, 1.0))\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(0, 1.0))\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(0, 1.0))\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(0, 1.0))\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(0, 1.0))\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(x1+x2, 1.0))\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(x3+x4, 1.0))\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(x5+x6, 1.0))\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(x7+x8, 1.0))\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(y1+y2, 1.0))\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(y3+y4, 1.0))\n",
    "        pyro.sample(\"obs\", dist.Normal(z1+z2, 1.0), obs=obs)\n",
    "        \n",
    "    # guide 1 basically inverse the arrows in the model\n",
    "    def guide_1(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_1([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_1([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_1([z2])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_1([z2])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_1([z1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_1([z1])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_1([y4])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_1([y4])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_1([y3])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_1([y3])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_1([y2])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_1([y2])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_1([y1])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_1([y1])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 2 inverse the arrows in the model and add obs as dependency for each RV \n",
    "    def guide_2(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_2([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_2([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_2([z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_2([z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_2([z1, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_2([z1, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_2([y4, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_2([y4, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_2([y3, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_2([y3, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_2([y2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_2([y2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_2([y1, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_2([y1, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 3 inverse the arrows and each RV depends on all RVs in previous levels\n",
    "    # i.e. x depends on all y + z + obs\n",
    "    def guide_3(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_3([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_3([obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_3([z1, z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_3([z1, z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_3([z1, z2, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_3([z1, z2, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_3([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 4 inverse the arrows and each RV depends on its previously sampled sibling (if any) at the same level\n",
    "    # i.e. x1 depends on y1 and x2, y1 depends on z1 and y2, y3 depends on z2 and y4\n",
    "    # this should be minimum failthful\n",
    "    def guide_4(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_4([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_4([z2, obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_4([z2])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_4([y4, z2])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_4([z1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_4([y2, z1])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_4([y4])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_4([x8, y4])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_4([y3])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_4([x6, y3])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_4([y2])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_4([x4, y2])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_4([y1])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_4([x2, y1])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "    \n",
    "    # guide 5 inverse the arrows and each RV depends on all previously sampled RV\n",
    "    # fully-connected\n",
    "    def guide_5(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        z2_mean, z2_std = self.z2_net_5([obs])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        z1_mean, z1_std = self.z1_net_5([z2, obs])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))\n",
    "        y4_mean, y4_std = self.y4_net_5([z1, z2, obs])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))\n",
    "        y3_mean, y3_std = self.y3_net_5([y4, z1, z2, obs])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))\n",
    "        y2_mean, y2_std = self.y2_net_5([y3, y4, z1, z2, obs])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))\n",
    "        y1_mean, y1_std = self.y1_net_5([y2, y3, y4, z1, z2, obs])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))\n",
    "        x8_mean, x8_std = self.x8_net_5([y1, y2, y3, y4, z1, z2, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        x7_mean, x7_std = self.x7_net_5([x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x6_mean, x6_std = self.x6_net_5([x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))\n",
    "        x5_mean, x5_std = self.x5_net_5([x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x4_mean, x4_std = self.x4_net_5([x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))\n",
    "        x3_mean, x3_std = self.x3_net_5([x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x2_mean, x2_std = self.x2_net_5([x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x1_mean, x1_std = self.x1_net_5([x2, x3, x4, x5, x6, x7, x8, y1, y2, y3, y4, z1, z2, obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        \n",
    "    # guide 6 the order to sample RV is the same as the model but given obs as dependency for xs\n",
    "    def guide_6(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "\n",
    "        x1_mean, x1_std = self.x1_net_6([obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        x2_mean, x2_std = self.x2_net_6([obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x3_mean, x3_std = self.x3_net_6([obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x4_mean, x4_std = self.x4_net_6([obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))        \n",
    "        x5_mean, x5_std = self.x5_net_6([obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x6_mean, x6_std = self.x6_net_6([obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))        \n",
    "        x7_mean, x7_std = self.x7_net_6([obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x8_mean, x8_std = self.x8_net_6([obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        y1_mean, y1_std = self.y1_net_6([x1, x2])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))        \n",
    "        y2_mean, y2_std = self.y2_net_6([x3, x4])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))        \n",
    "        y3_mean, y3_std = self.y3_net_6([x5, x6])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))        \n",
    "        y4_mean, y4_std = self.y4_net_6([x7, x8])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))        \n",
    "        z1_mean, z1_std = self.z1_net_6([y1, y2])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))        \n",
    "        z2_mean, z2_std = self.z2_net_6([y3, y4])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "    \n",
    "    # guide 7 is similar to guide 6 but each RV dependent on its subling\n",
    "    # the inverse of guide 4\n",
    "    def guide_7(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "\n",
    "        x1_mean, x1_std = self.x1_net_7([obs])\n",
    "        x1 = pyro.sample(\"x1\", dist.Normal(x1_mean, x1_std))\n",
    "        x2_mean, x2_std = self.x2_net_7([x1, obs])\n",
    "        x2 = pyro.sample(\"x2\", dist.Normal(x2_mean, x2_std))\n",
    "        x3_mean, x3_std = self.x3_net_7([obs])\n",
    "        x3 = pyro.sample(\"x3\", dist.Normal(x3_mean, x3_std))\n",
    "        x4_mean, x4_std = self.x4_net_7([x3, obs])\n",
    "        x4 = pyro.sample(\"x4\", dist.Normal(x4_mean, x4_std))        \n",
    "        x5_mean, x5_std = self.x5_net_7([obs])\n",
    "        x5 = pyro.sample(\"x5\", dist.Normal(x5_mean, x5_std))\n",
    "        x6_mean, x6_std = self.x6_net_7([x5, obs])\n",
    "        x6 = pyro.sample(\"x6\", dist.Normal(x6_mean, x6_std))        \n",
    "        x7_mean, x7_std = self.x7_net_7([obs])\n",
    "        x7 = pyro.sample(\"x7\", dist.Normal(x7_mean, x7_std))\n",
    "        x8_mean, x8_std = self.x8_net_7([x7, obs])\n",
    "        x8 = pyro.sample(\"x8\", dist.Normal(x8_mean, x8_std))\n",
    "        y1_mean, y1_std = self.y1_net_7([x1, x2])\n",
    "        y1 = pyro.sample(\"y1\", dist.Normal(y1_mean, y1_std))        \n",
    "        y2_mean, y2_std = self.y2_net_7([x3, x4, y1])\n",
    "        y2 = pyro.sample(\"y2\", dist.Normal(y2_mean, y2_std))        \n",
    "        y3_mean, y3_std = self.y3_net_7([x5, x6])\n",
    "        y3 = pyro.sample(\"y3\", dist.Normal(y3_mean, y3_std))        \n",
    "        y4_mean, y4_std = self.y4_net_7([x7, x8, y3])\n",
    "        y4 = pyro.sample(\"y4\", dist.Normal(y4_mean, y4_std))        \n",
    "        z1_mean, z1_std = self.z1_net_7([y1, y2])\n",
    "        z1 = pyro.sample(\"z1\", dist.Normal(z1_mean, z1_std))        \n",
    "        z2_mean, z2_std = self.z2_net_7([y3, y4, z1])\n",
    "        z2 = pyro.sample(\"z2\", dist.Normal(z2_mean, z2_std))\n",
    "        \n",
    "def generate_data():\n",
    "    x_len = 8\n",
    "    xs = torch.randn(x_len)\n",
    "    ys = []\n",
    "    i = 0\n",
    "    while i < len(xs):\n",
    "        y = dist.Normal(xs[i] + xs[i+1], 2).sample()\n",
    "        ys.append(y)\n",
    "        i +=2\n",
    "        \n",
    "    zs = []\n",
    "    i = 0\n",
    "    while i < len(ys):\n",
    "        z = dist.Normal(ys[i] + ys[i+1], 1.5).sample()\n",
    "        zs.append(z)\n",
    "        i +=2\n",
    "        \n",
    "        \n",
    "    obs = dist.Normal(zs[0] + zs[1], 1).sample()\n",
    "    return obs\n",
    "    \n",
    "        \n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "#print(data)\n",
    "experiment = Experiment()\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "#guide = experiment.guide_4 # guide_1\n",
    "\n",
    "# pyro auto guide\n",
    "guide = AutoNormal(experiment.model)\n",
    "#guide = AutoMultivariateNormal(experiment.model)\n",
    "#guide = AutoDiagonalNormal(experiment.model)\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "n_steps = 100\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for obs in data:\n",
    "        imme_loss += svi.step(obs) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olive-reynolds",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-54276383af52>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-54276383af52>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [Step 10/100] Immediate Loss: 5.6792811819911035 Accumlated Loss: 8.161501753419639\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# guide 1\n",
    "[Step 10/100] Immediate Loss: 5.6792811819911035 Accumlated Loss: 8.161501753419639\n",
    "[Step 20/100] Immediate Loss: 5.6724499085545546 Accumlated Loss: 5.7964787363111965\n",
    "[Step 30/100] Immediate Loss: 5.761731808781624 Accumlated Loss: 5.581517954558135\n",
    "[Step 40/100] Immediate Loss: 6.112146431803706 Accumlated Loss: 5.703019751578569\n",
    "[Step 50/100] Immediate Loss: 5.990561635196209 Accumlated Loss: 5.61033443725109\n",
    "[Step 60/100] Immediate Loss: 5.79047949910164 Accumlated Loss: 5.709876654744148\n",
    "[Step 70/100] Immediate Loss: 5.865784194469453 Accumlated Loss: 5.6813742448389535\n",
    "[Step 80/100] Immediate Loss: 5.5839250811934455 Accumlated Loss: 5.665409379035234\n",
    "[Step 90/100] Immediate Loss: 5.802031826376916 Accumlated Loss: 5.689023856550455\n",
    "[Step 100/100] Immediate Loss: 5.711089228987696 Accumlated Loss: 5.733322246074676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 2\n",
    "[Step 10/100] Immediate Loss: 6.268227699697018 Accumlated Loss: 9.823156678080556\n",
    "[Step 20/100] Immediate Loss: 6.012787947654725 Accumlated Loss: 6.139076143831014\n",
    "[Step 30/100] Immediate Loss: 6.102070910632606 Accumlated Loss: 5.927030056893825\n",
    "[Step 40/100] Immediate Loss: 6.45776209264994 Accumlated Loss: 5.981230340063572\n",
    "[Step 50/100] Immediate Loss: 6.256524928808213 Accumlated Loss: 5.893774724751712\n",
    "[Step 60/100] Immediate Loss: 6.069752818644045 Accumlated Loss: 5.9795956534147265\n",
    "[Step 70/100] Immediate Loss: 6.092835750877859 Accumlated Loss: 5.928910363674163\n",
    "[Step 80/100] Immediate Loss: 5.949914609193803 Accumlated Loss: 5.921238815844059\n",
    "[Step 90/100] Immediate Loss: 6.110138435661791 Accumlated Loss: 5.9243319559395315\n",
    "[Step 100/100] Immediate Loss: 5.967664820253849 Accumlated Loss: 5.956207058787346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 3\n",
    "[Step 10/100] Immediate Loss: 6.570058162808415 Accumlated Loss: 9.397841033637526\n",
    "[Step 20/100] Immediate Loss: 6.147684178054332 Accumlated Loss: 6.235418024212122\n",
    "[Step 30/100] Immediate Loss: 6.111919716298578 Accumlated Loss: 5.938203674733639\n",
    "[Step 40/100] Immediate Loss: 6.531079505085945 Accumlated Loss: 5.937320747315884\n",
    "[Step 50/100] Immediate Loss: 6.133750829696654 Accumlated Loss: 5.836949352592229\n",
    "[Step 60/100] Immediate Loss: 5.995875943303109 Accumlated Loss: 5.909800890862941\n",
    "[Step 70/100] Immediate Loss: 6.01717264592648 Accumlated Loss: 5.870649518340828\n",
    "[Step 80/100] Immediate Loss: 5.837504681944848 Accumlated Loss: 5.835405748039484\n",
    "[Step 90/100] Immediate Loss: 6.031392835974693 Accumlated Loss: 5.827427438616752\n",
    "[Step 100/100] Immediate Loss: 5.949472520351413 Accumlated Loss: 5.865983818709852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "### guide 4 ### best\n",
    "[Step 10/100] Immediate Loss: 4.377868088781835 Accumlated Loss: 6.545501601159573\n",
    "[Step 20/100] Immediate Loss: 3.575750644803046 Accumlated Loss: 4.03719574072957\n",
    "[Step 30/100] Immediate Loss: 3.5968227416276943 Accumlated Loss: 3.657659743905067\n",
    "[Step 40/100] Immediate Loss: 3.5601295506954207 Accumlated Loss: 3.6178785299956795\n",
    "[Step 50/100] Immediate Loss: 3.4762910395860662 Accumlated Loss: 3.543176322728395\n",
    "[Step 60/100] Immediate Loss: 3.52601896584034 Accumlated Loss: 3.533123803049326\n",
    "[Step 70/100] Immediate Loss: 3.449901377856731 Accumlated Loss: 3.498376666098833\n",
    "[Step 80/100] Immediate Loss: 3.472165140509606 Accumlated Loss: 3.527985264599323\n",
    "[Step 90/100] Immediate Loss: 3.535960964262485 Accumlated Loss: 3.4987394436597814\n",
    "[Step 100/100] Immediate Loss: 3.4975102710723887 Accumlated Loss: 3.5023412067890174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 5\n",
    "[Step 10/100] Immediate Loss: 5.436824112832545 Accumlated Loss: 7.459522048622368\n",
    "[Step 20/100] Immediate Loss: 4.522601895034313 Accumlated Loss: 4.697016129463912\n",
    "[Step 30/100] Immediate Loss: 4.035572609305381 Accumlated Loss: 4.087585103064775\n",
    "[Step 40/100] Immediate Loss: 3.9674540817737576 Accumlated Loss: 3.922967136412859\n",
    "[Step 50/100] Immediate Loss: 3.819277352690697 Accumlated Loss: 3.8670592607259744\n",
    "[Step 60/100] Immediate Loss: 3.8970872554183003 Accumlated Loss: 3.8228334636390207\n",
    "[Step 70/100] Immediate Loss: 3.6495595994591716 Accumlated Loss: 3.728844232827424\n",
    "[Step 80/100] Immediate Loss: 3.6761886674165725 Accumlated Loss: 3.7416907757222653\n",
    "[Step 90/100] Immediate Loss: 3.6880584159493455 Accumlated Loss: 3.6743881301581856\n",
    "[Step 100/100] Immediate Loss: 3.7141958668828003 Accumlated Loss: 3.684455200225115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 6\n",
    "[Step 10/100] Immediate Loss: 8.01269422084093 Accumlated Loss: 15.49425634944439\n",
    "[Step 20/100] Immediate Loss: 6.9067663696408275 Accumlated Loss: 7.9501663804352285\n",
    "[Step 30/100] Immediate Loss: 8.029220328330993 Accumlated Loss: 8.010903750896453\n",
    "[Step 40/100] Immediate Loss: 8.31351687759161 Accumlated Loss: 8.1114898557961\n",
    "[Step 50/100] Immediate Loss: 8.786913882493973 Accumlated Loss: 7.755306751757858\n",
    "[Step 60/100] Immediate Loss: 7.783528136909008 Accumlated Loss: 7.7925652467012405\n",
    "[Step 70/100] Immediate Loss: 8.006914387047292 Accumlated Loss: 7.681327867358923\n",
    "[Step 80/100] Immediate Loss: 8.374721429347991 Accumlated Loss: 7.807788733184337\n",
    "[Step 90/100] Immediate Loss: 7.715019945800301 Accumlated Loss: 7.808754653304815\n",
    "[Step 100/100] Immediate Loss: 8.256794970929624 Accumlated Loss: 7.728429790437221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide 7\n",
    "[Step 10/100] Immediate Loss: 7.946083300113675 Accumlated Loss: 15.880016953587534\n",
    "[Step 20/100] Immediate Loss: 6.707426010072232 Accumlated Loss: 7.429752558678389\n",
    "[Step 30/100] Immediate Loss: 6.904689866006373 Accumlated Loss: 7.198620594471693\n",
    "[Step 40/100] Immediate Loss: 7.047841712534428 Accumlated Loss: 7.0875664424300195\n",
    "[Step 50/100] Immediate Loss: 7.573134193122387 Accumlated Loss: 6.855033908337354\n",
    "[Step 60/100] Immediate Loss: 7.103918403685091 Accumlated Loss: 6.874631712168455\n",
    "[Step 70/100] Immediate Loss: 6.944367031455041 Accumlated Loss: 6.938687078088522\n",
    "[Step 80/100] Immediate Loss: 7.446044615507124 Accumlated Loss: 7.044109266996383\n",
    "[Step 90/100] Immediate Loss: 6.661473557949067 Accumlated Loss: 6.902258327007294\n",
    "[Step 100/100] Immediate Loss: 7.03185636729002 Accumlated Loss: 6.8993669908344755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoNormal \n",
    "[Step 10/100] Immediate Loss: 29.661400873661044 Accumlated Loss: 34.381083221018315\n",
    "[Step 20/100] Immediate Loss: 21.721210796236996 Accumlated Loss: 24.125531654298307\n",
    "[Step 30/100] Immediate Loss: 20.717992586493505 Accumlated Loss: 20.629015110522506\n",
    "[Step 40/100] Immediate Loss: 20.31778262376786 Accumlated Loss: 20.401564517676828\n",
    "[Step 50/100] Immediate Loss: 21.517062507569797 Accumlated Loss: 20.607605726897724\n",
    "[Step 60/100] Immediate Loss: 20.558893247246754 Accumlated Loss: 20.390989627033466\n",
    "[Step 70/100] Immediate Loss: 20.57022605895995 Accumlated Loss: 20.47847183179855\n",
    "[Step 80/100] Immediate Loss: 19.823867598176 Accumlated Loss: 20.282766120791436\n",
    "[Step 90/100] Immediate Loss: 20.220103700757026 Accumlated Loss: 20.263966775059696\n",
    "[Step 100/100] Immediate Loss: 20.07956038057804 Accumlated Loss: 20.539366428911684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoMultivariateNormal\n",
    "[Step 10/100] Immediate Loss: 29.280232212543496 Accumlated Loss: 34.96955828201771\n",
    "[Step 20/100] Immediate Loss: 20.823702557683003 Accumlated Loss: 23.777785731434825\n",
    "[Step 30/100] Immediate Loss: 17.56564211547375 Accumlated Loss: 18.975887567698955\n",
    "[Step 40/100] Immediate Loss: 18.09688677370549 Accumlated Loss: 18.158192227423196\n",
    "[Step 50/100] Immediate Loss: 17.358041861653323 Accumlated Loss: 17.932833659708496\n",
    "[Step 60/100] Immediate Loss: 17.660284592509267 Accumlated Loss: 17.789189765751363\n",
    "[Step 70/100] Immediate Loss: 16.889609196186065 Accumlated Loss: 17.35965327256918\n",
    "[Step 80/100] Immediate Loss: 18.56209426760674 Accumlated Loss: 17.78802405971289\n",
    "[Step 90/100] Immediate Loss: 17.714577720761305 Accumlated Loss: 17.483879809975623\n",
    "[Step 100/100] Immediate Loss: 16.55987268984317 Accumlated Loss: 17.230655351817603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoDiagonalNormal\n",
    "[Step 10/100] Immediate Loss: 29.594689139127723 Accumlated Loss: 35.09126758885384\n",
    "[Step 20/100] Immediate Loss: 22.305745403170594 Accumlated Loss: 24.653422838687895\n",
    "[Step 30/100] Immediate Loss: 19.765058637857443 Accumlated Loss: 20.882928909182546\n",
    "[Step 40/100] Immediate Loss: 20.646754955649378 Accumlated Loss: 20.50682894957065\n",
    "[Step 50/100] Immediate Loss: 20.2246539914608 Accumlated Loss: 20.506671326756482\n",
    "[Step 60/100] Immediate Loss: 21.094068167805677 Accumlated Loss: 20.755982849299905\n",
    "[Step 70/100] Immediate Loss: 20.336222262978545 Accumlated Loss: 20.427405071496963\n",
    "[Step 80/100] Immediate Loss: 21.357484986782072 Accumlated Loss: 20.727729279518126\n",
    "[Step 90/100] Immediate Loss: 21.060880010724066 Accumlated Loss: 20.713297606468206\n",
    "[Step 100/100] Immediate Loss: 20.076601029038425 Accumlated Loss: 20.360575951337818"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
