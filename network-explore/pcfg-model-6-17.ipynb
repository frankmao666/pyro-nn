{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optional-directory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.5857), tensor(2.7068), tensor(4.8608), tensor(6.1139), tensor(4.6004), tensor(3.8240), tensor(1.9414), tensor(2.3964), tensor(3.5893), tensor(5.5297), tensor(2.9538), tensor(1.5710), tensor(2.2152), tensor(6.6835), tensor(2.9834), tensor(1.9756), tensor(2.8751), tensor(8.8158), tensor(3.6413), tensor(7.6196), tensor(2.6612), tensor(4.6239), tensor(2.4577), tensor(3.7058), tensor(3.6893), tensor(4.8420), tensor(4.2017), tensor(3.4029), tensor(3.9699), tensor(3.1579), tensor(2.5926), tensor(5.3986), tensor(1.5447), tensor(3.6529), tensor(3.0065), tensor(4.5435), tensor(4.9046), tensor(7.6414), tensor(7.8547), tensor(3.4003), tensor(3.5397), tensor(2.3844), tensor(5.0411), tensor(9.2279), tensor(4.0925), tensor(3.9601), tensor(2.4482), tensor(4.3861), tensor(3.0862), tensor(3.0329), tensor(6.2649), tensor(3.5822), tensor(2.9517), tensor(3.5280), tensor(3.0020), tensor(3.3643), tensor(6.1092), tensor(6.7970), tensor(3.5570), tensor(2.4357), tensor(4.5206), tensor(2.7233), tensor(4.8208), tensor(3.7926), tensor(5.3722), tensor(2.3932), tensor(6.1690), tensor(2.9790), tensor(3.9106), tensor(3.4592), tensor(2.1313), tensor(6.2138), tensor(-0.5234), tensor(3.1785), tensor(2.6159), tensor(3.6970), tensor(2.2894), tensor(2.6201), tensor(7.1070), tensor(0.0661), tensor(2.2554), tensor(3.2787), tensor(7.8124), tensor(5.9089), tensor(7.9558), tensor(7.8007), tensor(3.2686), tensor(5.3726), tensor(5.1581), tensor(7.8612), tensor(4.3224), tensor(1.9417), tensor(9.5836), tensor(2.5217), tensor(2.7025), tensor(3.0759), tensor(3.6562), tensor(2.7056), tensor(2.7447), tensor(4.6541)]\n",
      "[Step 10/100] Immediate Loss: 15.65785191923381 Accumlated Loss: 27.521529941409828\n",
      "[Step 20/100] Immediate Loss: 9.181662517264487 Accumlated Loss: 10.142460460945964\n",
      "[Step 30/100] Immediate Loss: 9.073848144486544 Accumlated Loss: 9.41119017122686\n",
      "[Step 40/100] Immediate Loss: 9.367795079164203 Accumlated Loss: 9.333177496946416\n",
      "[Step 50/100] Immediate Loss: 9.464715682566162 Accumlated Loss: 9.114056323527358\n",
      "[Step 60/100] Immediate Loss: 9.084946442395449 Accumlated Loss: 9.0807487567747\n",
      "[Step 70/100] Immediate Loss: 9.141939090248197 Accumlated Loss: 9.209436322024091\n",
      "[Step 80/100] Immediate Loss: 9.76587741822936 Accumlated Loss: 9.230823772877457\n",
      "[Step 90/100] Immediate Loss: 8.874032034681875 Accumlated Loss: 9.172223159402929\n",
      "[Step 100/100] Immediate Loss: 8.782549491748213 Accumlated Loss: 9.1371221883737\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from made import MADE\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# NN used for p(x | y)\n",
    "class simpleNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden=32, out_size=1, t=\"normal\", out_non_linear=None):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.out_non_linear = out_non_linear\n",
    "        self.hiddeen_layer = nn.Linear(input_size, hidden)\n",
    "        if t == \"normal\":\n",
    "            self.loc_layer = nn.Linear(hidden, out_size)\n",
    "            self.std_layer = nn.Linear(hidden, out_size)\n",
    "            self.softplus = nn.Softplus()\n",
    "        elif t == \"bern\":\n",
    "            self.prob_layer = nn.Linear(hidden, out_size)\n",
    "        elif t == \"mlp\":\n",
    "            self.out_layer = nn.Linear(hidden, out_size)\n",
    "        \n",
    "    def forward(self, x_list):\n",
    "        for i in range(len(x_list)):\n",
    "            if x_list[i].dim() == 0:\n",
    "                x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "        input_x = torch.cat(x_list)\n",
    "        hid = F.relu(self.hiddeen_layer(input_x))\n",
    "        # return loc, std\n",
    "        if self.t == \"normal\":\n",
    "            return self.loc_layer(hid), self.softplus(self.std_layer(hid))\n",
    "        elif self.t == \"bern\":\n",
    "            return torch.sigmoid(self.prob_layer(hid))\n",
    "        else:\n",
    "            if self.out_non_linear == \"tanh\":\n",
    "                return torch.tanh(self.out_layer(hid))\n",
    "            else:\n",
    "                return self.out_layer(hid)\n",
    "        \n",
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=32, max_l=5, max_t=3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size + max_l + max_t, hidden_size=hidden_size, nonlinearity='relu',\n",
    "                          batch_first=True, num_layers=1)\n",
    "        self.h_0 = nn.Parameter(torch.zeros((1, 1, hidden_size)))\n",
    "        self.out_loc = nn.Linear(hidden_size, 1)\n",
    "        self.out_std = nn.Linear(hidden_size, 1)\n",
    "        self.max_l = max_l # max time steps\n",
    "        self.max_t = max_t # type of random variables, ex. y1 y2 next_x\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "    def forward(self, x, obs, l, t):\n",
    "        \"\"\"\n",
    "        x: x0\n",
    "        obs: R\n",
    "        l: length\n",
    "        t: type, y1, y2 or next_x\n",
    "        \"\"\"\n",
    "        length = l * 3\n",
    "        input_x = x.repeat((int(length), 1))\n",
    "        input_obs = obs.repeat((int(length), 1))\n",
    "        input_l = []\n",
    "        input_t = []\n",
    "        \n",
    "        for n in range(int(l)):\n",
    "            \n",
    "            for i in range(int(t)):\n",
    "                input_l.append(n)\n",
    "                input_t.append(i)\n",
    "        input_l = F.one_hot(torch.tensor(input_l), self.max_l) \n",
    "        input_t = F.one_hot(torch.tensor(input_t), self.max_t) \n",
    "        \n",
    "        input_ = torch.unsqueeze(torch.cat([input_x, input_obs, input_l, input_t], -1), 0)\n",
    "        \n",
    "        # the input is [x, obs, onehot(l), onehot(t)]\n",
    "        rnn_output, _ = self.rnn(input_, self.h_0)\n",
    "        rnn_output = torch.squeeze(rnn_output, 0)\n",
    "        out_loc = self.out_loc(F.relu(rnn_output))\n",
    "        out_std = self.softplus(self.out_std(F.relu(rnn_output)))\n",
    "        # the first outputs are y_1_1, y_2_1, next_x_1; y_1_2, y_2_2, next_x_2\n",
    "        return torch.squeeze(out_loc, 1), torch.squeeze(out_std, 1) # shape l * t\n",
    "\n",
    "class Experiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 3\n",
    "        self.max_rec = 5\n",
    "        \n",
    "        # for guide_0\n",
    "        self.h_a_nn_0 = simpleNN(input_size=self.hidden_size, t=\"bern\")\n",
    "        self.h_b_nn_0 = simpleNN(input_size=self.hidden_size)\n",
    "        self.h_encoder_0 = simpleNN(input_size=1 + self.hidden_size, out_size=self.hidden_size, t=\"mlp\")\n",
    "        self.h0_0 = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        \n",
    "        \n",
    "        # for guide_1\n",
    "        self.h_a_nn_1 = simpleNN(input_size=1 + self.hidden_size, t=\"bern\")\n",
    "        self.h_b_nn_1 = simpleNN(input_size=1 + self.hidden_size)\n",
    "        self.h_encoder_1 = simpleNN(input_size=1 + self.hidden_size, out_size=self.hidden_size, t=\"mlp\")\n",
    "        self.h0_1 = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        \n",
    "        # for guide_2\n",
    "        self.h_a_nn_2 = simpleNN(input_size=1 + self.hidden_size, t=\"bern\")\n",
    "        self.h_b_nn_2 = simpleNN(input_size=2 + self.hidden_size)\n",
    "        self.h_encoder_2 = simpleNN(input_size=2 + self.hidden_size, out_size=self.hidden_size, t=\"mlp\")\n",
    "        self.h0_2 = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        \n",
    "        # for guide_made_0\n",
    "        self.hidden_size_made_0 = 3\n",
    "        self.made_in_dim_0_1 = 1 + self.hidden_size_made_0\n",
    "        self.num_var_0_1 = 1\n",
    "        self.made_out_dim_0_1 = self.made_in_dim_0_1 * self.num_var_0_1\n",
    "        self.made_hidden_0_1 = [32, 32]\n",
    "        self.made_0_1 = MADE(self.made_in_dim_0_1, self.made_hidden_0_1, self.made_out_dim_0_1, num_masks=1, natural_ordering=True)\n",
    "        self.made_map_a_0 = nn.Linear(self.made_out_dim_0_1, 1)\n",
    "    \n",
    "        self.made_in_dim_0_2 = 2 + self.hidden_size_made_0\n",
    "        self.num_var_0_2 = 1\n",
    "        self.made_out_dim_0_2 = self.made_in_dim_0_2 * self.num_var_0_2\n",
    "        self.made_hidden_0_2 = [32, 32]\n",
    "        self.made_0_2 = MADE(self.made_in_dim_0_2, self.made_hidden_0_2, self.made_out_dim_0_2, num_masks=1, natural_ordering=True)\n",
    "        self.made_map_b_loc_0 = nn.Linear(self.made_out_dim_0_2, 1)\n",
    "        self.made_map_b_std_0 = nn.Linear(self.made_out_dim_0_2, 1)\n",
    "        self.h_encoder_made_0 = simpleNN(input_size=2 + self.hidden_size, out_size=self.hidden_size, t=\"mlp\")\n",
    "        self.h0_made_0 = nn.Parameter(torch.zeros(self.hidden_size_made_0))\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    \n",
    "    def g(self, x):\n",
    "        return torch.tanh(x) \n",
    "    \n",
    "    def model(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_model(prefix, l):\n",
    "            a = pyro.sample(\"a_{}\".format(prefix), dist.Bernoulli(0.5))\n",
    "            if a > 0 or l > self.max_rec:\n",
    "                b = pyro.sample(\"b_{}\".format(prefix), dist.Normal(0, 1))\n",
    "                return b\n",
    "            else:\n",
    "                c = rec_model(prefix+\"c\", l + 1)\n",
    "                d = rec_model(prefix+\"d\", l + 1)\n",
    "                return c + d\n",
    "        sig = torch.tensor(0.5)\n",
    "        x = rec_model(\"root\", 0)\n",
    "        pyro.sample(\"obs\", dist.Normal(x, sig), obs=float(obs))\n",
    "    \n",
    "    # guide uses simple and individual NN for each random variable\n",
    "    def guide_0(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_guide(prefix, h, l):\n",
    "            a_prob = self.h_a_nn_0([h])\n",
    "            a = pyro.sample(\"a_{}\".format(prefix), dist.Bernoulli(a_prob))\n",
    "            if a > 0 or l > self.max_rec:\n",
    "                b_loc, b_std = self.h_b_nn_0([h])\n",
    "                return pyro.sample(\"b_{}\".format(prefix), dist.Normal(b_loc, b_std))\n",
    "            else:\n",
    "                c = rec_guide(prefix+\"c\", h, l + 1)\n",
    "                h = self.h_encoder_0([c,h])\n",
    "                d = rec_guide(prefix+\"d\", h, l + 1)\n",
    "                return c + d \n",
    "        rec_guide(\"root\", self.h0_0, 0)\n",
    "                \n",
    "    \n",
    "    # guide uses simple and individual NN for each random variable, add obs as dependency\n",
    "    def guide_1(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_guide(prefix, h, obs, l):\n",
    "            a_prob = self.h_a_nn_1([h, obs])\n",
    "            a = pyro.sample(\"a_{}\".format(prefix), dist.Bernoulli(a_prob))\n",
    "            if a > 0 or l > self.max_rec:\n",
    "                b_loc, b_std = self.h_b_nn_1([h, obs])\n",
    "                return pyro.sample(\"b_{}\".format(prefix), dist.Normal(b_loc, b_std))\n",
    "            else:\n",
    "                c = rec_guide(prefix+\"c\", h, obs, l + 1)\n",
    "                h = self.h_encoder_1([c,h])\n",
    "                d = rec_guide(prefix+\"d\", h, obs, l + 1)\n",
    "                return c + d \n",
    "        rec_guide(\"root\", self.h0_1, obs, 0)\n",
    "        \n",
    "    # guide uses simple and individual NN for each random variable, more dependency considered\n",
    "    def guide_2(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        def rec_guide(prefix, h, obs, l):\n",
    "            a_prob = self.h_a_nn_2([h, obs])\n",
    "            a = pyro.sample(\"a_{}\".format(prefix), dist.Bernoulli(a_prob))\n",
    "            if a > 0 or l > self.max_rec:\n",
    "                b_loc, b_std = self.h_b_nn_2([h, obs, a])\n",
    "                return pyro.sample(\"b_{}\".format(prefix), dist.Normal(b_loc, b_std))\n",
    "            else:\n",
    "                c = rec_guide(prefix+\"c\", h, obs, l + 1)\n",
    "                h = self.h_encoder_2([c,h,a])\n",
    "                d = rec_guide(prefix+\"d\", h, obs, l + 1)\n",
    "                return c + d \n",
    "        rec_guide(\"root\", self.h0_2, obs, 0)\n",
    "        \n",
    "    def guide_made_0(self, obs):\n",
    "        pyro.module(\"model\", self)\n",
    "        def concat_input_made(x_list):\n",
    "            for i in range(len(x_list)):\n",
    "                if x_list[i].dim() == 0:\n",
    "                    x_list[i] = torch.unsqueeze(x_list[i], dim=0)\n",
    "            input_x = torch.cat(x_list)\n",
    "            return input_x\n",
    "        def rec_guide(prefix, h, obs, l):\n",
    "            made_1_in = concat_input_made([h, obs])\n",
    "            made_1_out = self.made_0_1(made_1_in)\n",
    "            a_prob = torch.sigmoid(self.made_map_a_0(made_1_out))\n",
    "            a = pyro.sample(\"a_{}\".format(prefix), dist.Bernoulli(a_prob))\n",
    "            if a > 0 or l > self.max_rec:\n",
    "                made_2_in = concat_input_made([h, obs, a])\n",
    "                made_2_out = self.made_0_2(made_2_in)\n",
    "                b_loc = self.made_map_b_loc_0(made_2_out)\n",
    "                b_std = self.softplus(self.made_map_b_std_0(made_2_out))\n",
    "                return pyro.sample(\"b_{}\".format(prefix), dist.Normal(b_loc, b_std))\n",
    "            else:\n",
    "                c = rec_guide(prefix+\"c\", h, obs, l + 1)\n",
    "                h = self.h_encoder_made_0([c,h,a])\n",
    "                d = rec_guide(prefix+\"d\", h, obs, l + 1)\n",
    "                return c + d \n",
    "        rec_guide(\"root\", self.h0_made_0, obs, 0)\n",
    "    \n",
    "def generate_data():\n",
    "    # the actual data generation has three latent variables (y_1, y_2, y_3)\n",
    "    x0 = random.random() / 50\n",
    "    base_std = 0.356\n",
    "    def f(x0):\n",
    "        a = dist.Bernoulli(x0).sample()\n",
    "        if a > 0:\n",
    "            noise_mean = random.random() / 5 \n",
    "            if random.random() < 0.5:\n",
    "                noise_mean *= -1\n",
    "            noise_std = random.random() / 5\n",
    "            return dist.Normal(2 * x0 + noise_mean, base_std + noise_std).sample()\n",
    "        else:\n",
    "            s = 0\n",
    "            for _ in range(2):\n",
    "                s += f(max(x0 + random.random() / 10, 0.75))\n",
    "            return s\n",
    "        \n",
    "    return f(x0)\n",
    "    \n",
    "data = []\n",
    "num_data = 100\n",
    "for _ in range(num_data):\n",
    "    data.append(generate_data())\n",
    "\n",
    "print(data)\n",
    "experiment = Experiment()\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.95, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "guide = experiment.guide_made_0 # guide_1\n",
    "\n",
    "svi = SVI(experiment.model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 100\n",
    "log_interval = 10\n",
    "# do gradient steps\n",
    "loss = 0\n",
    "loss_track = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    imme_loss = 0\n",
    "    \n",
    "    for obs in data:\n",
    "        imme_loss += svi.step(obs) / num_data\n",
    "        \n",
    "    loss_track.append(imme_loss)\n",
    "    loss += imme_loss / log_interval\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print(\"[Step {}/{}] Immediate Loss: {} Accumlated Loss: {}\".format(step, n_steps, imme_loss, loss))\n",
    "        loss = 0\n",
    "    \n",
    "plt.plot(loss_track)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-paradise",
   "metadata": {},
   "source": [
    "results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "based-reader",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-cf15846e9d35>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-cf15846e9d35>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    [Step 10/200] Immediate Loss: 19.031159826517108 Accumlated Loss: 30.669728822827345\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# guide_0\n",
    "[Step 10/200] Immediate Loss: 19.031159826517108 Accumlated Loss: 30.669728822827345\n",
    "[Step 20/200] Immediate Loss: 16.54116699755191 Accumlated Loss: 16.42493181198835\n",
    "[Step 30/200] Immediate Loss: 15.830906611680986 Accumlated Loss: 15.341987950056792\n",
    "[Step 40/200] Immediate Loss: 14.625833902955055 Accumlated Loss: 15.328452881455421\n",
    "[Step 50/200] Immediate Loss: 15.429139192998413 Accumlated Loss: 15.12139590618014\n",
    "[Step 60/200] Immediate Loss: 16.700843995809553 Accumlated Loss: 15.193378344476224\n",
    "[Step 70/200] Immediate Loss: 13.782704436480998 Accumlated Loss: 14.926948586285116\n",
    "[Step 80/200] Immediate Loss: 13.849593170583253 Accumlated Loss: 14.773630363225937\n",
    "[Step 90/200] Immediate Loss: 14.682365895658728 Accumlated Loss: 14.936238646164536\n",
    "[Step 100/200] Immediate Loss: 14.949490445554256 Accumlated Loss: 15.427314028546215\n",
    "[Step 110/200] Immediate Loss: 15.533587679564953 Accumlated Loss: 15.366392598420385\n",
    "[Step 120/200] Immediate Loss: 15.174833083748815 Accumlated Loss: 15.251150453075768\n",
    "[Step 130/200] Immediate Loss: 15.296379088461395 Accumlated Loss: 15.222727478057147\n",
    "[Step 140/200] Immediate Loss: 14.548529184162614 Accumlated Loss: 15.24323720142245\n",
    "[Step 150/200] Immediate Loss: 15.327036719620224 Accumlated Loss: 15.089846912264827\n",
    "[Step 160/200] Immediate Loss: 15.66180207520723 Accumlated Loss: 15.366233869403601\n",
    "[Step 170/200] Immediate Loss: 15.747280451953404 Accumlated Loss: 14.878797188669443\n",
    "[Step 180/200] Immediate Loss: 14.456126456558705 Accumlated Loss: 14.763787083625793\n",
    "[Step 190/200] Immediate Loss: 14.843872060179715 Accumlated Loss: 14.933787340179087\n",
    "[Step 200/200] Immediate Loss: 15.440625265836713 Accumlated Loss: 15.287833866387603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_1\n",
    "[Step 10/100] Immediate Loss: 17.930261366367343 Accumlated Loss: 27.829307303488253\n",
    "[Step 20/100] Immediate Loss: 9.592198074162006 Accumlated Loss: 12.552848016187548\n",
    "[Step 30/100] Immediate Loss: 9.336000512987372 Accumlated Loss: 9.432053346917034\n",
    "[Step 40/100] Immediate Loss: 8.680979787409306 Accumlated Loss: 9.163381985932588\n",
    "[Step 50/100] Immediate Loss: 9.146411037594085 Accumlated Loss: 8.818429456993936\n",
    "[Step 60/100] Immediate Loss: 8.943090667575602 Accumlated Loss: 9.075083977945148\n",
    "[Step 70/100] Immediate Loss: 8.938816332668068 Accumlated Loss: 8.664682637892664\n",
    "[Step 80/100] Immediate Loss: 8.656451758295297 Accumlated Loss: 8.717697938293217\n",
    "[Step 90/100] Immediate Loss: 9.12393444098532 Accumlated Loss: 8.998925273619593\n",
    "[Step 100/100] Immediate Loss: 8.29359666161239 Accumlated Loss: 8.46837840466201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_2\n",
    "[Step 10/100] Immediate Loss: 11.012404969632627 Accumlated Loss: 20.942087798953054\n",
    "[Step 20/100] Immediate Loss: 8.874061445668339 Accumlated Loss: 9.659853560857476\n",
    "[Step 30/100] Immediate Loss: 9.305319509208205 Accumlated Loss: 8.925286741890012\n",
    "[Step 40/100] Immediate Loss: 8.64788700006902 Accumlated Loss: 8.818340191334485\n",
    "[Step 50/100] Immediate Loss: 8.317036350667474 Accumlated Loss: 8.81623889724165\n",
    "[Step 60/100] Immediate Loss: 8.895614063516259 Accumlated Loss: 8.728870033808054\n",
    "[Step 70/100] Immediate Loss: 8.995070771798492 Accumlated Loss: 8.337308281101286\n",
    "[Step 80/100] Immediate Loss: 7.560207392536105 Accumlated Loss: 9.192471126087941\n",
    "[Step 90/100] Immediate Loss: 8.08053003266454 Accumlated Loss: 8.266035702221098\n",
    "[Step 100/100] Immediate Loss: 8.43317556051537 Accumlated Loss: 8.17740331849642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guide_made_0\n",
    "[Step 10/100] Immediate Loss: 15.65785191923381 Accumlated Loss: 27.521529941409828\n",
    "[Step 20/100] Immediate Loss: 9.181662517264487 Accumlated Loss: 10.142460460945964\n",
    "[Step 30/100] Immediate Loss: 9.073848144486544 Accumlated Loss: 9.41119017122686\n",
    "[Step 40/100] Immediate Loss: 9.367795079164203 Accumlated Loss: 9.333177496946416\n",
    "[Step 50/100] Immediate Loss: 9.464715682566162 Accumlated Loss: 9.114056323527358\n",
    "[Step 60/100] Immediate Loss: 9.084946442395449 Accumlated Loss: 9.0807487567747\n",
    "[Step 70/100] Immediate Loss: 9.141939090248197 Accumlated Loss: 9.209436322024091\n",
    "[Step 80/100] Immediate Loss: 9.76587741822936 Accumlated Loss: 9.230823772877457\n",
    "[Step 90/100] Immediate Loss: 8.874032034681875 Accumlated Loss: 9.172223159402929\n",
    "[Step 100/100] Immediate Loss: 8.782549491748213 Accumlated Loss: 9.1371221883737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-massage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-providence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-perception",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-geology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-snowboard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-father",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-sixth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-athens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-essay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
